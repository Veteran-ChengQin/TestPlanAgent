{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "text=\"\"\"\\n{\"Test plan\": \"\\\\ttc_mod \"\\n}\\n\"\"\"\n",
    "\n",
    "# text = text.replace(\"\\r\\n\", \"\\\\n\").replace('\\\"', '\\\\\"').replace(\"'\", \"\\'\")\n",
    "\n",
    "json_data = json.loads(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " xx\n",
      "{\"Test plan\": \"\\\\ \\\"111  \"}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def fix_invalid_json_escapes(json_str):\n",
    "    # 有效的JSON转义序列\n",
    "    valid_escapes = ['\"', '\\\\', '/', 'b', 'f', 'n', 'r', 't', 'u']\n",
    "    \n",
    "    # 查找所有反斜杠后跟着的字符\n",
    "    def replace_invalid_escape(match):\n",
    "        escape_char = match.group(1)\n",
    "        print(escape_char+\"xx\")\n",
    "        # 如果是有效的转义序列，保留它\n",
    "        if escape_char in valid_escapes:\n",
    "            return '\\\\' + escape_char\n",
    "        # 如果是无效的转义序列，在反斜杠前再加一个反斜杠使其成为字面量\n",
    "        else:\n",
    "            return '\\\\\\\\' + escape_char\n",
    "    \n",
    "    # 使用正则表达式查找和替换所有转义序列\n",
    "    fixed_str = re.sub(r'\\\\([^\"])', replace_invalid_escape, json_str)\n",
    "    print(fixed_str)\n",
    "    # 测试修复后的字符串是否可以被正确解析\n",
    "    try:\n",
    "        json.loads(fixed_str)\n",
    "        return fixed_str\n",
    "    except json.JSONDecodeError as e:\n",
    "\n",
    "        print(f\"修复后仍有错误: {e}\")\n",
    "        return None\n",
    "\n",
    "# 测试示例\n",
    "text=\"\"\"{\"Test plan\": \"\\\\ \\\\\"111  \"}\"\"\"\n",
    "\n",
    "fixed_text = fix_invalid_json_escapes(text)\n",
    "# print(fixed_text)\n",
    "\n",
    "if fixed_text:\n",
    "    parsed_json = json.loads(fixed_text)\n",
    "    # print(parsed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_components(text):\n",
    "    thought_pattern = r'\\*\\*Thought\\*\\*: (.*?)\\n'\n",
    "    action_name_pattern = r'```(.*?)\\n'\n",
    "    action_params_pattern = r'```.*?\\n(.*?)```'\n",
    "    expected_info_pattern = r'\\*\\*Expected Information\\*\\*: (.*?)\\n'\n",
    "    \n",
    "    pair_pattern = r'#### Thought-Action Pair (TA\\d+)(.*?)(?=#### Thought-Action Pair TA\\d+|\\Z)'\n",
    "    pairs = re.findall(pair_pattern, text, re.DOTALL)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for pair_id, pair_content in pairs:\n",
    "        thought_match = re.search(thought_pattern, pair_content)\n",
    "        action_name_match = re.search(action_name_pattern, pair_content)\n",
    "        action_params_match = re.search(action_params_pattern, pair_content, re.DOTALL)\n",
    "        expected_info_match = re.search(expected_info_pattern, pair_content)\n",
    "        \n",
    "        if thought_match and action_name_match and action_params_match and expected_info_match:\n",
    "            try:\n",
    "                action_params_json = json.loads(action_params_match.group(1).strip())\n",
    "            except json.JSONDecodeError:\n",
    "                action_params_json = {\"error\": \"Invalid JSON\"}\n",
    "            \n",
    "            pair_dict = {\n",
    "                \"id\": pair_id.strip(),\n",
    "                \"thought\": thought_match.group(1).strip(),\n",
    "                \"action_name\": action_name_match.group(1).strip(),\n",
    "                \"action_parameters\": action_params_json,\n",
    "                \"expected_information\": expected_info_match.group(1).strip()\n",
    "            }\n",
    "            \n",
    "            results.append(pair_dict)\n",
    "\n",
    "# 示例文本\n",
    "text = '''\n",
    "### Exploration Step 2                                                                                  \n",
    "                                                                                                                                                                 \n",
    "#### Thought-Action Pair TA004                                                                                                                                   \n",
    "- **Thought**: Since the `load_module` function has been modified, I need to understand how it interacts with other components in the system to ensure that all d\n",
    "ependencies are correctly handled.                                                                                                                               \n",
    "- **Action**: search_code_dependencies                                                                                                                           \n",
    "- **Action Parameters**: {\"entity_name\": \"load_module\"}                                                                                                          \n",
    "- **Expected Information**: This will help me identify which functions or classes call `load_module` and which functions it calls, allowing me to understand the \n",
    "broader impact of these changes.                                                                                                                                 \n",
    "                                                                                                                                                                 \n",
    "#### Thought-Action Pair TA005                                                                                                                                   \n",
    "- **Thought**: The PR involves changes to the deck configuration, specifically the introduction of fixture definitions for modules. I need to understand how thes\n",
    "e changes affect the overall deck configuration validation.                                                                                                      \n",
    "- **Action**: search_class_in_project                                                                                                                            \n",
    "- **Action Parameters**: {\"class_name\": \"DeckConfiguration\"}                                                                                                     \n",
    "- **Expected Information**: This will provide details about the `DeckConfiguration` class, including its methods and properties, which are likely involved in val\n",
    "idating the new fixture definitions.                                                                                                                             \n",
    "                                                                                                                                                                 \n",
    "#### Thought-Action Pair TA006                                                                                                                                   \n",
    "- **Thought**: The PR includes updates to the `/deck_configuration` endpoint. I need to examine the changes to this endpoint to understand how it handles module \n",
    "fixtures.                                                                                                                                                        \n",
    "- **Action**: view_code_changes                                                                                                                                  \n",
    "- **Action Parameters**: {\"file_path\": \"api/src/opentrons/calibration_storage/deck_configuration.py\"}                                                            \n",
    "- **Expected Information**: This will show me the exact changes made to the endpoint, including any new functionality or modifications to existing logic.        \n",
    "                                                                                                                                                                 \n",
    "#### Thought-Action Pair TA007                                                                                                                                   \n",
    "- **Thought**: The PR modifies several files related to the protocol engine and state management. I need to understand how these changes affect the overall state\n",
    " management and validation of deck configurations.                                                                                                               \n",
    "- **Action**: search_class_in_project                                                                                                                            \n",
    "- **Action Parameters**: {\"class_name\": \"State\"}                                                                                                                 \n",
    "- **Expected Information**: This will help me understand the `State` class, which is likely central to managing and validating deck configurations, including the\n",
    " new fixture definitions.                                                                                                                                        \n",
    "                                                                                                                                                                 \n",
    "#### Thought-Action Pair TA008                                                                                                                                   \n",
    "- **Thought**: The PR includes changes to the `types.py` files in both the `calibration_storage` and `protocol_engine` directories. I need to examine these chang\n",
    "es to understand how they impact the type definitions used throughout the system.                                                                                \n",
    "- **Action**: view_code_changes                                                                                                                                  \n",
    "- **Action Parameters**: {\"file_path\": \"api/src/opentrons/calibration_storage/types.py\"}\n",
    "- **Expected Information**: This will show me the changes to the type definitions, which are crucial for ensuring consistency and correctness across the system.\n",
    "'''\n",
    "\n",
    "result = extract_components(text)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "react_dir = 'result/Embedding'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "scores_list = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, 'scores')\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            if 'deepseek-chat' in score_file:\n",
    "                score_file_path = os.path.join(scores_dir, score_file)\n",
    "                # print(score_file_path)\n",
    "                with open(score_file_path, 'r') as f: \n",
    "                    score = json.load(f)\n",
    "                    scores_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "react_dir = 'result/ReAct'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, 'scores')\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            score_file_path = os.path.join(scores_dir, score_file)\n",
    "            if 'qwen-coder-14B' in score_file_path:\n",
    "                pull_number = score_file_path.split('_')[-1].split('.')[0].strip()\n",
    "                scores_file_list_dir.append(pull_number)\n",
    "\n",
    "# print(scores_file_list_dir)\n",
    "with open('/data/veteran/project/TestPlanAgent/data/PR/PR_URL_for_test.txt', 'r') as f:\n",
    "    url_list = f.readlines()\n",
    "\n",
    "pull_list = []\n",
    "for url in url_list:\n",
    "    pull_number = url.split('/')[-1].strip()\n",
    "    pull_list.append({pull_number: url})\n",
    "\n",
    "for p1 in pull_list:\n",
    "    if list(p1.keys())[0] not in scores_file_list_dir:\n",
    "        print(list(p1.values())[0].strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric is total_score------------\n",
      "150\n",
      "Average Score: 20.333333333333332\n",
      "Median Score: 21.0\n",
      "Max Score: 29\n",
      "Min Score: 9\n",
      "metric is accuracy------------\n",
      "150\n",
      "Average Score: 6.066666666666666\n",
      "Median Score: 6.0\n",
      "Max Score: 9\n",
      "Min Score: 1\n",
      "metric is completeness------------\n",
      "150\n",
      "Average Score: 6.24\n",
      "Median Score: 6.0\n",
      "Max Score: 10\n",
      "Min Score: 1\n",
      "metric is clarity------------\n",
      "150\n",
      "Average Score: 8.026666666666667\n",
      "Median Score: 8.0\n",
      "Max Score: 10\n",
      "Min Score: 4\n"
     ]
    }
   ],
   "source": [
    "# 计算生成的test plan的得分情况\n",
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "def cal(score_list, metric):\n",
    "    print(f\"metric is {metric}------------\")\n",
    "    average_score = sum(score_list) / len(score_list)\n",
    "\n",
    "    # 计算中位数\n",
    "    median_score = statistics.median(score_list)\n",
    "\n",
    "    # 计算最大值\n",
    "    max_score = max(score_list)\n",
    "\n",
    "    # 计算最小值\n",
    "    min_score = min(score_list)\n",
    "    print(len(score_list))\n",
    "    # 打印结果\n",
    "    print(f\"Average Score: {average_score}\")\n",
    "    print(f\"Median Score: {median_score}\")\n",
    "    print(f\"Max Score: {max_score}\")\n",
    "    print(f\"Min Score: {min_score}\")\n",
    "\n",
    "react_dir = 'result/ReAct'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "scores_list = []\n",
    "file_list = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, 'scores')\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            if 'qwen-coder-14B' in score_file:\n",
    "                score_file_path = os.path.join(scores_dir, score_file)\n",
    "                pull_number = score_file_path.split('_')[-1].split('.')[0].strip()\n",
    "                if pull_number not in file_list:\n",
    "                    file_list.append(pull_number)\n",
    "                else:\n",
    "                    print(pull_number)\n",
    "                # print(score_file_path)\n",
    "                with open(score_file_path, 'r') as f: \n",
    "                    score = json.load(f)\n",
    "                    # if score['evaluation']['clarity']['score'] >= 5:\n",
    "                    scores_list.append(score)\n",
    "\n",
    "score_list = []\n",
    "for score in scores_list:\n",
    "    score_list.append(score['evaluation']['total_score'])\n",
    "cal(score_list, \"total_score\")\n",
    "\n",
    "score_list.clear()\n",
    "for score in scores_list:\n",
    "    score_list.append(score['evaluation']['accuracy']['score'])\n",
    "cal(score_list, \"accuracy\")\n",
    "\n",
    "score_list.clear()\n",
    "for score in scores_list:\n",
    "    score_list.append(score['evaluation']['completeness']['score'])\n",
    "cal(score_list, \"completeness\")\n",
    "\n",
    "score_list.clear()\n",
    "for score in scores_list:\n",
    "    score_list.append(score['evaluation']['clarity']['score'])\n",
    "cal(score_list, \"clarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16024,\n"
     ]
    }
   ],
   "source": [
    "with open(\"/data/veteran/project/TestPlanAgent/data/PR/PR_URL_for_test.txt\", 'r') as f:\n",
    "    url_list = f.readlines()\n",
    "\n",
    "pull_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    pull_number = url.split('/')[-1].strip()\n",
    "    pull_list.append(pull_number)\n",
    "\n",
    "# print(len(pull_list))\n",
    "# print(len(file_list))\n",
    "for pull_number in file_list:\n",
    "    if pull_list.count(pull_number) == 0:\n",
    "        print(pull_number)\n",
    "# 将两个list写入文件\n",
    "\n",
    "# for pull_number in pull_list:\n",
    "#     if pull_number not in file_list:\n",
    "#         print(pull_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "react_dir = 'result/ReAct'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "scores_list = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, 'scores')\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            if 'qwen-coder-14B' in score_file:\n",
    "                score_file_path = os.path.join(scores_dir, score_file)\n",
    "                # print(score_file_path)\n",
    "                with open(score_file_path, 'r') as f: \n",
    "                    score = json.load(f)\n",
    "                    if \"evaluation\" not in score:\n",
    "                        scores_list.append(score_file_path)\n",
    "scores_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "react_dir = 'result/ReAct'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "scores_list = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, 'scores')\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            if 'qwen-coder-32B' in score_file:\n",
    "                score_file_path = os.path.join(scores_dir, score_file)\n",
    "                # print(score_file_path)\n",
    "                with open(score_file_path, 'r') as f: \n",
    "                    score = json.load(f)\n",
    "                    score['path'] = score_file_path\n",
    "                    scores_list.append(score)\n",
    "\n",
    "# for score in scores_list:\n",
    "#     if score['evaluation']['clarity']['score'] < 5:\n",
    "#         print(score['evaluation']['total_score'], score['path'], score['evaluation']['clarity']['score'])\n",
    "\n",
    "with open('/data/veteran/project/TestPlanAgent/data/PR/PR_URL_for_test.txt', 'r') as f:\n",
    "    full_url = f.readlines()\n",
    "\n",
    "aim_list = []\n",
    "\n",
    "for score in scores_list:\n",
    "    if score['evaluation']['accuracy']['score'] < 5:\n",
    "        for url in full_url:\n",
    "            pull_number = score['path'].split('_')[-1].split('.')[0]\n",
    "            if pull_number in url:\n",
    "                aim_list.append(url)\n",
    "                print(score['evaluation']['accuracy']['score'])\n",
    "                break\n",
    "aim_list\n",
    "# with open('/data/veteran/project/TestPlanAgent/data/PR/PR_URL_for_test_resume_1.txt', 'w') as f:\n",
    "#     f.writelines(aim_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt  # 导入matplotlib库\n",
    "\n",
    "react_dir = 'result/ReAct'\n",
    "\n",
    "react_list_dir = os.listdir(react_dir)\n",
    "\n",
    "scores_file_list_dir = []\n",
    "scores_list = []\n",
    "for i in react_list_dir:\n",
    "    scores_dir = os.path.join(react_dir, i, \"Test-Plan\")\n",
    "    if os.path.isdir(scores_dir):\n",
    "        scores_list_dir = os.listdir(scores_dir)\n",
    "        for score_file in scores_list_dir:\n",
    "            flag = False\n",
    "            if 'gpt-4o' in score_file:\n",
    "                score_file_path = os.path.join(scores_dir, score_file)\n",
    "                # print(score_file_path)\n",
    "                with open(score_file_path, 'r') as f: \n",
    "                    lines = f.readlines()\n",
    "                    # print(lines)\n",
    "                    # break\n",
    "                    for line in lines:\n",
    "                        if \"4. Test Cases\" in line:\n",
    "                            flag = True\n",
    "                            break\n",
    "                    if not flag:\n",
    "                        scores_list.append(score_file_path)\n",
    "\n",
    "print(len(scores_list))                   \n",
    "for score in scores_list:\n",
    "   print(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# 计算BLEU/ROUGE\n",
    "result_dir = \"./result/backup-with-git-diff-full/ReAct\"\n",
    "compare_pair = {}\n",
    "# 获取ref test plan以及 candidate test plan\n",
    "for repo in os.listdir(result_dir):\n",
    "    repo_dir = os.path.join(result_dir, repo)\n",
    "    if os.path.isdir(repo_dir):\n",
    "        PR_content_dir = os.path.join(repo_dir, \"PR-Content\")\n",
    "        if os.path.isdir(PR_content_dir):\n",
    "            PR_content_list = os.listdir(PR_content_dir)\n",
    "            for PR_content in PR_content_list:\n",
    "                pull_number = PR_content.split(\"_\")[0]\n",
    "                PR_content_file_dir = os.path.join(PR_content_dir, PR_content)\n",
    "                if os.path.isfile(PR_content_file_dir):\n",
    "                    with open(PR_content_file_dir, 'r') as f:\n",
    "                        PR_content_json = json.load(f)\n",
    "                    compare_pair[pull_number] = []\n",
    "                    compare_pair[pull_number].append(PR_content_json[\"Test_Plan\"])\n",
    "        Test_plan_dir = os.path.join(repo_dir, \"Test-Plan\")\n",
    "        if os.path.isdir(Test_plan_dir):\n",
    "            Test_plan_list = os.listdir(Test_plan_dir)\n",
    "            for Test_plan in Test_plan_list:\n",
    "                if \"gpt-4o\" in Test_plan:\n",
    "                    PR_content_file_dir = os.path.join(Test_plan_dir, Test_plan)\n",
    "                    pull_number = PR_content_file_dir.split(\"_\")[-1].split(\".\")[0]\n",
    "                    if os.path.isfile(PR_content_file_dir):\n",
    "                        with open(PR_content_file_dir, 'r') as f:\n",
    "                            PR_content_json = json.load(f)\n",
    "                        compare_pair[pull_number].append(PR_content_json[\"react_info\"][-1][\"test_plan\"])\n",
    "# print(compare_pair['16418'][0])\n",
    "for value in compare_pair.values():\n",
    "    if len(value) != 2:\n",
    "        print(value)\n",
    "        print(\"error\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'score': 1.2435569065346208, 'counts': [3869, 834, 274, 105], 'totals': [44443, 44406, 44369, 44332], 'precisions': [8.705532929820219, 1.8781245777597622, 0.6175482882192522, 0.23684922854822701], 'bp': 1.0, 'sys_len': 44443, 'ref_len': 8309}\n",
      "ROUGE: {'rouge1': 0.15005065305894255, 'rouge2': 0.03301212846981086, 'rougeL': 0.08387436333615349, 'rougeLsum': 0.14303829609377317}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load('sacrebleu')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "# For BLEU\n",
    "# predictions = [\"Going to play basketball this afternoon\", \"Going to play basketball afternoon\"]\n",
    "# references = [[\"Going to play basketball in the afternoon ?\"], [\"Going to play basketball in the afternoon ?\"]]\n",
    "references = [[value[0]] for value in compare_pair.values()]\n",
    "predictions =[value[1] for value in compare_pair.values()]\n",
    "\n",
    "bleu_results = bleu.compute(\n",
    "    predictions=predictions, \n",
    "    references=references,\n",
    "    # max_order=4,  # 只考虑1-gram和2-gram\n",
    "    # smooth=True   # 启用平滑处理\n",
    ")\n",
    "\n",
    "# For ROUGE\n",
    "rouge_results = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(f\"BLEU: {bleu_results}\")\n",
    "print(f\"ROUGE: {rouge_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BLEU = 1.28 39.6/5.4/0.2/0.1 (BP = 1.000 ratio = 1.146 hyp_len = 636 ref_len = 555)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "# predictions = [\"It's going to rain tomorrow.\"]\n",
    "# references = [[\"It will rain tomorrow.\"]]\n",
    "\n",
    "# 使用sacrebleu计算\n",
    "bleu = sacrebleu.corpus_bleu(predictions, references, force=True, tokenize='none')\n",
    "\n",
    "# 可通过调整输出分数得到paper中的计算方式\n",
    "bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System level F1 score: -0.198\n",
      "Precision: tensor([-0.3078, -0.2525, -0.2528, -0.2436, -0.1767, -0.3818, -0.2637,  0.0091,\n",
      "        -0.1118, -0.0834, -0.0840, -0.2777, -0.3577, -0.1670, -0.2006, -0.0483,\n",
      "        -0.0659, -0.2985, -0.1857, -0.2751, -0.1607, -0.1606, -0.2161, -0.1937,\n",
      "        -0.2022, -0.1191, -0.1154, -0.0875, -0.1723, -0.1360, -0.2139, -0.2572,\n",
      "        -0.5435, -0.2333, -0.1953, -0.5516, -0.5182])\n",
      "Recall: tensor([-0.5200, -0.4521, -0.1914, -0.4054, -0.0300, -0.7674, -0.5075, -0.0966,\n",
      "        -0.2609, -0.1439, -0.0098,  0.1636,  0.0916, -0.1436, -0.2203,  0.1602,\n",
      "         0.0121, -0.3713, -0.0374, -0.4466, -0.0922, -0.1319, -0.0737, -0.2150,\n",
      "        -0.1180, -0.0517, -0.0586, -0.1487, -0.1213, -0.0477,  0.0062,  0.0119,\n",
      "        -0.3816, -0.1589, -0.1980, -0.2936, -0.3203])\n",
      "F1 Score: tensor([-0.4141, -0.3522, -0.2203, -0.3238, -0.1027, -0.5806, -0.3866, -0.0426,\n",
      "        -0.1856, -0.1120, -0.0455, -0.0653, -0.1417, -0.1534, -0.2085,  0.0553,\n",
      "        -0.0256, -0.3330, -0.1109, -0.3602, -0.1248, -0.1444, -0.1441, -0.2024,\n",
      "        -0.1586, -0.0839, -0.0854, -0.1165, -0.1451, -0.0905, -0.1045, -0.1246,\n",
      "        -0.4617, -0.1944, -0.1947, -0.4240, -0.4191])\n"
     ]
    }
   ],
   "source": [
    "# 计算bertscore\n",
    "from bert_score import score\n",
    "\n",
    "references = [value[0] for value in compare_pair.values()]\n",
    "predictions =[value[1] for value in compare_pair.values()]\n",
    "\n",
    "# references = [\"I want to go to lunch.\"]\n",
    "# predictions = [\"I'd like to go to lunch.\"]\n",
    "\n",
    "P, R, F1 = score(predictions, references, lang=\"en\", rescale_with_baseline=True)\n",
    "\n",
    "print(f\"System level F1 score: {F1.mean():.3f}\")\n",
    "print(\"Precision:\", P)\n",
    "print(\"Recall:\", R)\n",
    "print(\"F1 Score:\", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System level F1 score: 0.798\n"
     ]
    }
   ],
   "source": [
    "print(f\"System level F1 score: {F1.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test Plan Details:\n",
      "```\n",
      "# Test Plan for PR: feat(commit-context): Allow committers from outside the org to be Suspect Committers\n",
      "\n",
      "## 1. Purpose\n",
      "The purpose of this test plan is to verify the functionality and correctness of allowing committers from outside the organization to be treated as Suspect Committers in the Sentry application. This involves validating changes made to handle both user and department committers, ensuring proper serialization and handling scenarios where both user and actor data might be null.\n",
      "\n",
      "## 2. Scope\n",
      "In Scope:\n",
      "- Changes to the serialization logic in `event_file_committers.py`, particularly handling committers who are not within the Sentry organization.\n",
      "- Modifications to the `Actor` and `GroupOwner` models to handle null scenarios and refine logic around users and teams.\n",
      "- Updates to the `handle_auto_assignment` method in `projectownership.py`, ensuring correct assignments are only made when valid owners are resolved.\n",
      "- Test cases related to new and modified unit tests found in `test_commit_context.py` and `test_organization_group_index.py`.\n",
      "\n",
      "Out of Scope:\n",
      "- Any functionality or modules outside of commit context and suspect committer identification, as well as integration tests beyond this functionality.\n",
      "\n",
      "## 3. Test Environment\n",
      "- Sentry application set up locally or in a staging environment with access to commit data and integration with GitHub.\n",
      "- A database with mock data for testing commit authors and their contexts, along with the ability to modify and observe Sentry's behavior on new commits.\n",
      "- Access to test frameworks (e.g., pytest) and mocking tools to execute unit tests.\n",
      "\n",
      "## 4. Test Cases\n",
      "### Component: Event File Committers\n",
      "- **Test Case ID**: TC01-EventFile-ExternalCommitter\n",
      "  - **Objective**: Validate serialization for committers without internal Sentry accounts.\n",
      "  - **Preconditions**: Committer data from a GitHub commit with an email not associated with a Sentry user.\n",
      "  - **Test Steps**:\n",
      "    1. Trigger the endpoint `event_file_committers.py` with an event linked to an external committer.\n",
      "    2. Verify the response for correct serialization, especially the \"author\" field.\n",
      "  - **Expected Results**: \n",
      "    - The author is returned with email as the sole identifier if there's no internal user.\n",
      "  - **Priority**: High\n",
      "\n",
      "### Component: Models - Actor and GroupOwner\n",
      "- **Test Case ID**: TC02-Actor-NullIdentifier\n",
      "  - **Objective**: Ensure `from_actor_identifier` handles null gracefully.\n",
      "  - **Preconditions**: None (Verify method against null actor_identifier).\n",
      "  - **Test Steps**:\n",
      "    1. Call `from_actor_identifier` with `None`.\n",
      "    2. Check that the return value is `None`.\n",
      "  - **Expected Results**: \n",
      "    - No exceptions; returns `None`.\n",
      "  - **Priority**: Medium\n",
      "\n",
      "- **Test Case ID**: TC03-GroupOwner-NullScenario\n",
      "  - **Objective**: Proper handling when both `user_id` and `team_id` are null.\n",
      "  - **Preconditions**: GroupOwner instance without team or user.\n",
      "  - **Test Steps**:\n",
      "    1. Save a GroupOwner with neither `user_id` nor `team_id`.\n",
      "    2. Verify the absence of exceptions or errors.\n",
      "  - **Expected Results**: \n",
      "    - Successfully handles null user and team.\n",
      "  - **Priority**: High\n",
      "\n",
      "### Component: Project Ownership\n",
      "- **Test Case ID**: TC04-AutoAssignment-ValidOwner\n",
      "  - **Objective**: Check auto-assignment logic when an owner is resolved.\n",
      "  - **Preconditions**: Owner resolve returns a valid entity.\n",
      "  - **Test Steps**:\n",
      "    1. Simulate auto-assignment process in `projectownership.py`.\n",
      "    2. Confirm `analytics.record()` is called for valid assignments.\n",
      "  - **Expected Results**: \n",
      "    - Assignments are only recorded when owners are valid.\n",
      "  - **Priority**: High\n",
      "\n",
      "### Component: Unit Tests\n",
      "- **Test Case ID**: TC05-UnitTest-CommitContext\n",
      "  - **Objective**: Ensure test method `test_commit_author_not_in_sentry` passes.\n",
      "  - **Preconditions**: Run with test framework access.\n",
      "  - **Test Steps**:\n",
      "    1. Execute new and layered test case in `test_commit_context.py`.\n",
      "    2. Observe results for assertion pass/fails.\n",
      "  - **Expected Results**: \n",
      "    - All assertions pass, confirming implementation correctness.\n",
      "  - **Priority**: High\n",
      "\n",
      "## Special Considerations\n",
      "- Test cases should account for integration with GitHub and mock responses as source environments might differ.\n",
      "- Consider potential impact on performance due to serialization changes.\n",
      "- Be aware of downstream effects on tools or scripts consuming unchanged components, ensuring backward compatibility.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "# 计算BLEU\n",
    "result_dir = \"result/backup-without-git-diff/InOut\"\n",
    "generate_test_plan_path = \"result/backup-without-git-diff/InOut/gpt-4o_claude-3-7-sonnet-20250219_result.json\"\n",
    "compare_pair = {}\n",
    "# 获取ref test plan以及 candidate test plan\n",
    "for repo in os.listdir(result_dir):\n",
    "    repo_dir = os.path.join(result_dir, repo)\n",
    "    if os.path.isdir(repo_dir):\n",
    "        PR_content_dir = os.path.join(repo_dir, \"PR-Content\")\n",
    "        if os.path.isdir(PR_content_dir):\n",
    "            PR_content_list = os.listdir(PR_content_dir)\n",
    "            for PR_content in PR_content_list:\n",
    "                pull_number = PR_content.split(\"_\")[0]\n",
    "                PR_content_file_dir = os.path.join(PR_content_dir, PR_content)\n",
    "                if os.path.isfile(PR_content_file_dir):\n",
    "                    with open(PR_content_file_dir, 'r') as f:\n",
    "                        PR_content_json = json.load(f)\n",
    "                    compare_pair[pull_number] = []\n",
    "                    compare_pair[pull_number].append(PR_content_json[\"Test_Plan\"])\n",
    "\n",
    "with open(generate_test_plan_path, 'r') as f:\n",
    "    gen_test_plan = json.load(f)\n",
    "\n",
    "for url in gen_test_plan:\n",
    "    pull_number = url.split(\"/\")[-1]\n",
    "    if pull_number in compare_pair:\n",
    "        compare_pair[pull_number].append(gen_test_plan[url][\"test_plan\"])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thought': 'I need to look at the implementation details of the `ReplayView` function, as the PR mentions changes related to how the replay video resizing happens when the browser window size changes. Understanding this implementation will enable me to generate comprehensive test cases tailored to the introduced changes.',\n",
       " 'action': 'search_function_in_project',\n",
       " 'action_param': {'function_name': 'ReplayView'},\n",
       " 'observation': 'cat not find the entity (class or function) in the project'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计工具的使用情况 适应另外一种格式的输出\n",
    "\n",
    "import os \n",
    "# 计算BLEU\n",
    "result_dir = \"./result/ReAct\"\n",
    "\n",
    "reacts = []\n",
    "# 获取ref test plan以及 candidate test plan\n",
    "for repo in os.listdir(result_dir):\n",
    "    repo_dir = os.path.join(result_dir, repo)\n",
    "    if os.path.isdir(repo_dir):\n",
    "        Test_plan_dir = os.path.join(repo_dir, \"Test-Plan\")\n",
    "        if os.path.isdir(Test_plan_dir):\n",
    "            Test_plan_list = os.listdir(Test_plan_dir)\n",
    "            for Test_plan in Test_plan_list:\n",
    "                if \"gpt-3.5-turbo\" in Test_plan:\n",
    "                    PR_content_file_dir = os.path.join(Test_plan_dir, Test_plan)\n",
    "                    pull_number = PR_content_file_dir.split(\"_\")[-1].split(\".\")[0]\n",
    "                    if os.path.isfile(PR_content_file_dir):\n",
    "                        with open(PR_content_file_dir, 'r') as f:\n",
    "                            PR_content_json = json.load(f)\n",
    "                        reacts.extend(PR_content_json[\"react_info\"][:-1])\n",
    "        scores_dir = os.path.join(repo_dir, \"scores\")\n",
    "        if os.path.isdir(scores_dir):\n",
    "            scores_list_dir = os.listdir(scores_dir)\n",
    "            for score_file in scores_list_dir:\n",
    "                if 'gpt-3.5-turbo' in score_file:\n",
    "                    score_file_path = os.path.join(scores_dir, score_file)\n",
    "                    # print(score_file_path)\n",
    "                    pull_number = score_file_path.split(\"_\")[-1].split(\".\")[0]\n",
    "                    with open(score_file_path, 'r') as f: \n",
    "                        score = json.load(f)\n",
    "                        reacts.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'search_function_in_project': {'number': 56, 'observation': ['cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"error\": \"Entity \\'get\\' exists but has invalid structure\"}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def save(self, commit=True):\\\\n        user = super().save(commit=False)\\\\n        user.set_password(self.cleaned_data[\\\\\"password\\\\\"])\\\\n        if commit:\\\\n            user.save()\\\\n            if self.cleaned_data.get(\\\\\"subscribe\\\\\"):\\\\n                newsletter.backend.create_or_update_subscriptions(\\\\n                    user, list_ids=newsletter.backend.get_default_list_ids()\\\\n                )\\\\n            if self.cleaned_data.get(\\\\\"timezone\\\\\"):\\\\n                UserOption.objects.create(\\\\n                    user=user, key=\\\\\"timezone\\\\\", value=self.cleaned_data.get(\\\\\"timezone\\\\\")\\\\n                )\\\\n        return user\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/web/forms/accounts.py\", \"line\": [231, 244], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def owner():\\\\n    return Factories.create_user()\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/tasks/test_statistical_detectors.py\", \"line\": [59, 60], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def send_and_save_sentry_app_request(\\\\n    url: str,\\\\n    sentry_app: SentryApp | RpcSentryApp,\\\\n    org_id: int,\\\\n    event: str,\\\\n    **kwargs: Any,\\\\n) -> Response:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Send a webhook request, and save the request into the Redis buffer for the\\\\n    app dashboard request log. Returns the response of the request.\\\\n\\\\n    kwargs ends up being the arguments passed into safe_urlopen\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    with SentryAppInteractionEvent(\\\\n        operation_type=SentryAppInteractionType.EXTERNAL_REQUEST,\\\\n        event_type=SentryAppEventType(event),\\\\n    ).capture() as lifecycle:\\\\n        buffer = SentryAppWebhookRequestsBuffer(sentry_app)\\\\n        slug = sentry_app.slug_for_metrics\\\\n\\\\n        try:\\\\n            resp = safe_urlopen(url=url, **kwargs)\\\\n        except (Timeout, ConnectionError) as e:\\\\n            error_type = e.__class__.__name__.lower()\\\\n            lifecycle.add_extras(\\\\n                {\\\\n                    \\\\\"reason\\\\\": \\\\\"send_and_save_sentry_app_request.timeout\\\\\",\\\\n                    \\\\\"error_type\\\\\": error_type,\\\\n                    \\\\\"organization_id\\\\\": org_id,\\\\n                    \\\\\"integration_slug\\\\\": sentry_app.slug,\\\\n                    \\\\\"url\\\\\": url,\\\\n                },\\\\n            )\\\\n            track_response_code(error_type, slug, event)\\\\n            buffer.add_request(\\\\n                response_code=TIMEOUT_STATUS_CODE,\\\\n                org_id=org_id,\\\\n                event=event,\\\\n                url=url,\\\\n                headers=kwargs.get(\\\\\"headers\\\\\"),\\\\n            )\\\\n            lifecycle.record_halt(e)\\\\n            # Re-raise the exception because some of these tasks might retry on the exception\\\\n            raise\\\\n\\\\n        track_response_code(resp.status_code, slug, event)\\\\n        buffer.add_request(\\\\n            response_code=resp.status_code,\\\\n            org_id=org_id,\\\\n            event=event,\\\\n            url=url,\\\\n            error_id=resp.headers.get(\\\\\"Sentry-Hook-Error\\\\\"),\\\\n            project_id=resp.headers.get(\\\\\"Sentry-Hook-Project\\\\\"),\\\\n            response=resp,\\\\n            headers=kwargs.get(\\\\\"headers\\\\\"),\\\\n        )\\\\n        try:\\\\n            resp.raise_for_status()\\\\n        except RequestException as e:\\\\n            lifecycle.record_halt(e)\\\\n            raise\\\\n        return resp\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/sentry_apps/external_requests/utils.py\", \"line\": [57, 119], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def send_and_save_webhook_request(\\\\n    sentry_app: SentryApp | RpcSentryApp,\\\\n    app_platform_event: AppPlatformEvent,\\\\n    url: str | None = None,\\\\n) -> Response:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Notify a SentryApp\\'s webhook about an incident and log response on redis.\\\\n\\\\n    :param sentry_app: The SentryApp to notify via a webhook.\\\\n    :param app_platform_event: Incident data. See AppPlatformEvent.\\\\n    :param url: The URL to hit for this webhook if it is different from `sentry_app.webhook_url`.\\\\n    :return: Webhook response\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    from sentry.sentry_apps.metrics import SentryAppInteractionEvent, SentryAppInteractionType\\\\n\\\\n    try:\\\\n        event = SentryAppEventType(f\\\\\"{app_platform_event.resource}.{app_platform_event.action}\\\\\")\\\\n    except ValueError as e:\\\\n        raise SentryAppSentryError(\\\\n            message=f\\\\\"{SentryAppWebhookFailureReason.INVALID_EVENT}\\\\\",\\\\n        ) from e\\\\n\\\\n    with SentryAppInteractionEvent(\\\\n        operation_type=SentryAppInteractionType.SEND_WEBHOOK, event_type=event\\\\n    ).capture() as lifecycle:\\\\n        buffer = SentryAppWebhookRequestsBuffer(sentry_app)\\\\n        org_id = app_platform_event.install.organization_id\\\\n        slug = sentry_app.slug_for_metrics\\\\n        url = url or sentry_app.webhook_url\\\\n        lifecycle.add_extras(\\\\n            {\\\\n                \\\\\"org_id\\\\\": org_id,\\\\n                \\\\\"sentry_app_slug\\\\\": sentry_app.slug,\\\\n                \\\\\"url\\\\\": url or \\\\\"\\\\\",\\\\n                \\\\\"event\\\\\": event,\\\\n                \\\\\"installation_uuid\\\\\": app_platform_event.install.uuid,\\\\n            }\\\\n        )\\\\n\\\\n        assert url is not None\\\\n        try:\\\\n            response = safe_urlopen(\\\\n                url=url,\\\\n                data=app_platform_event.body,\\\\n                headers=app_platform_event.headers,\\\\n                timeout=options.get(\\\\\"sentry-apps.webhook.timeout.sec\\\\\"),\\\\n            )\\\\n        except (Timeout, ConnectionError) as e:\\\\n            error_type = e.__class__.__name__.lower()\\\\n            lifecycle.add_extras(\\\\n                {\\\\n                    \\\\\"reason\\\\\": \\\\\"send_and_save_webhook_request.timeout\\\\\",\\\\n                    \\\\\"error_type\\\\\": error_type,\\\\n                    \\\\\"organization_id\\\\\": org_id,\\\\n                    \\\\\"integration_slug\\\\\": sentry_app.slug,\\\\n                    \\\\\"url\\\\\": url,\\\\n                },\\\\n            )\\\\n            track_response_code(error_type, slug, event)\\\\n            buffer.add_request(\\\\n                response_code=TIMEOUT_STATUS_CODE,\\\\n                org_id=org_id,\\\\n                event=event,\\\\n                url=url,\\\\n                headers=app_platform_event.headers,\\\\n            )\\\\n            record_timeout(sentry_app, org_id, e)\\\\n            lifecycle.record_halt(e)\\\\n            # Re-raise the exception because some of these tasks might retry on the exception\\\\n            raise\\\\n\\\\n        track_response_code(response.status_code, slug, event)\\\\n        buffer.add_request(\\\\n            response_code=response.status_code,\\\\n            org_id=org_id,\\\\n            event=event,\\\\n            url=url,\\\\n            error_id=response.headers.get(\\\\\"Sentry-Hook-Error\\\\\"),\\\\n            project_id=response.headers.get(\\\\\"Sentry-Hook-Project\\\\\"),\\\\n            response=response,\\\\n            headers=app_platform_event.headers,\\\\n        )\\\\n        # we don\\'t disable alert rules for internal integrations\\\\n        # so we don\\'t want to consider responses related to them\\\\n        # for the purpose of disabling integrations\\\\n        if app_platform_event.action != \\\\\"event.alert\\\\\":\\\\n            record_response_for_disabling_integration(sentry_app, org_id, response)\\\\n\\\\n        if response.status_code == status.HTTP_503_SERVICE_UNAVAILABLE:\\\\n            lifecycle.record_halt(\\\\n                halt_reason=f\\\\\"send_and_save_webhook_request.{SentryAppWebhookHaltReason.INTEGRATOR_ERROR}\\\\\"\\\\n            )\\\\n            raise ApiHostError.from_request(response.request)\\\\n\\\\n        elif response.status_code == status.HTTP_504_GATEWAY_TIMEOUT:\\\\n            lifecycle.record_halt(\\\\n                halt_reason=f\\\\\"send_and_save_webhook_request.{SentryAppWebhookHaltReason.INTEGRATOR_ERROR}\\\\\"\\\\n            )\\\\n            raise ApiTimeoutError.from_request(response.request)\\\\n\\\\n        elif 400 <= response.status_code < 500:\\\\n            lifecycle.record_halt(\\\\n                halt_reason=f\\\\\"send_and_save_webhook_request.{SentryAppWebhookHaltReason.GOT_CLIENT_ERROR}_{response.status_code}\\\\\"\\\\n            )\\\\n            raise ClientError(response.status_code, url, response=response)\\\\n\\\\n        try:\\\\n            response.raise_for_status()\\\\n        except RequestException as e:\\\\n            lifecycle.record_halt(e)\\\\n            raise\\\\n        return response\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/utils/sentry_apps/webhooks.py\", \"line\": [137, 248], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def send_incident_alert_notification(\\\\n    action: AlertRuleTriggerAction,\\\\n    incident: Incident,\\\\n    metric_value: float | int | None,\\\\n    new_status: IncidentStatus,\\\\n    notification_uuid: str | None = None,\\\\n) -> bool:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    When a metric alert is triggered, send incident data to the SentryApp\\'s webhook.\\\\n    :param action: The triggered `AlertRuleTriggerAction`.\\\\n    :param incident: The `Incident` for which to build a payload.\\\\n    :param metric_value: The value of the metric that triggered this alert to\\\\n    fire.\\\\n    :return:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    organization = serialize_rpc_organization(incident.organization)\\\\n    incident_attachment = build_incident_attachment(\\\\n        incident, new_status, metric_value, notification_uuid\\\\n    )\\\\n\\\\n    success = integration_service.send_incident_alert_notification(\\\\n        sentry_app_id=action.sentry_app_id,\\\\n        action_id=action.id,\\\\n        incident_id=incident.id,\\\\n        organization_id=organization.id,\\\\n        new_status=new_status.value,\\\\n        incident_attachment_json=json.dumps(incident_attachment),\\\\n        metric_value=metric_value,\\\\n    )\\\\n    return success\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/rules/actions/notify_event_service.py\", \"line\": [69, 98], \"kind\": \"def\"}}', '{\"error\": \"Entity \\'get\\' exists but has invalid structure\"}', '{\"error\": \"Entity \\'get\\' exists but has invalid structure\"}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def auth_provider_settings_form(provider, auth_provider, organization, request):\\\\n    class AuthProviderSettingsForm(forms.Form):\\\\n        disabled = provider.is_partner\\\\n        require_link = forms.BooleanField(\\\\n            label=_(\\\\\"Require SSO\\\\\"),\\\\n            help_text=_(\\\\n                \\\\\"Require members use a valid linked SSO account to access this organization\\\\\"\\\\n            ),\\\\n            required=False,\\\\n            disabled=disabled,\\\\n        )\\\\n\\\\n        enable_scim = (\\\\n            forms.BooleanField(\\\\n                label=_(\\\\\"Enable SCIM\\\\\"),\\\\n                help_text=_(\\\\\"Enable SCIM to manage Memberships and Teams via your Provider\\\\\"),\\\\n                required=False,\\\\n                disabled=disabled,\\\\n            )\\\\n            if provider.can_use_scim(organization.id, request.user)\\\\n            else None\\\\n        )\\\\n\\\\n        default_role = forms.ChoiceField(\\\\n            label=_(\\\\\"Default Role\\\\\"),\\\\n            choices=roles.get_choices(),\\\\n            help_text=_(\\\\n                \\\\\"The default role new members will receive when logging in for the first time.\\\\\"\\\\n            ),\\\\n            disabled=disabled,\\\\n        )\\\\n\\\\n        if provider.is_saml and provider.name != \\\\\"SAML2\\\\\":\\\\n            # Generic SAML2 provider already includes the certificate field in it\\'s own configure view\\\\n            x509cert = forms.CharField(\\\\n                label=\\\\\"x509 public certificate\\\\\",\\\\n                widget=forms.Textarea,\\\\n                help_text=_(\\\\\"The SAML certificate for your Identity Provider\\\\\"),\\\\n                required=False,\\\\n                disabled=disabled,\\\\n            )\\\\n\\\\n    initial = {\\\\n        \\\\\"require_link\\\\\": not auth_provider.flags.allow_unlinked,\\\\n        \\\\\"default_role\\\\\": organization.default_role,\\\\n    }\\\\n    if provider.can_use_scim(organization.id, request.user):\\\\n        initial[\\\\\"enable_scim\\\\\"] = bool(auth_provider.flags.scim_enabled)\\\\n\\\\n    if provider.is_saml:\\\\n        initial_idp = auth_provider.config.get(\\\\\"idp\\\\\", {})\\\\n        certificate = initial_idp.get(\\\\\"x509cert\\\\\", \\\\\"\\\\\")\\\\n        initial[\\\\\"x509cert\\\\\"] = certificate\\\\n\\\\n    form = AuthProviderSettingsForm(\\\\n        data=request.POST if request.POST.get(\\\\\"op\\\\\") == \\\\\"settings\\\\\" else None, initial=initial\\\\n    )\\\\n\\\\n    return form\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/web/frontend/organization_auth_settings.py\", \"line\": [35, 93], \"kind\": \"def\"}}', '{\"error\": \"Entity \\'get\\' exists but has invalid structure\"}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def handle_existing_provider(\\\\n        self, request: HttpRequest, organization: RpcOrganization, auth_provider: RpcAuthProvider\\\\n    ):\\\\n        provider = auth_provider.get_provider()\\\\n\\\\n        if request.method == \\\\\"POST\\\\\":\\\\n            if provider.is_partner:\\\\n                return HttpResponse(\\\\\"Can\\'t disable partner authentication provider\\\\\", status=405)\\\\n\\\\n            op = request.POST.get(\\\\\"op\\\\\")\\\\n            if op == \\\\\"disable\\\\\":\\\\n                self._disable_provider(request, organization, auth_provider)\\\\n\\\\n                messages.add_message(request, messages.SUCCESS, OK_PROVIDER_DISABLED)\\\\n\\\\n                next_uri = f\\\\\"/settings/{organization.slug}/auth/\\\\\"\\\\n                return self.redirect(next_uri)\\\\n            elif op == \\\\\"reinvite\\\\\":\\\\n                email_missing_links_control.delay(organization.id, request.user.id, provider.key)\\\\n\\\\n                messages.add_message(request, messages.SUCCESS, OK_REMINDERS_SENT)\\\\n\\\\n                next_uri = reverse(\\\\n                    \\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug]\\\\n                )\\\\n                return self.redirect(next_uri)\\\\n\\\\n        form = auth_provider_settings_form(provider, auth_provider, organization, request)\\\\n\\\\n        if form.is_valid():\\\\n            allow_unlinked = not form.cleaned_data[\\\\\"require_link\\\\\"]\\\\n            form_scim_enabled = form.cleaned_data.get(\\\\\"enable_scim\\\\\", False)\\\\n            auth_service.change_scim(\\\\n                provider_id=auth_provider.id,\\\\n                user_id=request.user.id,\\\\n                enabled=form_scim_enabled,\\\\n                allow_unlinked=allow_unlinked,\\\\n            )\\\\n\\\\n            organization = organization_service.update_default_role(\\\\n                organization_id=organization.id, default_role=form.cleaned_data[\\\\\"default_role\\\\\"]\\\\n            )\\\\n\\\\n            if form.initial != form.cleaned_data:\\\\n                changed_data = {}\\\\n                for key, value in form.cleaned_data.items():\\\\n                    if key == \\\\\"x509cert\\\\\":\\\\n                        original_idp = auth_provider.config.get(\\\\\"idp\\\\\", {})\\\\n                        if original_idp.get(\\\\\"x509cert\\\\\", \\\\\"\\\\\") != value:\\\\n                            auth_provider.config = {\\\\n                                **auth_provider.config,\\\\n                                \\\\\"idp\\\\\": {\\\\n                                    **original_idp,\\\\n                                    \\\\\"x509cert\\\\\": value,\\\\n                                },\\\\n                            }\\\\n                            auth_service.update_provider_config(\\\\n                                organization_id=organization.id,\\\\n                                auth_provider_id=auth_provider.id,\\\\n                                config=auth_provider.config,\\\\n                            )\\\\n                            changed_data[\\\\\"x509cert\\\\\"] = f\\\\\"to {value}\\\\\"\\\\n                    elif form.initial.get(key) != value:\\\\n                        changed_data[key] = f\\\\\"to {value}\\\\\"\\\\n\\\\n                self.create_audit_entry(\\\\n                    request,\\\\n                    organization=organization,\\\\n                    target_object=auth_provider.id,\\\\n                    event=audit_log.get_event_id(\\\\\"SSO_EDIT\\\\\"),\\\\n                    data=changed_data,\\\\n                )\\\\n\\\\n        view = provider.get_configure_view()\\\\n        response = view(request, organization, auth_provider)\\\\n        if isinstance(response, DeferredResponse):\\\\n            response = response.render(\\\\n                request,\\\\n                {\\\\n                    \\\\\"auth_provider\\\\\": auth_provider,\\\\n                    \\\\\"organization\\\\\": organization,\\\\n                    \\\\\"provider\\\\\": provider,\\\\n                },\\\\n            )\\\\n\\\\n        pending_links_count = organization_service.count_members_without_sso(\\\\n            organization_id=organization.id\\\\n        )\\\\n        context = {\\\\n            \\\\\"form\\\\\": form,\\\\n            \\\\\"pending_links_count\\\\\": pending_links_count,\\\\n            \\\\\"login_url\\\\\": organization.absolute_url(Organization.get_url(organization.slug)),\\\\n            \\\\\"settings_url\\\\\": organization.absolute_url(\\\\n                reverse(\\\\\"sentry-organization-settings\\\\\", args=[organization.slug])\\\\n            ),\\\\n            \\\\\"auth_provider\\\\\": auth_provider,\\\\n            \\\\\"provider_name\\\\\": provider.name,\\\\n            \\\\\"scim_api_token\\\\\": auth_provider.get_scim_token(),\\\\n            \\\\\"scim_url\\\\\": get_scim_url(auth_provider, organization),\\\\n            \\\\\"content\\\\\": response,\\\\n            \\\\\"disabled\\\\\": provider.is_partner,\\\\n        }\\\\n\\\\n        return self.respond(\\\\\"sentry/organization-auth-provider-settings.html\\\\\", context)\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/web/frontend/organization_auth_settings.py\", \"line\": [123, 226], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"__init__\\\\nvalidate\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop/admin/securedrop_admin/__init__.py\", \"line\": [234, 248], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"        def get_translations(self) -> Set[str]:\\\\n            translations = I18N_DEFAULT_LOCALES\\\\n            for dirname in os.listdir(self.translation_dir):\\\\n                if dirname != \\\\\"messages.pot\\\\\":\\\\n                    translations.add(dirname)\\\\n            return translations\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop/admin/securedrop_admin/__init__.py\", \"line\": [227, 232], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"        def call_api(self, api_client, session):\\\\n            return_value = next(self.return_value)\\\\n            if isinstance(return_value, Exception):\\\\n                raise return_value\\\\n            else:\\\\n                return return_value\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/factory.py\", \"line\": [160, 165], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def load(cls) -> \\\\\"Config\\\\\":\\\\n        \\\\\"\\\\\"\\\\\"For each attribute, look it up from either QubesDB or the environment.\\\\\"\\\\\"\\\\\"\\\\n        config = {}\\\\n\\\\n        with try_qubesdb() as db:\\\\n            for field in fields(cls):\\\\n                lookup = cls.mapping[field.name]\\\\n                if db:\\\\n                    logger.debug(f\\\\\"Reading {lookup} from QubesDB\\\\\")\\\\n                    value = db.read(f\\\\\"/vm-config/{lookup}\\\\\")\\\\n                    if not value or len(value) == 0:\\\\n                        if field.default == MISSING:\\\\n                            raise KeyError(f\\\\\"Could not read {lookup} from QubesDB\\\\\")\\\\n                        # Normalize for parity with the case where os.environ.get() is None\\\\n                        value = None\\\\n                else:\\\\n                    logger.debug(f\\\\\"Reading {lookup} from environment\\\\\")\\\\n                    value = os.environ.get(lookup)\\\\n                    if not value or len(value) == 0:\\\\n                        # Same normalization used for QubesDB\\\\n                        value = None\\\\n\\\\n                if value is None and field.default != MISSING:\\\\n                    logger.debug(f\\\\\"Using default value for {lookup}\\\\\")\\\\n                    value = field.default\\\\n\\\\n                # Cast to int if needed (might raise if value is invalid)\\\\n                # TODO: in theory we could `field.type(value)` but that doesn\\'t\\\\n                # handle union types\\\\n                if field.type is int:\\\\n                    value = int(value)\\\\n                config[field.name] = value\\\\n\\\\n        return cls(**config)\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/securedrop_client/config.py\", \"line\": [51, 84], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"error\": \"Entity \\'__init__\\' exists but has invalid structure\"}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def read(self) -> bytes:\\\\n        \\\\\"\\\\\"\\\\\"Read available data over the socket.\\\\\"\\\\\"\\\\\"\\\\n        if not self._sock:\\\\n            return bytes()\\\\n        ret = self._sock.recv(MAX_BUF)\\\\n        if len(ret) == 0:\\\\n            # The socket connection died! Just reconnect to the server.\\\\n            self._reconnect()\\\\n        LOG.debug(f\\\\\"Received [{len(ret)}] bytes\\\\\")\\\\n        return ret\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/usb-bridge/ot3usb/tcp_conn.py\", \"line\": [73, 82], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def read(self) -> bytes:\\\\n        \\\\\"\\\\\"\\\\\"Read available data over the socket.\\\\\"\\\\\"\\\\\"\\\\n        if not self._sock:\\\\n            return bytes()\\\\n        ret = self._sock.recv(MAX_BUF)\\\\n        if len(ret) == 0:\\\\n            # The socket connection died! Just reconnect to the server.\\\\n            self._reconnect()\\\\n        LOG.debug(f\\\\\"Received [{len(ret)}] bytes\\\\\")\\\\n        return ret\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/usb-bridge/ot3usb/tcp_conn.py\", \"line\": [73, 82], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def _transform_profile_element(\\\\n    element: Union[ProfileStep, ProfileCycle],\\\\n    thermocycler_state: ThermocyclerModuleSubState,\\\\n) -> Union[ThermocyclerStep, ThermocyclerCycle]:\\\\n    if isinstance(element, ProfileStep):\\\\n        return _transform_profile_step(element, thermocycler_state)\\\\n    else:\\\\n        return ThermocyclerCycle(\\\\n            steps=[\\\\n                _transform_profile_step(step, thermocycler_state)\\\\n                for step in element.steps\\\\n            ],\\\\n            repetitions=element.repetitions,\\\\n        )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocol_engine/commands/thermocycler/run_extended_profile.py\", \"line\": [88, 101], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def _transform_profile_element(\\\\n    element: Union[ProfileStep, ProfileCycle],\\\\n    thermocycler_state: ThermocyclerModuleSubState,\\\\n) -> Union[ThermocyclerStep, ThermocyclerCycle]:\\\\n    if isinstance(element, ProfileStep):\\\\n        return _transform_profile_step(element, thermocycler_state)\\\\n    else:\\\\n        return ThermocyclerCycle(\\\\n            steps=[\\\\n                _transform_profile_step(step, thermocycler_state)\\\\n                for step in element.steps\\\\n            ],\\\\n            repetitions=element.repetitions,\\\\n        )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocol_engine/commands/thermocycler/run_extended_profile.py\", \"line\": [88, 101], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def install(\\\\n    venv_dir: Optional[Path],\\\\n    package_names: Optional[List[str]],\\\\n    package_specs: List[str],\\\\n    local_bin_dir: Path,\\\\n    local_man_dir: Path,\\\\n    python: Optional[str],\\\\n    pip_args: List[str],\\\\n    venv_args: List[str],\\\\n    verbose: bool,\\\\n    *,\\\\n    force: bool,\\\\n    reinstall: bool,\\\\n    include_dependencies: bool,\\\\n    preinstall_packages: Optional[List[str]],\\\\n    suffix: str = \\\\\"\\\\\",\\\\n    python_flag_passed=False,\\\\n) -> ExitCode:\\\\n    \\\\\"\\\\\"\\\\\"Returns pipx exit code.\\\\\"\\\\\"\\\\\"\\\\n    # package_spec is anything pip-installable, including package_name, vcs spec,\\\\n    #   zip file, or tar.gz file.\\\\n\\\\n    python = python or DEFAULT_PYTHON\\\\n\\\\n    package_names = package_names or []\\\\n    if len(package_names) != len(package_specs):\\\\n        package_names = [\\\\n            package_name_from_spec(package_spec, python, pip_args=pip_args, verbose=verbose)\\\\n            for package_spec in package_specs\\\\n        ]\\\\n\\\\n    for package_name, package_spec in zip(package_names, package_specs):\\\\n        if venv_dir is None:\\\\n            venv_container = VenvContainer(paths.ctx.venvs)\\\\n            venv_dir = venv_container.get_venv_dir(f\\\\\"{package_name}{suffix}\\\\\")\\\\n\\\\n        try:\\\\n            exists = venv_dir.exists() and bool(next(venv_dir.iterdir()))\\\\n        except StopIteration:\\\\n            exists = False\\\\n\\\\n        venv = Venv(venv_dir, python=python, verbose=verbose)\\\\n        venv.check_upgrade_shared_libs(pip_args=pip_args, verbose=verbose)\\\\n        if exists:\\\\n            if not reinstall and force and python_flag_passed:\\\\n                print(\\\\n                    pipx_wrap(\\\\n                        f\\\\\"\\\\\"\\\\\"\\\\n                        --python is ignored when --force is passed.\\\\n                        If you want to reinstall {package_name} with {python},\\\\n                        run `pipx reinstall {package_spec} --python {python}` instead.\\\\n                        \\\\\"\\\\\"\\\\\"\\\\n                    )\\\\n                )\\\\n            if force:\\\\n                print(f\\\\\"Installing to existing venv {venv.name!r}\\\\\")\\\\n                pip_args = [\\\\\"--force-reinstall\\\\\"] + pip_args\\\\n            else:\\\\n                print(\\\\n                    pipx_wrap(\\\\n                        f\\\\\"\\\\\"\\\\\"\\\\n                        {venv.name!r} already seems to be installed. Not modifying\\\\n                        existing installation in \\'{venv_dir}\\'. Pass \\'--force\\'\\\\n                        to force installation.\\\\n                        \\\\\"\\\\\"\\\\\"\\\\n                    )\\\\n                )\\\\n                if len(package_specs) == 1:\\\\n                    return EXIT_CODE_INSTALL_VENV_EXISTS\\\\n                # Reset venv_dir to None ready to install the next package in the list\\\\n                venv_dir = None\\\\n                continue\\\\n\\\\n        try:\\\\n            # Enable installing shared library `pip` with `pipx`\\\\n            override_shared = package_name == \\\\\"pip\\\\\"\\\\n            venv.create_venv(venv_args, pip_args, override_shared)\\\\n            for dep in preinstall_packages or []:\\\\n                venv.upgrade_package_no_metadata(dep, [])\\\\n            venv.install_package(\\\\n                package_name=package_name,\\\\n                package_or_url=package_spec,\\\\n                pip_args=pip_args,\\\\n                include_dependencies=include_dependencies,\\\\n                include_apps=True,\\\\n                is_main_package=True,\\\\n                suffix=suffix,\\\\n            )\\\\n            run_post_install_actions(\\\\n                venv,\\\\n                package_name,\\\\n                local_bin_dir,\\\\n                local_man_dir,\\\\n                venv_dir,\\\\n                include_dependencies,\\\\n                force=force,\\\\n            )\\\\n        except (Exception, KeyboardInterrupt):\\\\n            print()\\\\n            venv.remove_venv()\\\\n            raise\\\\n\\\\n        # Reset venv_dir to None ready to install the next package in the list\\\\n        venv_dir = None\\\\n\\\\n    # Any failure to install will raise PipxError, otherwise success\\\\n    return EXIT_CODE_OK\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/install.py\", \"line\": [20, 126], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def reinstall(\\\\n    *,\\\\n    venv_dir: Path,\\\\n    local_bin_dir: Path,\\\\n    local_man_dir: Path,\\\\n    python: str,\\\\n    verbose: bool,\\\\n    force_reinstall_shared_libs: bool = False,\\\\n    python_flag_passed: bool = False,\\\\n) -> ExitCode:\\\\n    \\\\\"\\\\\"\\\\\"Returns pipx exit code.\\\\\"\\\\\"\\\\\"\\\\n    if not venv_dir.exists():\\\\n        print(f\\\\\"Nothing to reinstall for {venv_dir.name} {sleep}\\\\\")\\\\n        return EXIT_CODE_REINSTALL_VENV_NONEXISTENT\\\\n\\\\n    try:\\\\n        Path(python).relative_to(venv_dir)\\\\n    except ValueError:\\\\n        pass\\\\n    else:\\\\n        print(\\\\n            f\\\\\"{error} Error, the python executable would be deleted!\\\\\",\\\\n            \\\\\"Change it using the --python option or PIPX_DEFAULT_PYTHON environment variable.\\\\\",\\\\n        )\\\\n        return EXIT_CODE_REINSTALL_INVALID_PYTHON\\\\n\\\\n    venv = Venv(venv_dir, verbose=verbose)\\\\n    venv.check_upgrade_shared_libs(\\\\n        pip_args=venv.pipx_metadata.main_package.pip_args, verbose=verbose, force_upgrade=force_reinstall_shared_libs\\\\n    )\\\\n\\\\n    if venv.pipx_metadata.main_package.package_or_url is not None:\\\\n        package_or_url = venv.pipx_metadata.main_package.package_or_url\\\\n    else:\\\\n        package_or_url = venv.main_package_name\\\\n\\\\n    uninstall(venv_dir, local_bin_dir, local_man_dir, verbose)\\\\n\\\\n    # in case legacy original dir name\\\\n    venv_dir = venv_dir.with_name(canonicalize_name(venv_dir.name))\\\\n\\\\n    # install main package first\\\\n    install(\\\\n        venv_dir,\\\\n        [venv.main_package_name],\\\\n        [package_or_url],\\\\n        local_bin_dir,\\\\n        local_man_dir,\\\\n        python,\\\\n        venv.pipx_metadata.main_package.pip_args,\\\\n        venv.pipx_metadata.venv_args,\\\\n        verbose,\\\\n        force=True,\\\\n        reinstall=True,\\\\n        include_dependencies=venv.pipx_metadata.main_package.include_dependencies,\\\\n        preinstall_packages=[],\\\\n        suffix=venv.pipx_metadata.main_package.suffix,\\\\n        python_flag_passed=python_flag_passed,\\\\n    )\\\\n\\\\n    # now install injected packages\\\\n    for injected_name, injected_package in venv.pipx_metadata.injected_packages.items():\\\\n        if injected_package.package_or_url is None:\\\\n            # This should never happen, but package_or_url is type\\\\n            #   Optional[str] so mypy thinks it could be None\\\\n            raise PipxError(f\\\\\"Internal Error injecting package {injected_package} into {venv.name}\\\\\")\\\\n        inject_dep(\\\\n            venv_dir,\\\\n            injected_name,\\\\n            injected_package.package_or_url,\\\\n            injected_package.pip_args,\\\\n            verbose=verbose,\\\\n            include_apps=injected_package.include_apps,\\\\n            include_dependencies=injected_package.include_dependencies,\\\\n            force=True,\\\\n        )\\\\n\\\\n    # Any failure to install will raise PipxError, otherwise success\\\\n    return EXIT_CODE_OK\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/reinstall.py\", \"line\": [21, 99], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"    def upgrade_package_no_metadata(self, package_name: str, pip_args: List[str]) -> None:\\\\n        logger.info(\\\\\"Upgrading %s\\\\\", package_descr := full_package_description(package_name, package_name))\\\\n        with animate(f\\\\\"upgrading {package_descr}\\\\\", self.do_animation):\\\\n            pip_process = self._run_pip([\\\\\"--no-input\\\\\", \\\\\"install\\\\\"] + pip_args + [\\\\\"--upgrade\\\\\", package_name])\\\\n        subprocess_post_check(pip_process)\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/venv.py\", \"line\": [441, 445], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def use_emojis() -> bool:\\\\n    # All emojis that pipx might possibly use\\\\n    emoji_test_str = \\\\\"\\\\u2728\\\\ud83c\\\\udf1f\\\\u26a0\\\\ufe0f\\\\ud83d\\\\ude34\\\\u28f7\\\\u28ef\\\\u28df\\\\u287f\\\\u28bf\\\\u28fb\\\\u28fd\\\\u28fe\\\\\"\\\\n    try:\\\\n        emoji_test_str.encode(sys.stderr.encoding)\\\\n        platform_emoji_support = True\\\\n    except UnicodeEncodeError:\\\\n        platform_emoji_support = False\\\\n    use_emoji = os.getenv(\\\\\"PIPX_USE_EMOJI\\\\\")\\\\n    if use_emoji is None:\\\\n        use_emoji = str(os.getenv(\\\\\"USE_EMOJI\\\\\", platform_emoji_support))\\\\n    return strtobool(use_emoji)\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/emojis.py\", \"line\": [15, 26], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def run_pipx_command(args: argparse.Namespace, subparsers: Dict[str, argparse.ArgumentParser]) -> ExitCode:  # noqa: C901\\\\n    verbose = args.verbose if \\\\\"verbose\\\\\" in args else False\\\\n\\\\n    pip_args = get_pip_args(vars(args))\\\\n    venv_args = get_venv_args(vars(args))\\\\n\\\\n    venv_container = VenvContainer(paths.ctx.venvs)\\\\n\\\\n    if \\\\\"package\\\\\" in args:\\\\n        package = args.package\\\\n        package_is_url(package)\\\\n        package_is_path(package)\\\\n\\\\n        if \\\\\"spec\\\\\" in args and args.spec is not None:\\\\n            if package_is_url(args.spec, raise_error=False):\\\\n                if \\\\\"#egg=\\\\\" not in args.spec:\\\\n                    args.spec = args.spec + f\\\\\"#egg={package}\\\\\"\\\\n\\\\n        venv_dir = venv_container.get_venv_dir(package)\\\\n        logger.info(f\\\\\"Virtual Environment location is {venv_dir}\\\\\")\\\\n\\\\n    if \\\\\"packages\\\\\" in args:\\\\n        for package in args.packages:\\\\n            package_is_url(package)\\\\n            package_is_path(package)\\\\n        venv_dirs = {package: venv_container.get_venv_dir(package) for package in args.packages}\\\\n        venv_dirs_msg = \\\\\"\\\\\\\\n\\\\\".join(f\\\\\"- {key} : {value}\\\\\" for key, value in venv_dirs.items())\\\\n        logger.info(f\\\\\"Virtual Environment locations are:\\\\\\\\n{venv_dirs_msg}\\\\\")\\\\n\\\\n    if \\\\\"skip\\\\\" in args:\\\\n        skip_list = [canonicalize_name(x) for x in args.skip]\\\\n\\\\n    python_flag_passed = False\\\\n\\\\n    if \\\\\"python\\\\\" in args:\\\\n        python_flag_passed = bool(args.python)\\\\n        fetch_missing_python = args.fetch_missing_python\\\\n        try:\\\\n            interpreter = find_python_interpreter(\\\\n                args.python or DEFAULT_PYTHON, fetch_missing_python=fetch_missing_python\\\\n            )\\\\n            args.python = interpreter\\\\n        except InterpreterResolutionError as e:\\\\n            logger.debug(\\\\\"Failed to resolve interpreter:\\\\\", exc_info=True)\\\\n            print(\\\\n                pipx_wrap(\\\\n                    f\\\\\"{hazard} {e}\\\\\",\\\\n                    subsequent_indent=\\\\\" \\\\\" * 4,\\\\n                )\\\\n            )\\\\n            return EXIT_CODE_SPECIFIED_PYTHON_EXECUTABLE_NOT_FOUND\\\\n\\\\n    if args.command == \\\\\"run\\\\\":\\\\n        commands.run(\\\\n            args.app_with_args[0],\\\\n            args.spec,\\\\n            args.path,\\\\n            args.app_with_args[1:],\\\\n            args.python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            args.pypackages,\\\\n            verbose,\\\\n            not args.no_cache,\\\\n        )\\\\n        # We should never reach here because run() is NoReturn.\\\\n        return ExitCode(1)\\\\n    elif args.command == \\\\\"install\\\\\":\\\\n        return commands.install(\\\\n            None,\\\\n            None,\\\\n            args.package_spec,\\\\n            paths.ctx.bin_dir,\\\\n            paths.ctx.man_dir,\\\\n            args.python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            verbose,\\\\n            force=args.force,\\\\n            reinstall=False,\\\\n            include_dependencies=args.include_deps,\\\\n            preinstall_packages=args.preinstall,\\\\n            suffix=args.suffix,\\\\n            python_flag_passed=python_flag_passed,\\\\n        )\\\\n    elif args.command == \\\\\"install-all\\\\\":\\\\n        return commands.install_all(\\\\n            args.spec_metadata_file,\\\\n            paths.ctx.bin_dir,\\\\n            paths.ctx.man_dir,\\\\n            args.python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            verbose,\\\\n            force=args.force,\\\\n        )\\\\n    elif args.command == \\\\\"inject\\\\\":\\\\n        return commands.inject(\\\\n            venv_dir,\\\\n            None,\\\\n            args.dependencies,\\\\n            args.requirements,\\\\n            pip_args,\\\\n            verbose=verbose,\\\\n            include_apps=args.include_apps,\\\\n            include_dependencies=args.include_deps,\\\\n            force=args.force,\\\\n            suffix=args.with_suffix,\\\\n        )\\\\n    elif args.command == \\\\\"uninject\\\\\":\\\\n        return commands.uninject(\\\\n            venv_dir,\\\\n            args.dependencies,\\\\n            local_bin_dir=paths.ctx.bin_dir,\\\\n            local_man_dir=paths.ctx.man_dir,\\\\n            leave_deps=args.leave_deps,\\\\n            verbose=verbose,\\\\n        )\\\\n    elif args.command == \\\\\"upgrade\\\\\":\\\\n        return commands.upgrade(\\\\n            venv_dirs,\\\\n            args.python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            verbose,\\\\n            include_injected=args.include_injected,\\\\n            force=args.force,\\\\n            install=args.install,\\\\n            python_flag_passed=python_flag_passed,\\\\n        )\\\\n    elif args.command == \\\\\"upgrade-all\\\\\":\\\\n        return commands.upgrade_all(\\\\n            venv_container,\\\\n            verbose,\\\\n            include_injected=args.include_injected,\\\\n            skip=skip_list,\\\\n            force=args.force,\\\\n            pip_args=pip_args,\\\\n            python_flag_passed=python_flag_passed,\\\\n        )\\\\n    elif args.command == \\\\\"upgrade-shared\\\\\":\\\\n        return commands.upgrade_shared(\\\\n            verbose,\\\\n            pip_args,\\\\n        )\\\\n    elif args.command == \\\\\"list\\\\\":\\\\n        return commands.list_packages(\\\\n            venv_container,\\\\n            args.include_injected,\\\\n            args.json,\\\\n            args.short,\\\\n            args.pinned,\\\\n        )\\\\n    elif args.command == \\\\\"interpreter\\\\\":\\\\n        if args.interpreter_command == \\\\\"list\\\\\":\\\\n            return commands.list_interpreters(venv_container)\\\\n        elif args.interpreter_command == \\\\\"prune\\\\\":\\\\n            return commands.prune_interpreters(venv_container)\\\\n        elif args.interpreter_command == \\\\\"upgrade\\\\\":\\\\n            return commands.upgrade_interpreters(venv_container, verbose)\\\\n        elif args.interpreter_command is None:\\\\n            subparsers[\\\\\"interpreter\\\\\"].print_help()\\\\n            return EXIT_CODE_OK\\\\n        else:\\\\n            raise PipxError(f\\\\\"Unknown interpreter command {args.interpreter_command}\\\\\")\\\\n    elif args.command == \\\\\"pin\\\\\":\\\\n        return commands.pin(venv_dir, verbose, skip_list, args.injected_only)\\\\n    elif args.command == \\\\\"unpin\\\\\":\\\\n        return commands.unpin(venv_dir, verbose)\\\\n    elif args.command == \\\\\"uninstall\\\\\":\\\\n        return commands.uninstall(venv_dir, paths.ctx.bin_dir, paths.ctx.man_dir, verbose)\\\\n    elif args.command == \\\\\"uninstall-all\\\\\":\\\\n        return commands.uninstall_all(\\\\n            venv_container,\\\\n            paths.ctx.bin_dir,\\\\n            paths.ctx.man_dir,\\\\n            verbose,\\\\n        )\\\\n    elif args.command == \\\\\"reinstall\\\\\":\\\\n        return commands.reinstall(\\\\n            venv_dir=venv_dir,\\\\n            local_bin_dir=paths.ctx.bin_dir,\\\\n            local_man_dir=paths.ctx.man_dir,\\\\n            python=args.python,\\\\n            verbose=verbose,\\\\n            python_flag_passed=python_flag_passed,\\\\n        )\\\\n    elif args.command == \\\\\"reinstall-all\\\\\":\\\\n        return commands.reinstall_all(\\\\n            venv_container,\\\\n            paths.ctx.bin_dir,\\\\n            paths.ctx.man_dir,\\\\n            args.python,\\\\n            verbose,\\\\n            skip=skip_list,\\\\n            python_flag_passed=python_flag_passed,\\\\n        )\\\\n    elif args.command == \\\\\"runpip\\\\\":\\\\n        if not venv_dir:\\\\n            raise PipxError(\\\\\"Developer error: venv_dir is not defined.\\\\\")\\\\n        return commands.run_pip(package, venv_dir, args.pipargs, args.verbose)\\\\n    elif args.command == \\\\\"ensurepath\\\\\":\\\\n        try:\\\\n            return commands.ensure_pipx_paths(prepend=args.prepend, force=args.force, all_shells=args.all_shells)\\\\n        except Exception as e:\\\\n            logger.debug(\\\\\"Uncaught Exception:\\\\\", exc_info=True)\\\\n            raise PipxError(str(e), wrap_message=False) from None\\\\n    elif args.command == \\\\\"completions\\\\\":\\\\n        print(constants.completion_instructions)\\\\n        return ExitCode(0)\\\\n    elif args.command == \\\\\"environment\\\\\":\\\\n        return commands.environment(value=args.value)\\\\n    else:\\\\n        raise PipxError(f\\\\\"Unknown command {args.command}\\\\\")\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/main.py\", \"line\": [214, 427], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def run(\\\\n    app: str,\\\\n    spec: str,\\\\n    is_path: bool,\\\\n    app_args: List[str],\\\\n    python: str,\\\\n    pip_args: List[str],\\\\n    venv_args: List[str],\\\\n    pypackages: bool,\\\\n    verbose: bool,\\\\n    use_cache: bool,\\\\n) -> NoReturn:\\\\n    \\\\\"\\\\\"\\\\\"Installs venv to temporary dir (or reuses cache), then runs app from\\\\n    package\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    # For any package, we need to just use the name\\\\n    try:\\\\n        package_name = Requirement(app).name\\\\n    except InvalidRequirement:\\\\n        # Raw URLs to scripts are supported, too, so continue if\\\\n        # we can\\'t parse this as a package\\\\n        package_name = app\\\\n\\\\n    content = None if spec is not None else maybe_script_content(app, is_path)\\\\n    if content is not None:\\\\n        run_script(content, app_args, python, pip_args, venv_args, verbose, use_cache)\\\\n    else:\\\\n        package_or_url = spec if spec is not None else app\\\\n        run_package(\\\\n            package_name,\\\\n            package_or_url,\\\\n            app_args,\\\\n            python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            pypackages,\\\\n            verbose,\\\\n            use_cache,\\\\n        )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/run.py\", \"line\": [177, 216], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def run_package(\\\\n    app: str,\\\\n    package_or_url: str,\\\\n    app_args: List[str],\\\\n    python: str,\\\\n    pip_args: List[str],\\\\n    venv_args: List[str],\\\\n    pypackages: bool,\\\\n    verbose: bool,\\\\n    use_cache: bool,\\\\n) -> NoReturn:\\\\n    if which(app):\\\\n        logger.warning(\\\\n            pipx_wrap(\\\\n                f\\\\\"\\\\\"\\\\\"\\\\n                {hazard}  {app} is already on your PATH and installed at\\\\n                {which(app)}. Downloading and running anyway.\\\\n                \\\\\"\\\\\"\\\\\",\\\\n                subsequent_indent=\\\\\" \\\\\" * 4,\\\\n            )\\\\n        )\\\\n\\\\n    if WINDOWS:\\\\n        app_filename = f\\\\\"{app}.exe\\\\\"\\\\n        logger.info(f\\\\\"Assuming app is {app_filename!r} (Windows only)\\\\\")\\\\n    else:\\\\n        app_filename = app\\\\n\\\\n    pypackage_bin_path = get_pypackage_bin_path(app)\\\\n    if pypackage_bin_path.exists():\\\\n        logger.info(f\\\\\"Using app in local __pypackages__ directory at \\'{pypackage_bin_path}\\'\\\\\")\\\\n        run_pypackage_bin(pypackage_bin_path, app_args)\\\\n    if pypackages:\\\\n        raise PipxError(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n            \\'--pypackages\\' flag was passed, but \\'{pypackage_bin_path}\\' was\\\\n            not found. See https://github.com/cs01/pythonloc to learn how to\\\\n            install here, or omit the flag.\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        )\\\\n\\\\n    venv_dir = _get_temporary_venv_path([package_or_url], python, pip_args, venv_args)\\\\n\\\\n    venv = Venv(venv_dir)\\\\n    bin_path = venv.bin_path / app_filename\\\\n    _prepare_venv_cache(venv, bin_path, use_cache)\\\\n\\\\n    if venv.has_app(app, app_filename):\\\\n        logger.info(f\\\\\"Reusing cached venv {venv_dir}\\\\\")\\\\n        venv.run_app(app, app_filename, app_args)\\\\n    else:\\\\n        logger.info(f\\\\\"venv location is {venv_dir}\\\\\")\\\\n        _download_and_run(\\\\n            Path(venv_dir),\\\\n            package_or_url,\\\\n            app,\\\\n            app_filename,\\\\n            app_args,\\\\n            python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            use_cache,\\\\n            verbose,\\\\n        )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/run.py\", \"line\": [111, 174], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def _get_requirements_from_script(content: Union[str, Path]) -> Optional[List[str]]:\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Supports inline script metadata.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    if isinstance(content, Path):\\\\n        content = content.read_text(encoding=\\\\\"utf-8\\\\\")\\\\n\\\\n    name = \\\\\"script\\\\\"\\\\n\\\\n    # Windows is currently getting un-normalized line endings, so normalize\\\\n    content = content.replace(\\\\\"\\\\\\\\r\\\\\\\\n\\\\\", \\\\\"\\\\\\\\n\\\\\")\\\\n\\\\n    matches = [m for m in INLINE_SCRIPT_METADATA.finditer(content) if m.group(\\\\\"type\\\\\") == name]\\\\n\\\\n    if not matches:\\\\n        pyproject_matches = [m for m in INLINE_SCRIPT_METADATA.finditer(content) if m.group(\\\\\"type\\\\\") == \\\\\"pyproject\\\\\"]\\\\n        if pyproject_matches:\\\\n            logger.error(\\\\n                pipx_wrap(\\\\n                    f\\\\\"\\\\\"\\\\\"\\\\n                    {hazard}  Using old form of requirements table. Use updated PEP\\\\n                    723 syntax by replacing `# /// pyproject` with `# /// script`\\\\n                    and `run.dependencies` (or `run.requirements`) with\\\\n                    `dependencies`.\\\\n                    \\\\\"\\\\\"\\\\\",\\\\n                    subsequent_indent=\\\\\" \\\\\" * 4,\\\\n                )\\\\n            )\\\\n            raise ValueError(\\\\\"Old \\'pyproject\\' table found\\\\\")\\\\n        return None\\\\n\\\\n    if len(matches) > 1:\\\\n        raise ValueError(f\\\\\"Multiple {name} blocks found\\\\\")\\\\n\\\\n    content = \\\\\"\\\\\".join(\\\\n        line[2:] if line.startswith(\\\\\"# \\\\\") else line[1:] for line in matches[0].group(\\\\\"content\\\\\").splitlines(keepends=True)\\\\n    )\\\\n\\\\n    pyproject = tomllib.loads(content)\\\\n\\\\n    requirements = []\\\\n    for requirement in pyproject.get(\\\\\"dependencies\\\\\", []):\\\\n        # Validate the requirement\\\\n        try:\\\\n            req = Requirement(requirement)\\\\n        except InvalidRequirement as e:\\\\n            raise PipxError(f\\\\\"Invalid requirement {requirement}: {e}\\\\\") from e\\\\n\\\\n        # Use the normalised form of the requirement\\\\n        requirements.append(str(req))\\\\n\\\\n    return requirements\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/run.py\", \"line\": [333, 385], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def run(\\\\n    app: str,\\\\n    spec: str,\\\\n    is_path: bool,\\\\n    app_args: List[str],\\\\n    python: str,\\\\n    pip_args: List[str],\\\\n    venv_args: List[str],\\\\n    pypackages: bool,\\\\n    verbose: bool,\\\\n    use_cache: bool,\\\\n) -> NoReturn:\\\\n    \\\\\"\\\\\"\\\\\"Installs venv to temporary dir (or reuses cache), then runs app from\\\\n    package\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    # For any package, we need to just use the name\\\\n    try:\\\\n        package_name = Requirement(app).name\\\\n    except InvalidRequirement:\\\\n        # Raw URLs to scripts are supported, too, so continue if\\\\n        # we can\\'t parse this as a package\\\\n        package_name = app\\\\n\\\\n    content = None if spec is not None else maybe_script_content(app, is_path)\\\\n    if content is not None:\\\\n        run_script(content, app_args, python, pip_args, venv_args, verbose, use_cache)\\\\n    else:\\\\n        package_or_url = spec if spec is not None else app\\\\n        run_package(\\\\n            package_name,\\\\n            package_or_url,\\\\n            app_args,\\\\n            python,\\\\n            pip_args,\\\\n            venv_args,\\\\n            pypackages,\\\\n            verbose,\\\\n            use_cache,\\\\n        )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/run.py\", \"line\": [177, 216], \"kind\": \"def\"}}']}, 'view_file_contents': {'number': 31, 'observation': ['{\"file_content\": \"import React, {useCallback, useEffect, useRef, useState} from \\'react\\';\\\\nimport styled from \\'@emotion/styled\\';\\\\nimport {useResizeObserver} from \\'@react-aria/utils\\';\\\\n\\\\nimport {Panel as _Panel} from \\'sentry/components/panels\\';\\\\nimport {useReplayContext} from \\'sentry/components/replays/replayContext\\';\\\\n\\\\nimport BufferingOverlay from \\'./player/bufferingOverlay\\';\\\\nimport FastForwardBadge from \\'./player/fastForwardBadge\\';\\\\n\\\\ninterface Props {\\\\n  className?: string;\\\\n  height?: number;\\\\n}\\\\n\\\\nfunction BasePlayerRoot({className, height = Infinity}: Props) {\\\\n  const {\\\\n    initRoot,\\\\n    dimensions: videoDimensions,\\\\n    fastForwardSpeed,\\\\n    isBuffering,\\\\n  } = useReplayContext();\\\\n\\\\n  const windowEl = useRef<HTMLDivElement>(null);\\\\n  const viewEl = useRef<HTMLDivElement>(null);\\\\n\\\\n  const [windowDimensions, setWindowDimensions] = useState({\\\\n    width: 0,\\\\n    height: 0,\\\\n  });\\\\n\\\\n  // Create the `rrweb` instance which creates an iframe inside `viewEl`\\\\n  useEffect(() => initRoot(viewEl.current), [initRoot]);\\\\n\\\\n  // Read the initial width & height where the player will be inserted, this is\\\\n  // so we can shrink the video into the available space.\\\\n  // If the size of the container changes, we can re-calculate the scaling factor\\\\n  const updateWindowDimensions = useCallback(\\\\n    () =>\\\\n      setWindowDimensions({\\\\n        width: windowEl.current?.clientWidth || 0,\\\\n        height: windowEl.current?.clientHeight || 0,\\\\n      }),\\\\n    [setWindowDimensions]\\\\n  );\\\\n  useResizeObserver({ref: windowEl, onResize: updateWindowDimensions});\\\\n  // If your browser doesn\\'t have ResizeObserver then set the size once.\\\\n  useEffect(() => {\\\\n    if (typeof window.ResizeObserver !== \\'undefined\\') {\\\\n      return;\\\\n    }\\\\n    updateWindowDimensions();\\\\n  }, [updateWindowDimensions]);\\\\n\\\\n  // Update the scale of the view whenever dimensions have changed.\\\\n  useEffect(() => {\\\\n    if (viewEl.current) {\\\\n      const windowHeight = height === Infinity ? windowDimensions.height : height;\\\\n\\\\n      const scale = Math.min(\\\\n        windowDimensions.width / videoDimensions.width,\\\\n        windowHeight / videoDimensions.height,\\\\n        1\\\\n      );\\\\n      if (scale) {\\\\n        viewEl.current.style[\\'transform-origin\\'] = \\'top left\\';\\\\n        viewEl.current.style.transform = `scale(${scale})`;\\\\n        viewEl.current.style.width = `${videoDimensions.width * scale}px`;\\\\n        viewEl.current.style.height = `${videoDimensions.height * scale}px`;\\\\n      }\\\\n    }\\\\n  }, [windowDimensions, videoDimensions, height]);\\\\n\\\\n  return (\\\\n    <SizingWindow ref={windowEl} className=\\\\\"sr-block\\\\\" minHeight={height}>\\\\n      <div ref={viewEl} className={className} />\\\\n      {fastForwardSpeed ? <PositionedFastForward speed={fastForwardSpeed} /> : null}\\\\n      {isBuffering ? <PositionedBuffering /> : null}\\\\n    </SizingWindow>\\\\n  );\\\\n}\\\\n\\\\n// Center the viewEl inside the windowEl.\\\\n// This is useful when the window is inside a container that has large fixed\\\\n// dimensions, like when in fullscreen mode.\\\\nconst SizingWindow = styled(\\'div\\')<{minHeight: number}>`\\\\n  width: 100%;\\\\n  height: 100%;\\\\n  ${p => (p.minHeight !== Infinity ? `min-height: ${p.minHeight}px !important;` : \\'\\')}\\\\n\\\\n  display: flex;\\\\n  justify-content: center;\\\\n  align-items: center;\\\\n  position: relative;\\\\n\\\\n  background-color: ${p => p.theme.backgroundSecondary};\\\\n  background-image: repeating-linear-gradient(\\\\n      -145deg,\\\\n      transparent,\\\\n      transparent 8px,\\\\n      ${p => p.theme.backgroundSecondary} 8px,\\\\n      ${p => p.theme.backgroundSecondary} 11px\\\\n    ),\\\\n    repeating-linear-gradient(\\\\n      -45deg,\\\\n      transparent,\\\\n      transparent 15px,\\\\n      ${p => p.theme.gray100} 15px,\\\\n      ${p => p.theme.gray100} 16px\\\\n    );\\\\n`;\\\\n\\\\nconst PositionedFastForward = styled(FastForwardBadge)`\\\\n  position: absolute;\\\\n  left: 0;\\\\n  bottom: 0;\\\\n`;\\\\n\\\\nconst PositionedBuffering = styled(BufferingOverlay)`\\\\n  position: absolute;\\\\n  top: 0;\\\\n  left: 0;\\\\n  right: 0;\\\\n  bottom: 0;\\\\n`;\\\\n\\\\n// Base styles, to make the Replayer instance work\\\\nconst PlayerRoot = styled(BasePlayerRoot)`\\\\n  .replayer-wrapper {\\\\n    background: white;\\\\n    user-select: none;\\\\n  }\\\\n  .replayer-wrapper > .replayer-mouse-tail {\\\\n    position: absolute;\\\\n    pointer-events: none;\\\\n  }\\\\n\\\\n  /* Override default user-agent styles */\\\\n  .replayer-wrapper > iframe {\\\\n    border: none;\\\\n  }\\\\n`;\\\\n\\\\n// Sentry-specific styles for the player.\\\\n// The elements we have to work with are:\\\\n// ```css\\\\n// div.replayer-wrapper {}\\\\n// div.replayer-wrapper > div.replayer-mouse {}\\\\n// div.replayer-wrapper > canvas.replayer-mouse-tail {}\\\\n// div.replayer-wrapper > iframe {}\\\\n// ```\\\\n// The mouse-tail is also configured for color/size in `app/components/replays/replayContext.tsx`\\\\nconst SentryPlayerRoot = styled(PlayerRoot)`\\\\n  .replayer-mouse {\\\\n    position: absolute;\\\\n    width: 32px;\\\\n    height: 32px;\\\\n    transition: left 0.05s linear, top 0.05s linear;\\\\n    background-size: contain;\\\\n    background-repeat: no-repeat;\\\\n    background-image: url(\\'data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTIiIGhlaWdodD0iMTkiIHZpZXdCb3g9IjAgMCAxMiAxOSIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTAgMTZWMEwxMS42IDExLjZINC44TDQuNCAxMS43TDAgMTZaIiBmaWxsPSJ3aGl0ZSIvPgo8cGF0aCBkPSJNOS4xIDE2LjdMNS41IDE4LjJMMC43OTk5OTkgNy4xTDQuNSA1LjZMOS4xIDE2LjdaIiBmaWxsPSJ3aGl0ZSIvPgo8cGF0aCBkPSJNNC42NzQ1MSA4LjYxODUxTDIuODMwMzEgOS4zOTI3MUw1LjkyNzExIDE2Ljc2OTVMNy43NzEzMSAxNS45OTUzTDQuNjc0NTEgOC42MTg1MVoiIGZpbGw9ImJsYWNrIi8+CjxwYXRoIGQ9Ik0xIDIuNFYxMy42TDQgMTAuN0w0LjQgMTAuNkg5LjJMMSAyLjRaIiBmaWxsPSJibGFjayIvPgo8L3N2Zz4K\\');\\\\n    border-color: transparent;\\\\n  }\\\\n  .replayer-mouse:after {\\\\n    content: \\'\\';\\\\n    display: inline-block;\\\\n    width: 32px;\\\\n    height: 32px;\\\\n    background: ${p => p.theme.purple300};\\\\n    border-radius: 100%;\\\\n    transform: translate(-50%, -50%);\\\\n    opacity: 0.3;\\\\n  }\\\\n  .replayer-mouse.active:after {\\\\n    animation: click 0.2s ease-in-out 1;\\\\n  }\\\\n  .replayer-mouse.touch-device {\\\\n    background-image: none;\\\\n    width: 70px;\\\\n    height: 70px;\\\\n    border-radius: 100%;\\\\n    margin-left: -37px;\\\\n    margin-top: -37px;\\\\n    border: 4px solid rgba(73, 80, 246, 0);\\\\n    transition: left 0s linear, top 0s linear, border-color 0.2s ease-in-out;\\\\n  }\\\\n  .replayer-mouse.touch-device.touch-active {\\\\n    border-color: ${p => p.theme.purple200};\\\\n    transition: left 0.25s linear, top 0.25s linear, border-color 0.2s ease-in-out;\\\\n  }\\\\n  .replayer-mouse.touch-device:after {\\\\n    opacity: 0;\\\\n  }\\\\n  .replayer-mouse.touch-device.active:after {\\\\n    animation: touch-click 0.2s ease-in-out 1;\\\\n  }\\\\n  @keyframes click {\\\\n    0% {\\\\n      opacity: 0.3;\\\\n      width: 20px;\\\\n      height: 20px;\\\\n    }\\\\n    50% {\\\\n      opacity: 0.5;\\\\n      width: 10px;\\\\n      height: 10px;\\\\n    }\\\\n  }\\\\n  @keyframes touch-click {\\\\n    0% {\\\\n      opacity: 0;\\\\n      width: 20px;\\\\n      height: 20px;\\\\n    }\\\\n    50% {\\\\n      opacity: 0.5;\\\\n      width: 10px;\\\\n      height: 10px;\\\\n    }\\\\n  }\\\\n`;\\\\n\\\\nexport default SentryPlayerRoot;\\\\n\\\\n\"}', '{\"file_content\": \"import React, {useEffect, useRef, useState} from \\'react\\';\\\\nimport styled from \\'@emotion/styled\\';\\\\nimport debounce from \\'lodash/debounce\\';\\\\n\\\\nimport {Panel, PanelBody, PanelHeader as _PanelHeader} from \\'sentry/components/panels\\';\\\\nimport HorizontalMouseTracking from \\'sentry/components/replays/player/horizontalMouseTracking\\';\\\\nimport {PlayerScrubber} from \\'sentry/components/replays/player/scrubber\\';\\\\nimport ReplayController from \\'sentry/components/replays/replayController\\';\\\\nimport ReplayCurrentUrl from \\'sentry/components/replays/replayCurrentUrl\\';\\\\nimport ReplayPlayer from \\'sentry/components/replays/replayPlayer\\';\\\\n\\\\n// How much to reveal under the player, so people can see the \\'pagefold\\' and\\\\n// know that they can scroll the page.\\\\nconst BOTTOM_REVEAL_PIXELS = 70;\\\\n\\\\ntype Props = {\\\\n  isFullscreen: boolean;\\\\n  toggleFullscreen: () => void;\\\\n};\\\\n\\\\nfunction ReplayView({isFullscreen, toggleFullscreen}: Props) {\\\\n  const containerRef = useRef<HTMLDivElement>(null);\\\\n  const playerRef = useRef<HTMLDivElement>(null);\\\\n\\\\n  const [windowInnerHeight, setWindowInnerHeight] = useState(window.innerHeight);\\\\n  const [playerHeight, setPlayerHeight] = useState(0);\\\\n\\\\n  useEffect(() => {\\\\n    const onResize = debounce(() => {\\\\n      setWindowInnerHeight(window.innerHeight);\\\\n    });\\\\n    window.addEventListener(\\'resize\\', onResize);\\\\n    return () => {\\\\n      window.removeEventListener(\\'resize\\', onResize);\\\\n    };\\\\n  }, []);\\\\n\\\\n  useEffect(() => {\\\\n    const containerBottom =\\\\n      (containerRef.current?.offsetTop || 0) + (containerRef.current?.offsetHeight || 0);\\\\n    const playerOffsetHeight = playerRef.current?.offsetHeight || 0;\\\\n    const calc =\\\\n      windowInnerHeight - (containerBottom - playerOffsetHeight) - BOTTOM_REVEAL_PIXELS;\\\\n    setPlayerHeight(Math.max(200, calc));\\\\n  }, [windowInnerHeight]);\\\\n\\\\n  return (\\\\n    <PanelNoMargin ref={containerRef} isFullscreen={isFullscreen}>\\\\n      <PanelHeader>\\\\n        <ReplayCurrentUrl />\\\\n      </PanelHeader>\\\\n      <PanelHeader ref={playerRef} disablePadding noBorder>\\\\n        <ReplayPlayer height={isFullscreen ? Infinity : playerHeight} />\\\\n      </PanelHeader>\\\\n      <HorizontalMouseTracking>\\\\n        <PlayerScrubber />\\\\n      </HorizontalMouseTracking>\\\\n      <PanelBody withPadding>\\\\n        <ReplayController toggleFullscreen={toggleFullscreen} />\\\\n      </PanelBody>\\\\n    </PanelNoMargin>\\\\n  );\\\\n}\\\\n\\\\nconst PanelNoMargin = styled(Panel)<{isFullscreen: boolean}>`\\\\n  margin-bottom: 0;\\\\n\\\\n  ${p =>\\\\n    p.isFullscreen\\\\n      ? `height: 100%;\\\\n      display: grid;\\\\n      grid-template-rows: auto 1fr auto;\\\\n      `\\\\n      : \\'\\'}\\\\n`;\\\\n\\\\nconst PanelHeader = styled(_PanelHeader)<{noBorder?: boolean}>`\\\\n  display: block;\\\\n  padding: 0;\\\\n  ${p => (p.noBorder ? \\'border-bottom: none;\\' : \\'\\')}\\\\n`;\\\\n\\\\nexport default ReplayView;\\\\n\\\\n\"}', '{\"file_content\": \"from unittest.mock import patch\\\\n\\\\nimport pytest\\\\nimport responses\\\\nfrom requests import HTTPError\\\\n\\\\nfrom sentry.integrations.types import EventLifecycleOutcome\\\\nfrom sentry.sentry_apps.external_requests.issue_link_requester import (\\\\n    FAILURE_REASON_BASE,\\\\n    IssueLinkRequester,\\\\n    IssueRequestActionType,\\\\n)\\\\nfrom sentry.sentry_apps.metrics import SentryAppEventType, SentryAppExternalRequestHaltReason\\\\nfrom sentry.sentry_apps.services.app import app_service\\\\nfrom sentry.sentry_apps.utils.errors import SentryAppIntegratorError\\\\nfrom sentry.testutils.asserts import (\\\\n    assert_count_of_metric,\\\\n    assert_halt_metric,\\\\n    assert_many_halt_metrics,\\\\n    assert_success_metric,\\\\n)\\\\nfrom sentry.testutils.cases import TestCase\\\\nfrom sentry.users.services.user.serial import serialize_rpc_user\\\\nfrom sentry.utils import json\\\\nfrom sentry.utils.sentry_apps import SentryAppWebhookRequestsBuffer\\\\n\\\\n\\\\nclass TestIssueLinkRequester(TestCase):\\\\n    def setUp(self):\\\\n        super().setUp()\\\\n\\\\n        self.user = self.create_user(name=\\\\\"foo\\\\\")\\\\n        self.org = self.create_organization(owner=self.user)\\\\n        self.project = self.create_project(slug=\\\\\"boop\\\\\", organization=self.org)\\\\n        self.group = self.create_group(project=self.project)\\\\n\\\\n        self.sentry_app = self.create_sentry_app(\\\\n            name=\\\\\"foo\\\\\", organization=self.org, webhook_url=\\\\\"https://example.com\\\\\", scopes=()\\\\n        )\\\\n\\\\n        self.orm_install = self.create_sentry_app_installation(\\\\n            slug=\\\\\"foo\\\\\", organization=self.org, user=self.user\\\\n        )\\\\n        self.rpc_user = serialize_rpc_user(self.user)\\\\n        self.install = app_service.get_many(filter=dict(installation_ids=[self.orm_install.id]))[0]\\\\n\\\\n    @responses.activate\\\\n    @patch(\\\\\"sentry.integrations.utils.metrics.EventLifecycle.record_event\\\\\")\\\\n    def test_makes_request(self, mock_record):\\\\n        fields = {\\\\\"title\\\\\": \\\\\"An Issue\\\\\", \\\\\"description\\\\\": \\\\\"a bug was found\\\\\", \\\\\"assignee\\\\\": \\\\\"user-1\\\\\"}\\\\n\\\\n        responses.add(\\\\n            method=responses.POST,\\\\n            url=\\\\\"https://example.com/link-issue\\\\\",\\\\n            json={\\\\n                \\\\\"project\\\\\": \\\\\"ProjectName\\\\\",\\\\n                \\\\\"webUrl\\\\\": \\\\\"https://example.com/project/issue-id\\\\\",\\\\n                \\\\\"identifier\\\\\": \\\\\"issue-1\\\\\",\\\\n            },\\\\n            status=200,\\\\n            content_type=\\\\\"application/json\\\\\",\\\\n        )\\\\n\\\\n        result = IssueLinkRequester(\\\\n            install=self.install,\\\\n            group=self.group,\\\\n            uri=\\\\\"/link-issue\\\\\",\\\\n            fields=fields,\\\\n            user=self.rpc_user,\\\\n            action=IssueRequestActionType(\\\\\"create\\\\\"),\\\\n        ).run()\\\\n        assert result == {\\\\n            \\\\\"project\\\\\": \\\\\"ProjectName\\\\\",\\\\n            \\\\\"webUrl\\\\\": \\\\\"https://example.com/project/issue-id\\\\\",\\\\n            \\\\\"identifier\\\\\": \\\\\"issue-1\\\\\",\\\\n        }\\\\n\\\\n        request = responses.calls[0].request\\\\n        data = {\\\\n            \\\\\"fields\\\\\": {\\\\\"title\\\\\": \\\\\"An Issue\\\\\", \\\\\"description\\\\\": \\\\\"a bug was found\\\\\", \\\\\"assignee\\\\\": \\\\\"user-1\\\\\"},\\\\n            \\\\\"issueId\\\\\": self.group.id,\\\\n            \\\\\"installationId\\\\\": self.install.uuid,\\\\n            \\\\\"webUrl\\\\\": self.group.get_absolute_url(),\\\\n            \\\\\"project\\\\\": {\\\\\"id\\\\\": self.project.id, \\\\\"slug\\\\\": self.project.slug},\\\\n            \\\\\"actor\\\\\": {\\\\\"type\\\\\": \\\\\"user\\\\\", \\\\\"id\\\\\": self.user.id, \\\\\"name\\\\\": self.user.name},\\\\n        }\\\\n        payload = json.loads(request.body)\\\\n        assert payload == data\\\\n        assert request.headers[\\\\\"Sentry-App-Signature\\\\\"] == self.sentry_app.build_signature(\\\\n            json.dumps(payload)\\\\n        )\\\\n        buffer = SentryAppWebhookRequestsBuffer(self.sentry_app)\\\\n        requests = buffer.get_requests()\\\\n\\\\n        assert len(requests) == 1\\\\n        assert requests[0][\\\\\"response_code\\\\\"] == 200\\\\n        assert requests[0][\\\\\"event_type\\\\\"] == \\\\\"external_issue.created\\\\\"\\\\n\\\\n        # SLO assertions\\\\n        assert_success_metric(mock_record)\\\\n\\\\n        # EXTERNAL_REQUEST (success) -> EXTERNAL_REQUEST (success)\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.STARTED, outcome_count=2\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.SUCCESS, outcome_count=2\\\\n        )\\\\n\\\\n    @responses.activate\\\\n    @patch(\\\\\"sentry.integrations.utils.metrics.EventLifecycle.record_event\\\\\")\\\\n    def test_invalid_response_format(self, mock_record):\\\\n        # missing \\'identifier\\'\\\\n        invalid_format = {\\\\n            \\\\\"project\\\\\": \\\\\"ProjectName\\\\\",\\\\n            \\\\\"webUrl\\\\\": \\\\\"https://example.com/project/issue-id\\\\\",\\\\n        }\\\\n        responses.add(\\\\n            method=responses.POST,\\\\n            url=\\\\\"https://example.com/link-issue\\\\\",\\\\n            json=invalid_format,\\\\n            status=200,\\\\n            content_type=\\\\\"application/json\\\\\",\\\\n        )\\\\n        with pytest.raises(SentryAppIntegratorError) as exception_info:\\\\n            IssueLinkRequester(\\\\n                install=self.install,\\\\n                group=self.group,\\\\n                uri=\\\\\"/link-issue\\\\\",\\\\n                fields={},\\\\n                user=self.rpc_user,\\\\n                action=IssueRequestActionType(\\\\\"create\\\\\"),\\\\n            ).run()\\\\n\\\\n        assert exception_info.value.webhook_context == {\\\\n            \\\\\"error_type\\\\\": FAILURE_REASON_BASE.format(\\\\n                SentryAppExternalRequestHaltReason.BAD_RESPONSE\\\\n            ),\\\\n            \\\\\"uri\\\\\": \\\\\"/link-issue\\\\\",\\\\n            \\\\\"installation_uuid\\\\\": self.install.uuid,\\\\n            \\\\\"sentry_app_slug\\\\\": self.sentry_app.slug,\\\\n            \\\\\"project_slug\\\\\": self.group.project.slug,\\\\n            \\\\\"group_id\\\\\": self.group.id,\\\\n            \\\\\"response\\\\\": invalid_format,\\\\n        }\\\\n\\\\n        # SLO assertions\\\\n        assert_halt_metric(\\\\n            mock_record,\\\\n            f\\\\\"{SentryAppEventType.EXTERNAL_ISSUE_LINKED}.{SentryAppExternalRequestHaltReason.BAD_RESPONSE}\\\\\",\\\\n        )\\\\n\\\\n        # EXTERNAL_REQUEST (halt) -> EXTERNAL_REQUEST (success)\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.STARTED, outcome_count=2\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.SUCCESS, outcome_count=1\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.HALTED, outcome_count=1\\\\n        )\\\\n\\\\n    @responses.activate\\\\n    @patch(\\\\\"sentry.integrations.utils.metrics.EventLifecycle.record_event\\\\\")\\\\n    def test_500_response(self, mock_record):\\\\n        responses.add(\\\\n            method=responses.POST,\\\\n            url=\\\\\"https://example.com/link-issue\\\\\",\\\\n            body=\\\\\"Something failed\\\\\",\\\\n            status=500,\\\\n        )\\\\n\\\\n        with pytest.raises(SentryAppIntegratorError) as exception_info:\\\\n            IssueLinkRequester(\\\\n                install=self.install,\\\\n                group=self.group,\\\\n                uri=\\\\\"/link-issue\\\\\",\\\\n                fields={},\\\\n                user=self.rpc_user,\\\\n                action=IssueRequestActionType(\\\\\"create\\\\\"),\\\\n            ).run()\\\\n\\\\n        assert exception_info.value.webhook_context == {\\\\n            \\\\\"error_type\\\\\": FAILURE_REASON_BASE.format(\\\\n                SentryAppExternalRequestHaltReason.BAD_RESPONSE\\\\n            ),\\\\n            \\\\\"uri\\\\\": \\\\\"/link-issue\\\\\",\\\\n            \\\\\"installation_uuid\\\\\": self.install.uuid,\\\\n            \\\\\"sentry_app_slug\\\\\": self.sentry_app.slug,\\\\n            \\\\\"project_slug\\\\\": self.group.project.slug,\\\\n            \\\\\"group_id\\\\\": self.group.id,\\\\n            \\\\\"error_message\\\\\": \\\\\"500 Server Error: Internal Server Error for url: https://example.com/link-issue\\\\\",\\\\n        }\\\\n\\\\n        buffer = SentryAppWebhookRequestsBuffer(self.sentry_app)\\\\n        requests = buffer.get_requests()\\\\n        assert len(requests) == 1\\\\n        assert requests[0][\\\\\"response_code\\\\\"] == 500\\\\n        assert requests[0][\\\\\"event_type\\\\\"] == \\\\\"external_issue.created\\\\\"\\\\n\\\\n        # SLO assertions\\\\n        # We recieved back a 500 response from 3p\\\\n        assert_many_halt_metrics(mock_record, [HTTPError(), HTTPError()])\\\\n\\\\n        # EXTERNAL_REQUEST (halt) -> EXTERNAL_REQUEST (halt)\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.STARTED, outcome_count=2\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.HALTED, outcome_count=2\\\\n        )\\\\n\\\\n    @responses.activate\\\\n    @patch(\\\\\"sentry.integrations.utils.metrics.EventLifecycle.record_event\\\\\")\\\\n    def test_invalid_json_response(self, mock_record):\\\\n        responses.add(\\\\n            method=responses.POST,\\\\n            url=\\\\\"https://example.com/link-issue\\\\\",\\\\n            body=\\\\\"not valid json}\\\\\",\\\\n            status=200,\\\\n            content_type=\\\\\"application/json\\\\\",\\\\n        )\\\\n\\\\n        with pytest.raises(SentryAppIntegratorError) as exception_info:\\\\n            IssueLinkRequester(\\\\n                install=self.install,\\\\n                group=self.group,\\\\n                uri=\\\\\"/link-issue\\\\\",\\\\n                fields={},\\\\n                user=self.rpc_user,\\\\n                action=IssueRequestActionType(\\\\\"create\\\\\"),\\\\n            ).run()\\\\n\\\\n        assert exception_info.value.webhook_context == {\\\\n            \\\\\"error_type\\\\\": FAILURE_REASON_BASE.format(\\\\n                SentryAppExternalRequestHaltReason.BAD_RESPONSE\\\\n            ),\\\\n            \\\\\"uri\\\\\": \\\\\"/link-issue\\\\\",\\\\n            \\\\\"installation_uuid\\\\\": self.install.uuid,\\\\n            \\\\\"sentry_app_slug\\\\\": self.sentry_app.slug,\\\\n            \\\\\"project_slug\\\\\": self.group.project.slug,\\\\n            \\\\\"group_id\\\\\": self.group.id,\\\\n            \\\\\"response_body\\\\\": b\\\\\"not valid json}\\\\\",\\\\n        }\\\\n\\\\n        buffer = SentryAppWebhookRequestsBuffer(self.sentry_app)\\\\n        requests = buffer.get_requests()\\\\n\\\\n        assert len(requests) == 1\\\\n        assert requests[0][\\\\\"response_code\\\\\"] == 200\\\\n        assert requests[0][\\\\\"event_type\\\\\"] == \\\\\"external_issue.created\\\\\"\\\\n\\\\n        # SLO assertions\\\\n        assert_halt_metric(\\\\n            mock_record,\\\\n            json.JSONDecodeError(\\\\\"Expecting value\\\\\", \\\\\"not valid json}\\\\\", 0),\\\\n        )\\\\n\\\\n        # EXTERNAL_REQUEST (halt) -> EXTERNAL_REQUEST (success)\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.STARTED, outcome_count=2\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.SUCCESS, outcome_count=1\\\\n        )\\\\n        assert_count_of_metric(\\\\n            mock_record=mock_record, outcome=EventLifecycleOutcome.HALTED, outcome_count=1\\\\n        )\\\\n\"}', 'File not found: /data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/sentry_apps/mediators/sentry_app_installations/test_installation_notifier.py', '{\"file_content\": \"from typing import Sequence\\\\n\\\\nfrom rest_framework.request import Request\\\\nfrom rest_framework.response import Response\\\\n\\\\nfrom sentry import features\\\\nfrom sentry.api.base import region_silo_endpoint\\\\nfrom sentry.api.bases import NoProjects, OrganizationEventsV2EndpointBase\\\\nfrom sentry.api.paginator import GenericOffsetPaginator\\\\nfrom sentry.models import Organization\\\\nfrom sentry.snuba import discover\\\\n\\\\n\\\\n@region_silo_endpoint\\\\nclass OrganizationReplayEventsMetaEndpoint(OrganizationEventsV2EndpointBase):\\\\n    \\\\\"\\\\\"\\\\\"The generic Events endpoints require that the `organizations:global-views` feature\\\\n    be enabled before they return across multiple projects.\\\\n\\\\n    This endpoint is purpose built for the Session Replay product which intentionally\\\\n    requests data across multiple transactions, and therefore potentially multiple projects.\\\\n    This is similar to performance, and modeled after `OrganizationEventsMetaEndpoint`.\\\\n\\\\n    This endpoint offers a narrow interface specific to the requirements of `useReplayData.tsx`\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    private = True\\\\n\\\\n    def get_field_list(self, organization: Organization, request: Request) -> Sequence[str]:\\\\n        return [\\\\n            \\\\\"error.type\\\\\",\\\\n            \\\\\"error.value\\\\\",\\\\n            \\\\\"group.id\\\\\",\\\\n            \\\\\"id\\\\\",\\\\n            \\\\\"issue.id\\\\\",\\\\n            \\\\\"issue\\\\\",\\\\n            \\\\\"timestamp\\\\\",\\\\n        ]\\\\n\\\\n    def get(self, request: Request, organization) -> Response:\\\\n        if not features.has(\\\\\"organizations:session-replay\\\\\", organization, actor=request.user):\\\\n            return Response(status=404)\\\\n\\\\n        try:\\\\n            params = self.get_snuba_params(request, organization, check_global_views=False)\\\\n        except NoProjects:\\\\n            return Response({\\\\\"count\\\\\": 0})\\\\n\\\\n        def data_fn(offset, limit):\\\\n            query_details = {\\\\n                \\\\\"selected_columns\\\\\": self.get_field_list(organization, request),\\\\n                \\\\\"query\\\\\": request.GET.get(\\\\\"query\\\\\"),\\\\n                \\\\\"params\\\\\": params,\\\\n                \\\\\"equations\\\\\": self.get_equation_list(organization, request),\\\\n                \\\\\"orderby\\\\\": self.get_orderby(request),\\\\n                \\\\\"offset\\\\\": offset,\\\\n                \\\\\"limit\\\\\": limit,\\\\n                \\\\\"referrer\\\\\": \\\\\"api.replay.details-page\\\\\",\\\\n                \\\\\"auto_fields\\\\\": True,\\\\n                \\\\\"auto_aggregations\\\\\": True,\\\\n                \\\\\"use_aggregate_conditions\\\\\": True,\\\\n                \\\\\"allow_metric_aggregates\\\\\": False,\\\\n                \\\\\"transform_alias_to_input_format\\\\\": True,\\\\n            }\\\\n\\\\n            return discover.query(**query_details)\\\\n\\\\n        return self.paginate(\\\\n            request=request,\\\\n            paginator=GenericOffsetPaginator(data_fn=data_fn),\\\\n            on_results=lambda results: self.handle_results_with_meta(\\\\n                request,\\\\n                organization,\\\\n                params[\\\\\"project_id\\\\\"],\\\\n                results,\\\\n                standard_meta=True,\\\\n            ),\\\\n        )\\\\n\\\\n\"}', '{\"file_content\": \"from rest_framework.request import Request\\\\nfrom rest_framework.response import Response\\\\n\\\\nfrom sentry.api.base import region_silo_endpoint\\\\nfrom sentry.api.bases.organization import OrganizationAuthProviderPermission, OrganizationEndpoint\\\\nfrom sentry.api.serializers import serialize\\\\nfrom sentry.auth import manager\\\\n\\\\n\\\\n@region_silo_endpoint\\\\nclass OrganizationAuthProvidersEndpoint(OrganizationEndpoint):\\\\n    permission_classes = (OrganizationAuthProviderPermission,)\\\\n\\\\n    def get(self, request: Request, organization) -> Response:\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        List available auth providers that are available to use for an Organization\\\\n        ```````````````````````````````````````````````````````````````````````````\\\\n\\\\n        :pparam string organization_slug: the organization short name\\\\n        :auth: required\\\\n        \\\\\"\\\\\"\\\\\"\\\\n        provider_list = []\\\\n        for k, v in manager:\\\\n            if not v.is_partner:\\\\n                provider_list.append(\\\\n                    {\\\\\"key\\\\\": k, \\\\\"name\\\\\": v.name, \\\\\"requiredFeature\\\\\": v.required_feature}\\\\n                )\\\\n\\\\n        return Response(serialize(provider_list, request.user))\\\\n\\\\n\"}', '{\"file_content\": \"from unittest.mock import patch\\\\n\\\\nimport pytest\\\\nfrom django.db import models\\\\nfrom django.urls import reverse\\\\n\\\\nfrom sentry import audit_log, auth\\\\nfrom sentry.auth.authenticators.totp import TotpInterface\\\\nfrom sentry.auth.exceptions import IdentityNotValid\\\\nfrom sentry.auth.providers.fly.provider import FlyOAuth2Provider\\\\nfrom sentry.models import (\\\\n    AuditLogEntry,\\\\n    AuthIdentity,\\\\n    AuthProvider,\\\\n    Organization,\\\\n    OrganizationMember,\\\\n    SentryAppInstallationForProvider,\\\\n    User,\\\\n)\\\\nfrom sentry.services.hybrid_cloud.organization import organization_service\\\\nfrom sentry.testutils import AuthProviderTestCase, PermissionTestCase\\\\nfrom sentry.testutils.helpers.features import with_feature\\\\nfrom sentry.testutils.silo import region_silo_test\\\\nfrom sentry.web.frontend.organization_auth_settings import get_scim_url\\\\n\\\\n\\\\n@region_silo_test\\\\nclass OrganizationAuthSettingsPermissionTest(PermissionTestCase):\\\\n    def setUp(self):\\\\n        super().setUp()\\\\n        self.auth_provider = AuthProvider.objects.create(\\\\n            organization_id=self.organization.id, provider=\\\\\"dummy\\\\\"\\\\n        )\\\\n        AuthIdentity.objects.create(user=self.user, ident=\\\\\"foo\\\\\", auth_provider=self.auth_provider)\\\\n        self.login_as(self.user, organization_id=self.organization.id)\\\\n        self.path = reverse(\\\\n            \\\\\"sentry-organization-auth-provider-settings\\\\\", args=[self.organization.slug]\\\\n        )\\\\n\\\\n    def create_owner_and_attach_identity(self):\\\\n        user = self.create_user(is_superuser=False)\\\\n        self.create_member(\\\\n            user=user, organization=self.organization, role=\\\\\"owner\\\\\", teams=[self.team]\\\\n        )\\\\n        AuthIdentity.objects.create(user=user, ident=\\\\\"foo2\\\\\", auth_provider=self.auth_provider)\\\\n        om = OrganizationMember.objects.get(user_id=user.id, organization=self.organization)\\\\n        setattr(om.flags, \\\\\"sso:linked\\\\\", True)\\\\n        om.save()\\\\n        return user\\\\n\\\\n    def create_manager_and_attach_identity(self):\\\\n        user = self.create_user(is_superuser=False)\\\\n        self.create_member(\\\\n            user=user, organization=self.organization, role=\\\\\"manager\\\\\", teams=[self.team]\\\\n        )\\\\n        AuthIdentity.objects.create(user=user, ident=\\\\\"foo3\\\\\", auth_provider=self.auth_provider)\\\\n        om = OrganizationMember.objects.get(user_id=user.id, organization=self.organization)\\\\n        setattr(om.flags, \\\\\"sso:linked\\\\\", True)\\\\n        om.save()\\\\n        return user\\\\n\\\\n    def test_teamless_admin_cannot_load(self):\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            self.assert_teamless_admin_cannot_access(self.path)\\\\n\\\\n    def test_team_admin_cannot_load(self):\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            self.assert_team_admin_cannot_access(self.path)\\\\n\\\\n    def test_manager_cannot_load(self):\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            self.assert_role_cannot_access(self.path, \\\\\"manager\\\\\")\\\\n\\\\n    def test_manager_can_load(self):\\\\n        manager = self.create_manager_and_attach_identity()\\\\n\\\\n        self.login_as(manager, organization_id=self.organization.id)\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.get(self.path)\\\\n            assert resp.status_code == 200\\\\n\\\\n    def test_owner_can_load(self):\\\\n        owner = self.create_owner_and_attach_identity()\\\\n\\\\n        self.login_as(owner, organization_id=self.organization.id)\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.get(self.path)\\\\n            assert resp.status_code == 200\\\\n\\\\n    def test_load_if_already_set_up(self):\\\\n        owner = self.create_owner_and_attach_identity()\\\\n\\\\n        # can load without feature since already set up\\\\n        self.login_as(owner, organization_id=self.organization.id)\\\\n        with self.feature({\\\\\"organizations:sso-basic\\\\\": False}):\\\\n            resp = self.client.get(self.path)\\\\n            assert resp.status_code == 200\\\\n\\\\n\\\\n@region_silo_test\\\\nclass OrganizationAuthSettingsTest(AuthProviderTestCase):\\\\n    def enroll_user_and_require_2fa(self, user, organization):\\\\n        TotpInterface().enroll(user)\\\\n        organization.update(flags=models.F(\\\\\"flags\\\\\").bitor(Organization.flags.require_2fa))\\\\n        assert organization.flags.require_2fa.is_set\\\\n\\\\n    def assert_require_2fa_disabled(self, user, organization, logger):\\\\n        organization = Organization.objects.get(id=organization.id)\\\\n        assert not organization.flags.require_2fa.is_set\\\\n\\\\n        event = AuditLogEntry.objects.get(\\\\n            target_object=organization.id, event=audit_log.get_event_id(\\\\\"ORG_EDIT\\\\\"), actor=user\\\\n        )\\\\n        audit_log_event = audit_log.get(event.event)\\\\n        assert \\\\\"require_2fa to False when enabling SSO\\\\\" in audit_log_event.render(event)\\\\n        logger.info.assert_called_once_with(\\\\n            \\\\\"Require 2fa disabled during sso setup\\\\\", extra={\\\\\"organization_id\\\\\": organization.id}\\\\n        )\\\\n\\\\n    def assert_basic_flow(self, user, organization, expect_error=False):\\\\n        configure_path = reverse(\\\\n            \\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug]\\\\n        )\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(configure_path, {\\\\\"provider\\\\\": \\\\\"dummy\\\\\", \\\\\"init\\\\\": True})\\\\n            assert resp.status_code == 200\\\\n            assert self.provider.TEMPLATE in resp.content.decode(\\\\\"utf-8\\\\\")\\\\n\\\\n            path = reverse(\\\\\"sentry-auth-sso\\\\\")\\\\n            resp = self.client.post(path, {\\\\\"email\\\\\": user.email})\\\\n\\\\n        settings_path = reverse(\\\\\"sentry-organization-auth-settings\\\\\", args=[organization.slug])\\\\n\\\\n        if expect_error:\\\\n            self.assertRedirects(resp, settings_path)\\\\n            return\\\\n        else:\\\\n            self.assertRedirects(resp, configure_path)\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id, provider=\\\\\"dummy\\\\\")\\\\n        auth_identity = AuthIdentity.objects.get(auth_provider=auth_provider)\\\\n        assert user == auth_identity.user\\\\n\\\\n        member = OrganizationMember.objects.get(organization=organization, user_id=user.id)\\\\n\\\\n        assert getattr(member.flags, \\\\\"sso:linked\\\\\")\\\\n        assert not getattr(member.flags, \\\\\"sso:invalid\\\\\")\\\\n\\\\n    def create_org_and_auth_provider(self, provider_name=\\\\\"dummy\\\\\"):\\\\n        if provider_name == \\\\\"Fly.io\\\\\":\\\\n            auth.register(\\\\\"Fly.io\\\\\", FlyOAuth2Provider)\\\\n            self.addCleanup(auth.unregister, \\\\\"Fly.io\\\\\", FlyOAuth2Provider)\\\\n\\\\n        self.user.update(is_managed=True)\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=self.user)\\\\n\\\\n        auth_provider = AuthProvider.objects.create(\\\\n            organization_id=organization.id, provider=provider_name\\\\n        )\\\\n\\\\n        AuthIdentity.objects.create(user=self.user, ident=\\\\\"foo\\\\\", auth_provider=auth_provider)\\\\n        return organization, auth_provider\\\\n\\\\n    def create_om_and_link_sso(self, organization):\\\\n        om = OrganizationMember.objects.get(user_id=self.user.id, organization=organization)\\\\n        setattr(om.flags, \\\\\"sso:linked\\\\\", True)\\\\n        om.save()\\\\n        return om\\\\n\\\\n    def test_can_start_auth_flow(self):\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=self.user)\\\\n\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        self.login_as(self.user)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(path, {\\\\\"provider\\\\\": \\\\\"dummy\\\\\", \\\\\"init\\\\\": True})\\\\n\\\\n        assert resp.status_code == 200\\\\n        assert resp.content.decode(\\\\\"utf-8\\\\\") == self.provider.TEMPLATE\\\\n\\\\n    def test_cannot_start_auth_flow_feature_missing(self):\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=self.user)\\\\n\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        self.login_as(self.user)\\\\n\\\\n        with self.feature({\\\\\"organizations:sso-basic\\\\\": False}):\\\\n            resp = self.client.post(path, {\\\\\"provider\\\\\": \\\\\"dummy\\\\\", \\\\\"init\\\\\": True})\\\\n\\\\n        assert resp.status_code == 401\\\\n\\\\n    @patch(\\\\\"sentry.auth.helper.logger\\\\\")\\\\n    def test_basic_flow(self, logger):\\\\n        user = self.create_user(\\\\\"bar@example.com\\\\\")\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=user)\\\\n\\\\n        self.login_as(user)\\\\n        self.assert_basic_flow(user, organization)\\\\n\\\\n        # disable require 2fa logs not called\\\\n        assert not AuditLogEntry.objects.filter(\\\\n            target_object=organization.id, event=audit_log.get_event_id(\\\\\"ORG_EDIT\\\\\"), actor=user\\\\n        ).exists()\\\\n        assert not logger.info.called\\\\n\\\\n    @with_feature(\\\\\"organizations:customer-domains\\\\\")\\\\n    @patch(\\\\\"sentry.auth.helper.logger\\\\\")\\\\n    def test_basic_flow_customer_domain(self, logger):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n\\\\n        path = reverse(\\\\\"sentry-customer-domain-organization-auth-provider-settings\\\\\")\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.get(path, SERVER_NAME=f\\\\\"{organization.slug}.testserver\\\\\")\\\\n\\\\n        content = resp.content.decode(\\\\\"utf-8\\\\\")\\\\n        assert f\\\\\"http://{organization.slug}.testserver\\\\\" in content\\\\n        assert f\\\\\"http://{organization.slug}.testserver/issues\\\\\" in content\\\\n        assert f\\\\\"/organziations/{organization.slug}/issues\\\\\" not in content\\\\n\\\\n    @patch(\\\\\"sentry.auth.helper.logger\\\\\")\\\\n    @patch(\\\\\"sentry.auth.providers.dummy.DummyProvider.build_identity\\\\\")\\\\n    def test_basic_flow_error(self, build_identity, logger):\\\\n        build_identity.side_effect = IdentityNotValid()\\\\n\\\\n        user = self.create_user(\\\\\"bar@example.com\\\\\")\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=user)\\\\n\\\\n        self.login_as(user)\\\\n        self.assert_basic_flow(user, organization, expect_error=True)\\\\n\\\\n    @patch(\\\\\"sentry.auth.helper.logger\\\\\")\\\\n    def test_basic_flow__disable_require_2fa(self, logger):\\\\n        user = self.create_user(\\\\\"bar@example.com\\\\\")\\\\n        organization = self.create_organization(name=\\\\\"foo\\\\\", owner=user)\\\\n\\\\n        self.login_as(user)\\\\n        self.enroll_user_and_require_2fa(user, organization)\\\\n\\\\n        self.assert_basic_flow(user, organization)\\\\n        self.assert_require_2fa_disabled(user, organization, logger)\\\\n\\\\n    @patch(\\\\\"sentry.web.frontend.organization_auth_settings.email_unlink_notifications\\\\\")\\\\n    def test_disable_provider(self, email_unlink_notifications):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        om = self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(path, {\\\\\"op\\\\\": \\\\\"disable\\\\\"})\\\\n\\\\n        assert resp.status_code == 302\\\\n\\\\n        assert not AuthProvider.objects.filter(organization_id=organization.id).exists()\\\\n        assert not AuthProvider.objects.filter(id=auth_provider.id).exists()\\\\n\\\\n        om = OrganizationMember.objects.get(id=om.id)\\\\n\\\\n        assert not getattr(om.flags, \\\\\"sso:linked\\\\\")\\\\n        assert not User.objects.get(id=om.user_id).is_managed\\\\n\\\\n        assert email_unlink_notifications.delay.called\\\\n\\\\n    @patch(\\\\\"sentry.web.frontend.organization_auth_settings.email_unlink_notifications\\\\\")\\\\n    @with_feature(\\\\\"organizations:sso-basic\\\\\")\\\\n    def test_disable_partner_provider(self, email_unlink_notifications):\\\\n        organization, auth_provider = self.create_org_and_auth_provider(\\\\\"Fly.io\\\\\")\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        resp = self.client.post(path, {\\\\\"op\\\\\": \\\\\"disable\\\\\"})\\\\n        assert resp.status_code == 405\\\\n\\\\n    @patch(\\\\\"sentry.web.frontend.organization_auth_settings.email_unlink_notifications\\\\\")\\\\n    def test_superuser_disable_provider(self, email_unlink_notifications):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        with self.feature(\\\\\"organizations:sso-scim\\\\\"):\\\\n            auth_provider.enable_scim(self.user)\\\\n\\\\n        om = self.create_om_and_link_sso(organization)\\\\n\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        superuser = self.create_user(is_superuser=True)\\\\n        self.login_as(superuser, superuser=True)\\\\n\\\\n        with self.feature({\\\\\"organizations:sso-basic\\\\\": False}):\\\\n            resp = self.client.post(path, {\\\\\"op\\\\\": \\\\\"disable\\\\\"})\\\\n\\\\n        assert resp.status_code == 302\\\\n\\\\n        assert not AuthProvider.objects.filter(organization_id=organization.id).exists()\\\\n        assert not AuthProvider.objects.filter(id=auth_provider.id).exists()\\\\n\\\\n        om = OrganizationMember.objects.get(id=om.id)\\\\n\\\\n        assert not getattr(om.flags, \\\\\"sso:linked\\\\\")\\\\n        assert not User.objects.get(id=om.user_id).is_managed\\\\n\\\\n        assert email_unlink_notifications.delay.called\\\\n\\\\n        with pytest.raises(SentryAppInstallationForProvider.DoesNotExist):\\\\n            SentryAppInstallationForProvider.objects.get(\\\\n                organization_id=self.organization.id, provider=\\\\\"dummy_scim\\\\\"\\\\n            )\\\\n\\\\n    def test_edit_sso_settings(self):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(\\\\n                path, {\\\\\"op\\\\\": \\\\\"settings\\\\\", \\\\\"require_link\\\\\": False, \\\\\"default_role\\\\\": \\\\\"owner\\\\\"}\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n        assert getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        organization = Organization.objects.get(id=organization.id)\\\\n        assert organization.default_role == \\\\\"owner\\\\\"\\\\n\\\\n        result = AuditLogEntry.objects.filter(\\\\n            organization_id=organization.id,\\\\n            target_object=auth_provider.id,\\\\n            event=audit_log.get_event_id(\\\\\"SSO_EDIT\\\\\"),\\\\n            actor=self.user,\\\\n        )[0]\\\\n\\\\n        assert result.data == {\\\\\"require_link\\\\\": \\\\\"to False\\\\\", \\\\\"default_role\\\\\": \\\\\"to owner\\\\\"}\\\\n\\\\n    def test_edit_sso_settings__sso_required(self):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(\\\\n                path, {\\\\\"op\\\\\": \\\\\"settings\\\\\", \\\\\"require_link\\\\\": False, \\\\\"default_role\\\\\": \\\\\"member\\\\\"}\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n        assert getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        organization = Organization.objects.get(id=organization.id)\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n\\\\n        result = AuditLogEntry.objects.filter(\\\\n            organization_id=organization.id,\\\\n            target_object=auth_provider.id,\\\\n            event=audit_log.get_event_id(\\\\\"SSO_EDIT\\\\\"),\\\\n            actor=self.user,\\\\n        )[0]\\\\n\\\\n        assert result.data == {\\\\\"require_link\\\\\": \\\\\"to False\\\\\"}\\\\n\\\\n    def test_edit_sso_settings__default_role(self):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(\\\\n                path, {\\\\\"op\\\\\": \\\\\"settings\\\\\", \\\\\"require_link\\\\\": True, \\\\\"default_role\\\\\": \\\\\"owner\\\\\"}\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        organization = Organization.objects.get(id=organization.id)\\\\n        assert organization.default_role == \\\\\"owner\\\\\"\\\\n\\\\n        result = AuditLogEntry.objects.filter(\\\\n            organization_id=organization.id,\\\\n            target_object=auth_provider.id,\\\\n            event=audit_log.get_event_id(\\\\\"SSO_EDIT\\\\\"),\\\\n            actor=self.user,\\\\n        )[0]\\\\n\\\\n        assert result.data == {\\\\\"default_role\\\\\": \\\\\"to owner\\\\\"}\\\\n\\\\n    def test_edit_sso_settings__no_change(self):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature(\\\\\"organizations:sso-basic\\\\\"):\\\\n            resp = self.client.post(\\\\n                path, {\\\\\"op\\\\\": \\\\\"settings\\\\\", \\\\\"require_link\\\\\": True, \\\\\"default_role\\\\\": \\\\\"member\\\\\"}\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        organization = Organization.objects.get(id=organization.id)\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n\\\\n        assert not AuditLogEntry.objects.filter(\\\\n            organization_id=organization.id, event=audit_log.get_event_id(\\\\\"SSO_EDIT\\\\\")\\\\n        ).exists()\\\\n\\\\n    def test_edit_sso_settings__scim(self):\\\\n        organization, auth_provider = self.create_org_and_auth_provider()\\\\n        self.create_om_and_link_sso(organization)\\\\n        path = reverse(\\\\\"sentry-organization-auth-provider-settings\\\\\", args=[organization.slug])\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"allow_unlinked\\\\\")\\\\n        assert organization.default_role == \\\\\"member\\\\\"\\\\n        self.login_as(self.user, organization_id=organization.id)\\\\n\\\\n        with self.feature({\\\\\"organizations:sso-basic\\\\\": True}):\\\\n            resp = self.client.post(\\\\n                path,\\\\n                {\\\\n                    \\\\\"op\\\\\": \\\\\"settings\\\\\",\\\\n                    \\\\\"require_link\\\\\": True,\\\\n                    \\\\\"enable_scim\\\\\": True,\\\\n                    \\\\\"default_role\\\\\": \\\\\"member\\\\\",\\\\n                },\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n        assert getattr(auth_provider.flags, \\\\\"scim_enabled\\\\\")\\\\n        assert auth_provider.get_scim_token() is not None\\\\n        assert (\\\\n            get_scim_url(\\\\n                auth_provider,\\\\n                organization_service.get_organization_by_id(\\\\n                    id=auth_provider.organization_id\\\\n                ).organization,\\\\n            )\\\\n            is not None\\\\n        )\\\\n\\\\n        # \\\\\"add\\\\\" some scim users\\\\n        u1 = self.create_user()\\\\n        not_scim_member = OrganizationMember.objects.create(\\\\n            user_id=u1.id, organization=organization\\\\n        )\\\\n        not_scim_member.save()\\\\n        u2 = self.create_user()\\\\n        scim_member = OrganizationMember.objects.create(user_id=u2.id, organization=organization)\\\\n        scim_member.flags[\\\\\"idp:provisioned\\\\\"] = True\\\\n        scim_member.save()\\\\n        u3 = self.create_user()\\\\n        scim_role_restricted_user = OrganizationMember.objects.create(\\\\n            user_id=u3.id, organization=organization\\\\n        )\\\\n        scim_role_restricted_user.flags[\\\\\"idp:provisioned\\\\\"] = True\\\\n        scim_role_restricted_user.flags[\\\\\"idp:role-restricted\\\\\"] = True\\\\n        scim_role_restricted_user.save()\\\\n\\\\n        with self.feature({\\\\\"organizations:sso-basic\\\\\": True}):\\\\n            resp = self.client.post(\\\\n                path,\\\\n                {\\\\n                    \\\\\"op\\\\\": \\\\\"settings\\\\\",\\\\n                    \\\\\"require_link\\\\\": True,\\\\n                    \\\\\"enable_scim\\\\\": False,\\\\n                    \\\\\"default_role\\\\\": \\\\\"member\\\\\",\\\\n                },\\\\n            )\\\\n\\\\n        assert resp.status_code == 200\\\\n        auth_provider = AuthProvider.objects.get(organization_id=organization.id)\\\\n\\\\n        assert not getattr(auth_provider.flags, \\\\\"scim_enabled\\\\\")\\\\n        assert (\\\\n\"}', '{\"file_content\": \"import {useCallback, useEffect, useRef, useState} from \\'react\\';\\\\n\\\\nimport type {Organization} from \\'sentry/types\\';\\\\nimport type EventView from \\'sentry/utils/discover/eventView\\';\\\\nimport fetchReplayList from \\'sentry/utils/replays/fetchReplayList\\';\\\\nimport useApi from \\'sentry/utils/useApi\\';\\\\nimport {useLocation} from \\'sentry/utils/useLocation\\';\\\\nimport type {ReplayListLocationQuery} from \\'sentry/views/replays/types\\';\\\\n\\\\ntype Options = {\\\\n  eventView: EventView;\\\\n  organization: Organization;\\\\n};\\\\n\\\\ntype State = Awaited<ReturnType<typeof fetchReplayList>>;\\\\n\\\\ntype Result = State;\\\\n\\\\nfunction useReplayList({eventView, organization}: Options): Result {\\\\n  const api = useApi();\\\\n  const location = useLocation<ReplayListLocationQuery>();\\\\n  const querySearchRef = useRef<string>();\\\\n\\\\n  const [data, setData] = useState<State>({\\\\n    fetchError: undefined,\\\\n    isFetching: true,\\\\n    pageLinks: null,\\\\n    replays: [],\\\\n  });\\\\n\\\\n  const loadReplays = useCallback(\\\\n    async (abortSignal: AbortSignal) => {\\\\n      setData(prev => ({\\\\n        ...prev,\\\\n        isFetching: true,\\\\n      }));\\\\n      const response = await fetchReplayList({\\\\n        api,\\\\n        organization,\\\\n        location,\\\\n        eventView,\\\\n      });\\\\n\\\\n      if (!abortSignal.aborted) {\\\\n        setData(response);\\\\n      }\\\\n    },\\\\n    [api, organization, location, eventView]\\\\n  );\\\\n\\\\n  useEffect(() => {\\\\n    if (!querySearchRef.current || querySearchRef.current !== location.search) {\\\\n      const controller = new AbortController();\\\\n      querySearchRef.current = location.search;\\\\n\\\\n      loadReplays(controller.signal);\\\\n      return () => {\\\\n        controller.abort();\\\\n      };\\\\n    }\\\\n    return () => {};\\\\n  }, [loadReplays, location.search]);\\\\n\\\\n  return data;\\\\n}\\\\n\\\\nexport default useReplayList;\\\\n\\\\n\"}', '{\"file_content\": \"import os\\\\nimport unittest\\\\nfrom collections import namedtuple\\\\n\\\\nfrom securedrop_client import state\\\\nfrom securedrop_client.api_jobs.sync import MetadataSyncJob, _update_state\\\\nfrom securedrop_client.db import User\\\\nfrom tests import factory\\\\n\\\\nwith open(os.path.join(os.path.dirname(__file__), \\\\\"..\\\\\", \\\\\"files\\\\\", \\\\\"test-key.gpg.pub.asc\\\\\")) as f:\\\\n    PUB_KEY = f.read()\\\\n\\\\nSource = namedtuple(\\\\\"Source\\\\\", [\\\\\"uuid\\\\\"])\\\\nSubmission = namedtuple(\\\\\"Submission\\\\\", [\\\\\"uuid\\\\\", \\\\\"source_uuid\\\\\", \\\\\"is_file\\\\\", \\\\\"is_downloaded\\\\\"])\\\\nFile = namedtuple(\\\\\"File\\\\\", [\\\\\"is_downloaded\\\\\"])\\\\n\\\\nTIMEOUT_OVERRIDE = 600  # sec\\\\n\\\\n\\\\nclass TestUpdateState(unittest.TestCase):\\\\n    def setUp(self):\\\\n        self._state = state.State()\\\\n        self._sources = []\\\\n        self._submissions = []\\\\n\\\\n    def test_handles_missing_files_gracefully(self):\\\\n        self._sources = [Source(uuid=\\\\\"3\\\\\"), Source(uuid=\\\\\"4\\\\\")]\\\\n        self._submissions = [\\\\n            Submission(uuid=\\\\\"6\\\\\", source_uuid=\\\\\"3\\\\\", is_file=lambda: True, is_downloaded=True),\\\\n            Submission(uuid=\\\\\"7\\\\\", source_uuid=\\\\\"4\\\\\", is_file=lambda: True, is_downloaded=True),\\\\n            Submission(uuid=\\\\\"8\\\\\", source_uuid=\\\\\"3\\\\\", is_file=lambda: False, is_downloaded=True),\\\\n            Submission(uuid=\\\\\"9\\\\\", source_uuid=\\\\\"3\\\\\", is_file=lambda: True, is_downloaded=False),\\\\n        ]\\\\n\\\\n        _update_state(self._state, self._submissions)\\\\n        assert self._state.file(\\\\\"6\\\\\")\\\\n        assert self._state.file(\\\\\"7\\\\\")\\\\n        assert not self._state.file(\\\\\"8\\\\\")\\\\n        assert self._state.file(\\\\\"9\\\\\")\\\\n\\\\n\\\\ndef test_MetadataSyncJob_has_default_timeout(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    remote_user = factory.RemoteUser()\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n    assert api_client.default_request_timeout == job.DEFAULT_REQUEST_TIMEOUT\\\\n\\\\n\\\\ndef test_MetadataSyncJob_takes_overriden_timeout(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    remote_user = factory.RemoteUser()\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_user])\\\\n\\\\n    os.environ[\\\\\"SDEXTENDEDTIMEOUT\\\\\"] = str(TIMEOUT_OVERRIDE)  # environment value must be string\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n    assert api_client.default_request_timeout == TIMEOUT_OVERRIDE\\\\n\\\\n    # Don\\'t pollute the environment for subsequent/out-of-order tests.\\\\n    del os.environ[\\\\\"SDEXTENDEDTIMEOUT\\\\\"]\\\\n\\\\n\\\\ndef test_MetadataSyncJob_creates_new_user(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    remote_user = factory.RemoteUser()\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    local_user = session.query(User).filter_by(uuid=remote_user.uuid).one_or_none()\\\\n    assert local_user\\\\n\\\\n\\\\ndef test_MetadataSyncJob_creates_new_special_deleted_user(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    remote_user = factory.RemoteUser(username=\\\\\"deleted\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    local_user = session.query(User).filter_by(uuid=remote_user.uuid).one_or_none()\\\\n    assert local_user.deleted\\\\n\\\\n\\\\ndef test_MetadataSyncJob_updates_application_state(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    some_file = factory.RemoteFile()\\\\n    some_message = factory.RemoteMessage()\\\\n    another_file = factory.RemoteFile()\\\\n    submissions = [some_file, some_message, another_file]\\\\n    mocker.patch(\\\\n        \\\\\"securedrop_client.api_jobs.sync.get_remote_data\\\\\", return_value=([], submissions, [])\\\\n    )\\\\n\\\\n    app_state = state.State()\\\\n    state_updater = mocker.patch(\\\\\"securedrop_client.api_jobs.sync._update_state\\\\\")\\\\n\\\\n    exising_user = factory.User(uuid=\\\\\"abc123-ima-uuid\\\\\")\\\\n    session.add(exising_user)\\\\n\\\\n    job = MetadataSyncJob(homedir, app_state)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    state_updater.assert_called_once_with(app_state, submissions)\\\\n\\\\n\\\\ndef test_MetadataSyncJob_updates_existing_user(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    remote_user = factory.RemoteUser(\\\\n        uuid=\\\\\"abc123-ima-uuid\\\\\",\\\\n        username=\\\\\"new-username\\\\\",\\\\n        first_name=\\\\\"NewFirstName\\\\\",\\\\n        last_name=\\\\\"NewLastName\\\\\",\\\\n    )\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_user])\\\\n\\\\n    exising_user = factory.User(uuid=\\\\\"abc123-ima-uuid\\\\\")\\\\n    session.add(exising_user)\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    assert exising_user.username == \\\\\"new-username\\\\\"\\\\n    assert exising_user.firstname == \\\\\"NewFirstName\\\\\"\\\\n    assert exising_user.lastname == \\\\\"NewLastName\\\\\"\\\\n\\\\n\\\\ndef test_MetadataSyncJob_deletes_user(mocker, homedir, session, session_maker):\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[])\\\\n\\\\n    user = factory.User()\\\\n    session.add(user)\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    local_user = session.query(User).filter_by(uuid=user.uuid).one_or_none()\\\\n    assert not local_user\\\\n\\\\n\\\\ndef test_MetadataSyncJob_does_not_delete_reserved_deleted_user(mocker, homedir, session):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Ensure that we do not delete the local \\\\\"deleted\\\\\" user account unless a \\\\\"deleted\\\\\" user account\\\\n    exists on the server that we can replace it with.\\\\n\\\\n    This test is to ensure that we support an edge case that can occur on a pre-2.2.0 server\\\\n    (before the server added support for creating an actual deleted user account).\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[])\\\\n\\\\n    reserved_deleted_user = factory.User(username=\\\\\"deleted\\\\\")\\\\n    session.add(reserved_deleted_user)\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    assert session.query(User).filter_by(username=\\\\\"deleted\\\\\").one_or_none()\\\\n\\\\n\\\\ndef test_MetadataSyncJob_reassociates_draftreplies_to_new_account_before_deleting_user(\\\\n    mocker, homedir, session\\\\n):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Ensure that any draft replies sent by a user that is about to be deleted are re-associated\\\\n    to a new \\\\\"deleted\\\\\" user account that exists on the server.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    user_to_delete_with_drafts = factory.User()\\\\n    session.add(user_to_delete_with_drafts)\\\\n    session.commit()\\\\n    draftreply = factory.DraftReply(journalist_id=user_to_delete_with_drafts.id)\\\\n    session.add(draftreply)\\\\n    session.commit()\\\\n\\\\n    remote_reserved_deleted_user = factory.RemoteUser(username=\\\\\"deleted\\\\\")\\\\n    # Set up get_users so that `user_to_delete_with_drafts` will be deleted and\\\\n    # `remote_reserved_deleted_user` will be created since it exists on the server\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_reserved_deleted_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    # Ensure the account was deleted\\\\n    deleted_user = session.query(User).filter_by(uuid=user_to_delete_with_drafts.uuid).one_or_none()\\\\n    assert not deleted_user\\\\n    # Ensure the \\\\\"deleted\\\\\" user account that exists on the server was created locally\\\\n    reserved_deleted_user = session.query(User).filter_by(username=\\\\\"deleted\\\\\").one_or_none()\\\\n    assert reserved_deleted_user\\\\n    assert reserved_deleted_user.uuid == remote_reserved_deleted_user.uuid\\\\n    # Ensure draft replies are reassociated\\\\n    assert draftreply.journalist_id == reserved_deleted_user.id\\\\n\\\\n\\\\ndef test_MetadataSyncJob_reassociates_draftreplies_to_existing_account_before_deleting_user(\\\\n    mocker, homedir, session\\\\n):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Ensure that any draft replies sent by a user that is about to be deleted are re-associated\\\\n    to an existing \\\\\"deleted\\\\\" user account.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    user_to_delete_with_drafts = factory.User()\\\\n    session.add(user_to_delete_with_drafts)\\\\n    session.commit()\\\\n    draftreply = factory.DraftReply(journalist_id=user_to_delete_with_drafts.id)\\\\n    session.add(draftreply)\\\\n    session.commit()\\\\n\\\\n    local_reserved_deleted_user = factory.User(username=\\\\\"deleted\\\\\")\\\\n    session.add(local_reserved_deleted_user)\\\\n    session.commit()\\\\n\\\\n    remote_reserved_deleted_user = factory.RemoteUser(\\\\n        username=\\\\\"deleted\\\\\", uuid=local_reserved_deleted_user.uuid\\\\n    )\\\\n    # Set up get_users so that `user_to_delete_with_drafts` will be deleted and\\\\n    # `remote_reserved_deleted_user` will replace `local_reserved_deleted_user`\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_reserved_deleted_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    # Ensure the account was deleted\\\\n    deleted_user = session.query(User).filter_by(uuid=user_to_delete_with_drafts.uuid).one_or_none()\\\\n    assert not deleted_user\\\\n    # Ensure the \\\\\"deleted\\\\\" user account still exists\\\\n    reserved_deleted_user = session.query(User).filter_by(username=\\\\\"deleted\\\\\").one_or_none()\\\\n    assert reserved_deleted_user\\\\n    assert reserved_deleted_user.uuid == local_reserved_deleted_user.uuid\\\\n    # Ensure draft replies are reassociated\\\\n    assert draftreply.journalist_id == reserved_deleted_user.id\\\\n\\\\n\\\\ndef test_MetadataSyncJob_reassociates_draftreplies_to_new_local_account_before_deleting_user(\\\\n    mocker, homedir, session\\\\n):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Ensure that any draft replies, sent by a user that is about to be deleted, are re-associated\\\\n    to a new \\\\\"deleted\\\\\" user account that only exists locally.\\\\n\\\\n    This test is to ensure that we support an edge case that can occur on a pre-2.2.0 server\\\\n    (before the server added support for creating an actual deleted user account).\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    user_to_delete_with_drafts = factory.User()\\\\n    session.add(user_to_delete_with_drafts)\\\\n    session.commit()\\\\n\\\\n    draftreply = factory.DraftReply(journalist_id=user_to_delete_with_drafts.id)\\\\n    session.add(draftreply)\\\\n    # Set up get_users so that `user_to_delete_with_drafts` will be deleted\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    # Ensure the account was deleted\\\\n    deleted_user = session.query(User).filter_by(uuid=user_to_delete_with_drafts.uuid).one_or_none()\\\\n    assert not deleted_user\\\\n    # Ensure the \\\\\"deleted\\\\\" user account exists\\\\n    reserved_deleted_user = session.query(User).filter_by(username=\\\\\"deleted\\\\\").one_or_none()\\\\n    assert reserved_deleted_user\\\\n    # Ensure draft replies are reassociated\\\\n    assert draftreply.journalist_id == reserved_deleted_user.id\\\\n\\\\n\\\\ndef test_MetadataSyncJob_replaces_reserved_deleted_user_account(mocker, homedir, session):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Ensure that we delete the local \\\\\"deleted\\\\\" user account if it is being replaced by a new account\\\\n    from the server and that any draft replies are re-associated appropriately.\\\\n\\\\n    This test is to ensure that we support an edge case that can occur on a pre-2.2.0 server\\\\n    (before the server added support for creating an actual deleted user account).\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    local_reserved_deleted_user = factory.User(username=\\\\\"deleted\\\\\")\\\\n    session.add(local_reserved_deleted_user)\\\\n    session.commit()\\\\n    draftreply = factory.DraftReply(journalist_id=local_reserved_deleted_user.id)\\\\n    session.add(draftreply)\\\\n    session.commit()\\\\n\\\\n    remote_reserved_deleted_user = factory.RemoteUser(username=\\\\\"deleted\\\\\")\\\\n    # Set up get_users so that `user_to_delete_with_drafts` will be deleted and\\\\n    # `remote_reserved_deleted_user` will replace `local_reserved_deleted_user`\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n    api_client.get_users = mocker.MagicMock(return_value=[remote_reserved_deleted_user])\\\\n\\\\n    job = MetadataSyncJob(homedir)\\\\n    job.call_api(api_client, session)\\\\n\\\\n    # Ensure `remote_reserved_deleted_user` replaced `local_reserved_deleted_user` and that the\\\\n    # draft reply was reassociated to the new \\\\\"deleted\\\\\" user account.\\\\n    reserved_deleted_user = session.query(User).filter_by(username=\\\\\"deleted\\\\\").one_or_none()\\\\n    assert reserved_deleted_user\\\\n    assert reserved_deleted_user.uuid == remote_reserved_deleted_user.uuid\\\\n    assert draftreply.journalist_id == reserved_deleted_user.id\\\\n\\\\n\\\\ndef test_MetadataSyncJob_success(mocker, homedir, session, session_maker):\\\\n    job = MetadataSyncJob(homedir)\\\\n\\\\n    mock_source = factory.RemoteSource(\\\\n        key={\\\\\"type\\\\\": \\\\\"PGP\\\\\", \\\\\"public\\\\\": PUB_KEY, \\\\\"fingerprint\\\\\": \\\\\"123456ABC\\\\\"}\\\\n    )\\\\n\\\\n    mock_get_remote_data = mocker.patch(\\\\n        \\\\\"securedrop_client.api_jobs.sync.get_remote_data\\\\\", return_value=([mock_source], [], [])\\\\n    )\\\\n\\\\n    user = factory.User(uuid=\\\\\"mock1\\\\\", username=\\\\\"mock1\\\\\", firstname=\\\\\"mock1\\\\\", lastname=\\\\\"mock1\\\\\")\\\\n    session.add(user)\\\\n\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n\\\\n    user = {\\\\\"uuid\\\\\": \\\\\"mock1\\\\\", \\\\\"username\\\\\": \\\\\"mock1\\\\\", \\\\\"first_name\\\\\": \\\\\"mock1\\\\\", \\\\\"last_name\\\\\": \\\\\"mock1\\\\\"}\\\\n    mocker.patch.object(api_client, \\\\\"get_current_user\\\\\", return_value=user)\\\\n\\\\n    job.call_api(api_client, session)\\\\n\\\\n    assert mock_get_remote_data.call_count == 1\\\\n\\\\n\\\\ndef test_MetadataSyncJob_success_current_user_name_change(mocker, homedir, session, session_maker):\\\\n    job = MetadataSyncJob(homedir)\\\\n\\\\n    mock_source = factory.RemoteSource(\\\\n        key={\\\\\"type\\\\\": \\\\\"PGP\\\\\", \\\\\"public\\\\\": PUB_KEY, \\\\\"fingerprint\\\\\": \\\\\"123456ABC\\\\\"}\\\\n    )\\\\n\\\\n    mock_get_remote_data = mocker.patch(\\\\n        \\\\\"securedrop_client.api_jobs.sync.get_remote_data\\\\\", return_value=([mock_source], [], [])\\\\n    )\\\\n\\\\n    user = factory.User(uuid=\\\\\"mock1\\\\\", username=\\\\\"mock1\\\\\", firstname=\\\\\"mock1\\\\\", lastname=\\\\\"mock1\\\\\")\\\\n    session.add(user)\\\\n\\\\n    api_client = mocker.patch(\\\\\"securedrop_client.logic.sdclientapi.API\\\\\")\\\\n\\\\n    user = {\\\\\"uuid\\\\\": \\\\\"mock2\\\\\", \\\\\"username\\\\\": \\\\\"mock2\\\\\", \\\\\"first_name\\\\\": \\\\\"mock2\\\\\", \\\\\"last_name\\\\\": \\\\\"mock2\\\\\"}\\\\n    mocker.patch.object(api_client, \\\\\"get_current_user\\\\\", return_value=user)\\\\n\\\\n    job.call_api(api_client, session)\\\\n\\\\n    assert mock_get_remote_data.call_count == 1\\\\n\\\\n\\\\ndef test_MetadataSyncJob_success_with_missing_key(mocker, homedir, session, session_maker):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    Check that we can gracefully handle missing source keys.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    job = MetadataSyncJob(homedir)\\\\n\\\\n    mock_source = factory.RemoteSource(key={\\\\\"type\\\\\": \\\\\"PGP\\\\\", \\\\\"public\\\\\": \\\\\"\\\\\", \\\\\"fingerprint\\\\\": \\\\\"\\\\\"})\\\\n\\\\n    mock_get_remote_data = mocker.patch(\\\\n        \\\\\"securedrop_client.api_jobs.sync.get_remote_data\\\\\", return_value=([mock_source], [], [])\\\\n    )\\\\n\\\\n    api_client = mocker.MagicMock()\\\\n    api_client.default_request_timeout = mocker.MagicMock()\\\\n\\\\n    job.call_api(api_client, session)\\\\n\\\\n    assert mock_get_remote_data.call_count == 1\\\\n\\\\n\"}', '{\"file_content\": \"import os\\\\nfrom unittest.mock import MagicMock, patch\\\\n\\\\nimport pytest\\\\n\\\\nfrom securedrop_client.config import Config\\\\n\\\\n\\\\n@patch.dict(os.environ, {\\\\\"SD_SUBMISSION_KEY_FPR\\\\\": \\\\\"foobar\\\\\"})\\\\ndef test_config_from_env():\\\\n    config = Config.load()\\\\n\\\\n    assert config.journalist_key_fingerprint == \\\\\"foobar\\\\\"\\\\n    assert config.gpg_domain is None\\\\n\\\\n\\\\ndef test_config_from_qubesdb():\\\\n    qubesdb = MagicMock()\\\\n    QubesDB = MagicMock()\\\\n    QubesDB.read = MagicMock(return_value=\\\\\"foobar\\\\\")\\\\n    qubesdb.QubesDB = MagicMock(return_value=QubesDB)\\\\n\\\\n    with patch.dict(\\\\\"sys.modules\\\\\", qubesdb=qubesdb):\\\\n        config = Config.load()\\\\n\\\\n    assert config.journalist_key_fingerprint == \\\\\"foobar\\\\\"\\\\n\\\\n\\\\ndef test_config_from_qubesdb_key_missing():\\\\n    qubesdb = MagicMock()\\\\n    QubesDB = MagicMock()\\\\n    QubesDB.read = MagicMock(return_value=\\\\\"\\\\\")\\\\n    qubesdb.QubesDB = MagicMock(return_value=QubesDB)\\\\n\\\\n    with (\\\\n        patch.dict(\\\\\"sys.modules\\\\\", qubesdb=qubesdb),\\\\n        pytest.raises(KeyError, match=r\\\\\"Could not read from QubesDB\\\\\"),\\\\n    ):\\\\n        Config.load()\\\\n\\\\n\"}', '{\"file_content\": \"from abc import ABC, abstractmethod\\\\nfrom typing import List, Optional, Sequence, Type, cast\\\\n\\\\nfrom snuba.datasets.storage import (\\\\n    ReadableTableStorage,\\\\n    StorageAndMappers,\\\\n    WritableTableStorage,\\\\n)\\\\nfrom snuba.query.logical import Query\\\\nfrom snuba.query.query_settings import QuerySettings\\\\nfrom snuba.utils.registered_class import RegisteredClass\\\\n\\\\n\\\\nclass QueryStorageSelectorError(Exception):\\\\n    pass\\\\n\\\\n\\\\nclass QueryStorageSelector(ABC, metaclass=RegisteredClass):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    The component provided by a dataset and used at the beginning of the\\\\n    execution of a query to pick the storage query should be executed onto.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    @classmethod\\\\n    def config_key(cls) -> str:\\\\n        return cls.__name__\\\\n\\\\n    @classmethod\\\\n    def get_from_name(cls, name: str) -> Type[\\\\\"QueryStorageSelector\\\\\"]:\\\\n        return cast(Type[\\\\\"QueryStorageSelector\\\\\"], cls.class_from_name(name))\\\\n\\\\n    @abstractmethod\\\\n    def select_storage(\\\\n        self,\\\\n        query: Query,\\\\n        query_settings: QuerySettings,\\\\n        storage_and_mappers: List[StorageAndMappers],\\\\n    ) -> StorageAndMappers:\\\\n        raise NotImplementedError\\\\n\\\\n    def get_readable_storage_mapping(\\\\n        self, storage_and_mappers: Sequence[StorageAndMappers]\\\\n    ) -> Optional[StorageAndMappers]:\\\\n        return next(\\\\n            (\\\\n                storage\\\\n                for storage in storage_and_mappers\\\\n                if type(storage.storage) is ReadableTableStorage\\\\n            ),\\\\n            None,\\\\n        )\\\\n\\\\n    def get_writable_storage_mapping(\\\\n        self, storage_and_mappers: Sequence[StorageAndMappers]\\\\n    ) -> Optional[StorageAndMappers]:\\\\n        return next(\\\\n            (\\\\n                storage\\\\n                for storage in storage_and_mappers\\\\n                if isinstance(storage.storage, WritableTableStorage)\\\\n            ),\\\\n            None,\\\\n        )\\\\n\\\\n\\\\nclass DefaultQueryStorageSelector(QueryStorageSelector):\\\\n    \\\\\"\\\\\"\\\\\"\\\\n    A default query storage selector which chooses the only storage specified in config.\\\\n    Entities which define multiple storages should not use this selector and should use\\\\n    custom ones.\\\\n    \\\\\"\\\\\"\\\\\"\\\\n\\\\n    def select_storage(\\\\n        self,\\\\n        query: Query,\\\\n        query_settings: QuerySettings,\\\\n        storage_and_mappers: List[StorageAndMappers],\\\\n    ) -> StorageAndMappers:\\\\n        assert len(storage_and_mappers) == 1\\\\n        return storage_and_mappers[0]\\\\n\\\\n\"}', '{\"file_content\": \"import * as React from \\'react\\'\\\\n\\\\nimport { useHealthQuery } from \\'@opentrons/react-api-client\\'\\\\n\\\\nconst ROBOT_HEALTH_POLL_MS = 5000\\\\n\\\\nexport const INIT_STATUS = {\\\\n  INITIALIZING: \\'INITIALIZING\\',\\\\n  SUCCEEDED: \\'SUCCEEDED\\',\\\\n  FAILED: \\'FAILED\\',\\\\n} as const\\\\n\\\\nexport type RobotInitializationStatus =\\\\n  | typeof INIT_STATUS[keyof typeof INIT_STATUS]\\\\n  | null\\\\n\\\\nexport function useRobotInitializationStatus(): RobotInitializationStatus {\\\\n  const responseStatusCode = React.useRef<number | null>(null)\\\\n\\\\n  useHealthQuery({\\\\n    refetchInterval: ROBOT_HEALTH_POLL_MS,\\\\n    onSuccess: data => (responseStatusCode.current = data?.status ?? null),\\\\n    onError: error =>\\\\n      (responseStatusCode.current = error.response?.status ?? null),\\\\n  })\\\\n\\\\n  let status: RobotInitializationStatus\\\\n  switch (responseStatusCode.current) {\\\\n    case 503:\\\\n      status = INIT_STATUS.INITIALIZING\\\\n      break\\\\n    case 200:\\\\n      status = INIT_STATUS.SUCCEEDED\\\\n      break\\\\n    case 500:\\\\n      status = INIT_STATUS.FAILED\\\\n      break\\\\n    default:\\\\n      status = null\\\\n      break\\\\n  }\\\\n\\\\n  return status\\\\n}\\\\n\\\\n\"}', 'The provided path is a directory, not a file.', '{\"file_content\": \"import { createStore, combineReducers, applyMiddleware, compose } from \\'redux\\'\\\\nimport thunk from \\'redux-thunk\\'\\\\nimport { trackEventMiddleware } from \\'./analytics/middleware\\'\\\\nimport { makePersistSubscriber, rehydratePersistedAction } from \\'./persist\\'\\\\nimport { fileUploadMessage } from \\'./load-file/actions\\'\\\\nimport { makeTimelineMiddleware } from \\'./timelineMiddleware/makeTimelineMiddleware\\'\\\\nimport { rootReducer as analyticsReducer } from \\'./analytics\\'\\\\nimport { rootReducer as dismissReducer } from \\'./dismiss\\'\\\\nimport { rootReducer as featureFlagsReducer } from \\'./feature-flags\\'\\\\nimport { rootReducer as fileDataReducer } from \\'./file-data\\'\\\\nimport { rootReducer as labwareIngredReducer } from \\'./labware-ingred/reducers\\'\\\\nimport { rootReducer as loadFileReducer } from \\'./load-file\\'\\\\nimport { rootReducer as navigationReducer } from \\'./navigation\\'\\\\nimport { rootReducer as stepFormsReducer } from \\'./step-forms\\'\\\\nimport { rootReducer as tutorialReducer } from \\'./tutorial\\'\\\\nimport { rootReducer as uiReducer } from \\'./ui\\'\\\\nimport { rootReducer as wellSelectionReducer } from \\'./well-selection/reducers\\'\\\\nimport type {\\\\n  Store,\\\\n  Reducer,\\\\n  CombinedState,\\\\n  StoreEnhancer,\\\\n  Middleware,\\\\n} from \\'redux\\'\\\\nimport type { BaseState, Action } from \\'./types\\'\\\\n\\\\nconst timelineMiddleware = makeTimelineMiddleware()\\\\n\\\\nfunction getRootReducer(): Reducer<BaseState, Action> {\\\\n  const rootReducer = combineReducers<BaseState>({\\\\n    analytics: analyticsReducer,\\\\n    dismiss: dismissReducer,\\\\n    featureFlags: featureFlagsReducer,\\\\n    fileData: fileDataReducer,\\\\n    labwareIngred: labwareIngredReducer,\\\\n    loadFile: loadFileReducer,\\\\n    navigation: navigationReducer,\\\\n    stepForms: stepFormsReducer,\\\\n    tutorial: tutorialReducer,\\\\n    ui: uiReducer,\\\\n    wellSelection: wellSelectionReducer,\\\\n  })\\\\n  // TODO: Ian 2019-06-25 consider making file loading non-committal\\\\n  // so UNDO_LOAD_FILE doesnt\\' just reset Redux state\\\\n  return (state, action) => {\\\\n    if (\\\\n      action.type === \\'LOAD_FILE\\' ||\\\\n      action.type === \\'CREATE_NEW_PROTOCOL\\' ||\\\\n      action.type === \\'UNDO_LOAD_FILE\\'\\\\n    ) {\\\\n      // reset entire state, rehydrate from localStorage\\\\n      const resetState = rootReducer(undefined, rehydratePersistedAction())\\\\n\\\\n      if (action.type === \\'LOAD_FILE\\') {\\\\n        try {\\\\n          return rootReducer(resetState, action)\\\\n        } catch (e) {\\\\n          console.error(e)\\\\n          if (e instanceof Error) {\\\\n            // something in the reducers went wrong, show it to the user for bug report\\\\n            return rootReducer(\\\\n              state as CombinedState<BaseState>,\\\\n              fileUploadMessage({\\\\n                isError: true,\\\\n                errorType: \\'INVALID_JSON_FILE\\',\\\\n                errorMessage: e.message,\\\\n              })\\\\n            )\\\\n          }\\\\n        }\\\\n      }\\\\n\\\\n      return rootReducer(resetState, action)\\\\n    }\\\\n\\\\n    // pass-thru\\\\n    return rootReducer(state, action)\\\\n  }\\\\n}\\\\n\\\\nexport type StoreType = Store<BaseState, Action>\\\\n\\\\nexport function configureStore(): StoreType {\\\\n  const reducer = getRootReducer()\\\\n  const composeEnhancers: any =\\\\n    window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ || compose\\\\n  const store = createStore(\\\\n    reducer,\\\\n    /* preloadedState, */\\\\n    composeEnhancers(\\\\n      applyMiddleware(\\\\n        timelineMiddleware as Middleware<BaseState, Record<string, any>, any>,\\\\n        thunk,\\\\n        trackEventMiddleware as Middleware<BaseState, Record<string, any>, any>\\\\n      )\\\\n    ) as StoreEnhancer<unknown, unknown>\\\\n  )\\\\n  // initial rehydration, and persistence subscriber\\\\n  store.dispatch(rehydratePersistedAction())\\\\n  store.subscribe(makePersistSubscriber(store))\\\\n\\\\n  global.enablePrereleaseMode = () => {\\\\n    store.dispatch({\\\\n      type: \\'SET_FEATURE_FLAGS\\',\\\\n      payload: {\\\\n        PRERELEASE_MODE: true,\\\\n      },\\\\n    })\\\\n  }\\\\n\\\\n  return store\\\\n}\\\\n\"}', '{\"file_content\": \"from PyQt5.QtGui import QPalette\\\\n\\\\n\\\\ndef test_styles(modal_dialog):\\\\n    error_details = modal_dialog.error_details\\\\n\\\\n    assert error_details.getContentsMargins() == (36, 0, 40, 0)\\\\n    assert error_details.palette().color(QPalette.Foreground).name() == \\\\\"#ff0064\\\\\"\\\\n    assert error_details.font().family() == \\\\\"Montserrat\\\\\"\\\\n    assert error_details.font().pixelSize() == 16\\\\n\\\\n    modal_dialog.start_animate_activestate()\\\\n\\\\n    assert error_details.getContentsMargins() == (36, 0, 40, 0)\\\\n    assert error_details.palette().color(QPalette.Foreground).name() == \\\\\"#ff66c4\\\\\"\\\\n    assert error_details.font().family() == \\\\\"Montserrat\\\\\"\\\\n    assert error_details.font().pixelSize() == 16\\\\n\"}', '{\"file_content\": \"import { describe, it, vi, beforeEach } from \\'vitest\\'\\\\nimport \\'@testing-library/jest-dom/vitest\\'\\\\nimport { fireEvent, screen } from \\'@testing-library/react\\'\\\\nimport { i18n } from \\'../../../../assets/localization\\'\\\\nimport { renderWithProviders } from \\'../../../../__testing-utils__\\'\\\\nimport {\\\\n  getSavedStepForms,\\\\n  getUnsavedForm,\\\\n} from \\'../../../../step-forms/selectors\\'\\\\nimport {\\\\n  getSelectedStepId,\\\\n  getSelectedSubstep,\\\\n} from \\'../../../../ui/steps/selectors\\'\\\\nimport { getEnableHotKeysDisplay } from \\'../../../../feature-flags/selectors\\'\\\\nimport { DeckSetupContainer } from \\'../../DeckSetup\\'\\\\nimport { OffDeck } from \\'../../Offdeck\\'\\\\nimport { ProtocolSteps } from \\'..\\'\\\\nimport { SubstepsToolbox, TimelineToolbox } from \\'../Timeline\\'\\\\nimport type { SavedStepFormState } from \\'../../../../step-forms\\'\\\\n\\\\nvi.mock(\\'../../Offdeck\\')\\\\nvi.mock(\\'../../../../step-forms/selectors\\')\\\\nvi.mock(\\'../../../../ui/steps/selectors\\')\\\\nvi.mock(\\'../../../../ui/labware/selectors\\')\\\\nvi.mock(\\'../StepForm\\')\\\\nvi.mock(\\'../../DeckSetup\\')\\\\nvi.mock(\\'../StepSummary.tsx\\')\\\\nvi.mock(\\'../Timeline\\')\\\\nvi.mock(\\'../../../../feature-flags/selectors\\')\\\\n\\\\nconst render = () => {\\\\n  return renderWithProviders(<ProtocolSteps />, {\\\\n    i18nInstance: i18n,\\\\n  })[0]\\\\n}\\\\n\\\\nconst MOCK_STEP_FORMS = {\\\\n  \\'0522fde8-25a3-4840-b84a-af7282bd80d5\\': {\\\\n    moduleId: \\'781599b2-1eff-4594-8c96-06fcd54f4faa:heaterShakerModuleType\\',\\\\n    pauseAction: \\'untilTime\\',\\\\n    pauseHour: \\'22\\',\\\\n    pauseMessage: \\'sdfg\\',\\\\n    pauseMinute: \\'22\\',\\\\n    pauseSecond: \\'11\\',\\\\n    pauseTemperature: null,\\\\n    pauseTime: null,\\\\n    id: \\'0522fde8-25a3-4840-b84a-af7282bd80d5\\',\\\\n    stepType: \\'pause\\',\\\\n    stepName: \\'custom pause\\',\\\\n    stepDetails: \\'\\',\\\\n  },\\\\n}\\\\n\\\\ndescribe(\\'ProtocolSteps\\', () => {\\\\n  beforeEach(() => {\\\\n    vi.mocked(TimelineToolbox).mockReturnValue(<div>mock TimelineToolbox</div>)\\\\n    vi.mocked(DeckSetupContainer).mockReturnValue(\\\\n      <div>mock DeckSetupContainer</div>\\\\n    )\\\\n    vi.mocked(OffDeck).mockReturnValue(<div>mock OffDeck</div>)\\\\n    vi.mocked(getUnsavedForm).mockReturnValue(null)\\\\n    vi.mocked(getSelectedSubstep).mockReturnValue(null)\\\\n    vi.mocked(SubstepsToolbox).mockReturnValue(<div>mock SubstepsToolbox</div>)\\\\n    vi.mocked(getEnableHotKeysDisplay).mockReturnValue(true)\\\\n    vi.mocked(getSavedStepForms).mockReturnValue(\\\\n      MOCK_STEP_FORMS as SavedStepFormState\\\\n    )\\\\n    vi.mocked(getSelectedStepId).mockReturnValue(\\\\n      \\'0522fde8-25a3-4840-b84a-af7282bd80d5\\'\\\\n    )\\\\n  })\\\\n\\\\n  it(\\'renders each component in ProtocolSteps\\', () => {\\\\n    render()\\\\n    screen.getByText(\\'mock TimelineToolbox\\')\\\\n    screen.getByText(\\'mock DeckSetupContainer\\')\\\\n  })\\\\n\\\\n  it(\\'renders the toggle when formData is null\\', () => {\\\\n    render()\\\\n    screen.getByText(\\'mock DeckSetupContainer\\')\\\\n    fireEvent.click(screen.getByText(\\'Off-deck\\'))\\\\n    screen.getByText(\\'mock OffDeck\\')\\\\n  })\\\\n\\\\n  it(\\'renders the substepToolbox when selectedSubstep is not null\\', () => {\\\\n    vi.mocked(getSelectedSubstep).mockReturnValue(\\'mockId\\')\\\\n    render()\\\\n    screen.getByText(\\'mock SubstepsToolbox\\')\\\\n  })\\\\n\\\\n  it(\\'renders the hot keys display\\', () => {\\\\n    render()\\\\n    screen.getByText(\\'Double-click to edit\\')\\\\n    screen.getByText(\\'Shift + Click to select all\\')\\\\n    screen.getByText(\\'Command + Click for multi-select\\')\\\\n  })\\\\n\\\\n  it(\\'renders the current step name\\', () => {\\\\n    render()\\\\n    screen.getByText(\\'Custom pause\\')\\\\n  })\\\\n})\\\\n\\\\n\"}', '{\"file_content\": \"\\\\nexport const getLabwareIsRecommended = (\\\\n  def: LabwareDefinition2,\\\\n  moduleModel?: ModuleModel | null\\\\n): boolean => {\\\\n  //  special-casing the thermocycler module V2 recommended labware\\\\n  //  since its different from V1\\\\n  const moduleType = moduleModel != null ? getModuleType(moduleModel) : null\\\\n  if (moduleModel === THERMOCYCLER_MODULE_V2) {\\\\n    return (\\\\n      def.parameters.loadName === \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\'\\\\n    )\\\\n  } else {\\\\n    return moduleType != null\\\\n      ? RECOMMENDED_LABWARE_BY_MODULE[moduleType].includes(\\\\n          def.parameters.loadName\\\\n        )\\\\n      : false\\\\n  }\\\\n}\\\\n\"}', '{\"file_content\": \"    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n  ],\\\\n  [THERMOCYCLER_MODULE_TYPE]: [\\\\n    \\'biorad_96_wellplate_200ul_pcr\\',\\\\n    \\'nest_96_wellplate_100ul_pcr_full_skirt\\',\\\\n    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n  ],\\\\n  [HEATERSHAKER_MODULE_TYPE]: [\\\\n    \\'opentrons_96_deep_well_adapter\\',\\\\n    \\'opentrons_96_flat_bottom_adapter\\',\\\\n    \\'opentrons_96_pcr_adapter\\',\\\\n    \\'opentrons_universal_flat_adapter\\',\\\\n  ],\\\\n  [MAGNETIC_BLOCK_TYPE]: [\\\\n    \\'nest_96_wellplate_100ul_pcr_full_skirt\\',\\\\n    \\'nest_96_wellplate_2ml_deep\\',\\\\n    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n    \\'armadillo_96_wellplate_200ul_pcr_full_skirt\\',\\\\n    \\'biorad_96_wellplate_200ul_pcr\\',\\\\n  ],\\\\n}\\\\n\"}', '{\"file_content\": \"import * as React from \\'react\\'\\\\nimport startCase from \\'lodash/startCase\\'\\\\nimport reduce from \\'lodash/reduce\\'\\\\nimport {\\\\n  useOnClickOutside,\\\\n  DeprecatedCheckboxField,\\\\n  Icon,\\\\n  OutlineButton,\\\\n} from \\'@opentrons/components\\'\\\\nimport {\\\\n  getLabwareDefURI,\\\\n  getLabwareDefIsStandard,\\\\n  getIsLabwareAboveHeight,\\\\n  TEMPERATURE_MODULE_TYPE,\\\\n  MAGNETIC_MODULE_TYPE,\\\\n  THERMOCYCLER_MODULE_TYPE,\\\\n  HEATERSHAKER_MODULE_TYPE,\\\\n  MAGNETIC_BLOCK_TYPE,\\\\n  MAX_LABWARE_HEIGHT_EAST_WEST_HEATER_SHAKER_MM,\\\\n  LabwareDefinition2,\\\\n  ModuleType,\\\\n  ModuleModel,\\\\n  getModuleType,\\\\n  THERMOCYCLER_MODULE_V2,\\\\n} from \\'@opentrons/shared-data\\'\\\\nimport { i18n } from \\'../../localization\\'\\\\nimport { SPAN7_8_10_11_SLOT } from \\'../../constants\\'\\\\nimport {\\\\n  getLabwareIsCompatible as _getLabwareIsCompatible,\\\\n  getLabwareCompatibleWithAdapter,\\\\n  ADAPTER_96_CHANNEL,\\\\n} from \\'../../utils/labwareModuleCompatibility\\'\\\\nimport { getOnlyLatestDefs } from \\'../../labware-defs/utils\\'\\\\nimport { Portal } from \\'../portals/TopPortal\\'\\\\nimport { PDTitledList } from \\'../lists\\'\\\\nimport { useBlockingHint } from \\'../Hints/useBlockingHint\\'\\\\nimport { KnowledgeBaseLink } from \\'../KnowledgeBaseLink\\'\\\\nimport { LabwareItem } from \\'./LabwareItem\\'\\\\nimport { LabwarePreview } from \\'./LabwarePreview\\'\\\\nimport styles from \\'./styles.css\\'\\\\n\\\\nimport type { DeckSlot } from \\'../../types\\'\\\\nimport type { LabwareDefByDefURI } from \\'../../labware-defs\\'\\\\n\\\\nexport interface Props {\\\\n  onClose: (e?: any) => unknown\\\\n  onUploadLabware: (event: React.ChangeEvent<HTMLInputElement>) => unknown\\\\n  selectLabware: (containerType: string) => unknown\\\\n  customLabwareDefs: LabwareDefByDefURI\\\\n  /** the slot you\\'re literally adding labware to (may be a module slot) */\\\\n  slot?: DeckSlot | null\\\\n  /** if adding to a module, the slot of the parent (for display) */\\\\n  parentSlot?: DeckSlot | null\\\\n  /** if adding to a module, the module\\'s model */\\\\n  moduleModel?: ModuleModel | null\\\\n  /** tipracks that may be added to deck (depends on pipette<>tiprack assignment) */\\\\n  permittedTipracks: string[]\\\\n  isNextToHeaterShaker: boolean\\\\n  has96Channel: boolean\\\\n  adapterLoadName?: string\\\\n}\\\\n\\\\nconst LABWARE_CREATOR_URL = \\'https://labware.opentrons.com/create\\'\\\\nconst CUSTOM_CATEGORY = \\'custom\\'\\\\nconst adapterCompatibleLabware = \\'adapterCompatibleLabware\\'\\\\n\\\\nconst orderedCategories: string[] = [\\\\n  \\'tipRack\\',\\\\n  \\'tubeRack\\',\\\\n  \\'wellPlate\\',\\\\n  \\'reservoir\\',\\\\n  \\'aluminumBlock\\',\\\\n  \\'adapter\\',\\\\n  // \\'trash\\', // NOTE: trash intentionally hidden\\\\n]\\\\n\\\\nconst RECOMMENDED_LABWARE_BY_MODULE: { [K in ModuleType]: string[] } = {\\\\n  [TEMPERATURE_MODULE_TYPE]: [\\\\n    \\'opentrons_24_aluminumblock_generic_2ml_screwcap\\',\\\\n    \\'opentrons_96_well_aluminum_block\\',\\\\n    \\'opentrons_96_aluminumblock_generic_pcr_strip_200ul\\',\\\\n    \\'opentrons_24_aluminumblock_nest_1.5ml_screwcap\\',\\\\n    \\'opentrons_24_aluminumblock_nest_1.5ml_snapcap\\',\\\\n    \\'opentrons_24_aluminumblock_nest_2ml_screwcap\\',\\\\n    \\'opentrons_24_aluminumblock_nest_2ml_snapcap\\',\\\\n    \\'opentrons_24_aluminumblock_nest_0.5ml_screwcap\\',\\\\n    \\'opentrons_aluminum_flat_bottom_plate\\',\\\\n  ],\\\\n  [MAGNETIC_MODULE_TYPE]: [\\\\n    \\'nest_96_wellplate_100ul_pcr_full_skirt\\',\\\\n    \\'nest_96_wellplate_2ml_deep\\',\\\\n    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n  ],\\\\n  [THERMOCYCLER_MODULE_TYPE]: [\\\\n    \\'nest_96_wellplate_100ul_pcr_full_skirt\\',\\\\n    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n  ],\\\\n  [HEATERSHAKER_MODULE_TYPE]: [\\\\n    \\'opentrons_96_deep_well_adapter\\',\\\\n    \\'opentrons_96_flat_bottom_adapter\\',\\\\n    \\'opentrons_96_pcr_adapter\\',\\\\n    \\'opentrons_universal_flat_adapter\\',\\\\n  ],\\\\n  [MAGNETIC_BLOCK_TYPE]: [\\\\n    \\'nest_96_wellplate_100ul_pcr_full_skirt\\',\\\\n    \\'nest_96_wellplate_2ml_deep\\',\\\\n    \\'opentrons_96_wellplate_200ul_pcr_full_skirt\\',\\\\n  ],\\\\n}\\\\n\\\\n\"}', '{\"file_content\": \"}\\\\nexport const LabwareSelectionModal = (props: Props): JSX.Element | null => {\\\\n  const {\\\\n    customLabwareDefs,\\\\n    permittedTipracks,\\\\n    onClose,\\\\n    onUploadLabware,\\\\n    slot,\\\\n    parentSlot,\\\\n    moduleModel,\\\\n    selectLabware,\\\\n    isNextToHeaterShaker,\\\\n    adapterLoadName,\\\\n    has96Channel,\\\\n  } = props\\\\n  const defs = getOnlyLatestDefs()\\\\n  const moduleType = moduleModel != null ? getModuleType(moduleModel) : null\\\\n  const URIs = Object.keys(defs)\\\\n  const [selectedCategory, setSelectedCategory] = React.useState<string | null>(\\\\n    null\\\\n  )\\\\n  const [previewedLabware, setPreviewedLabware] = React.useState<\\\\n    LabwareDefinition2 | null | undefined\\\\n  >(null)\\\\n  const [filterRecommended, setFilterRecommended] = React.useState<boolean>(\\\\n    false\\\\n  )\\\\n  const [filterHeight, setFilterHeight] = React.useState<boolean>(false)\\\\n  const [enqueuedLabwareType, setEnqueuedLabwareType] = React.useState<\\\\n    string | null\\\\n  >(null)\\\\n  const blockingCustomLabwareHint = useBlockingHint({\\\\n    enabled: enqueuedLabwareType !== null,\\\\n    hintKey: \\'custom_labware_with_modules\\',\\\\n    content: <p>{i18n.t(`alert.hint.custom_labware_with_modules.body`)}</p>,\\\\n    handleCancel: () => setEnqueuedLabwareType(null),\\\\n    handleContinue: () => {\\\\n      setEnqueuedLabwareType(null)\\\\n      if (enqueuedLabwareType !== null) {\\\\n        // NOTE: this needs to be wrapped for Flow, IRL we know enqueuedLabwareType is not null\\\\n        // because `enabled` prop above ensures it\\'s !== null.\\\\n        selectLabware(enqueuedLabwareType)\\\\n      } else {\\\\n        console.error(\\\\n          \\'could not select labware because enqueuedLabwareType is null. This should not happen\\'\\\\n        )\\\\n      }\\\\n\"}', '{\"file_content\": \"import { useState } from \\'react\\'\\\\nimport { createPortal } from \\'react-dom\\'\\\\nimport { useTranslation } from \\'react-i18next\\'\\\\nimport { useSelector } from \\'react-redux\\'\\\\nimport { css } from \\'styled-components\\'\\\\n\\\\nimport {\\\\n  BORDERS,\\\\n  COLORS,\\\\n  DIRECTION_COLUMN,\\\\n  RESPONSIVENESS,\\\\n  Flex,\\\\n  JUSTIFY_SPACE_BETWEEN,\\\\n  POSITION_ABSOLUTE,\\\\n  SPACING,\\\\n  useConditionalConfirm,\\\\n  ModalShell,\\\\n  DISPLAY_FLEX,\\\\n  OVERFLOW_HIDDEN,\\\\n  OVERFLOW_AUTO,\\\\n} from \\'@opentrons/components\\'\\\\n\\\\nimport { getTopPortalEl } from \\'/app/App/portal\\'\\\\nimport { getIsOnDevice } from \\'/app/redux/config\\'\\\\nimport { ExitConfirmation } from \\'./ExitConfirmation\\'\\\\nimport {\\\\n  BEFORE_BEGINNING,\\\\n  BLOWOUT_SUCCESS,\\\\n  CHOOSE_BLOWOUT_LOCATION,\\\\n  CHOOSE_DROP_TIP_LOCATION,\\\\n  CHOOSE_LOCATION_OPTION,\\\\n  CONFIRM_POSITION,\\\\n  DROP_TIP_SUCCESS,\\\\n  DT_ROUTES,\\\\n  POSITION_AND_BLOWOUT,\\\\n  POSITION_AND_DROP_TIP,\\\\n} from \\'./constants\\'\\\\nimport {\\\\n  BeforeBeginning,\\\\n  ChooseLocation,\\\\n  ChooseDeckLocation,\\\\n  JogToPosition,\\\\n  Success,\\\\n  ConfirmPosition,\\\\n  useConfirmPosition,\\\\n} from \\'./steps\\'\\\\nimport { InProgressModal } from \\'/app/molecules/InProgressModal\\'\\\\nimport { useDropTipErrorComponents } from \\'./hooks\\'\\\\nimport { DropTipWizardHeader } from \\'./DropTipWizardHeader\\'\\\\nimport { ErrorInfo } from \\'./ErrorInfo\\'\\\\n\\\\nimport type { DropTipWizardFlowsProps } from \\'.\\'\\\\nimport type { DropTipWizardContainerProps, IssuedCommandsType } from \\'./types\\'\\\\nimport type {\\\\n  UseDropTipRoutingResult,\\\\n  UseDropTipWithTypeResult,\\\\n  DropTipBlowoutLocationDetails,\\\\n} from \\'./hooks\\'\\\\n\\\\nexport type DropTipWizardProps = DropTipWizardFlowsProps &\\\\n  UseDropTipWithTypeResult &\\\\n  UseDropTipRoutingResult & {\\\\n    issuedCommandsType: IssuedCommandsType\\\\n    dropTipCommandLocations: DropTipBlowoutLocationDetails[]\\\\n  }\\\\n\\\\nexport function DropTipWizard(props: DropTipWizardProps): JSX.Element {\\\\n  const {\\\\n    issuedCommandsType,\\\\n    activeMaintenanceRunId,\\\\n    proceed,\\\\n    goBack,\\\\n    currentStep,\\\\n    dropTipCommands,\\\\n    errorDetails,\\\\n  } = props\\\\n\\\\n  const isFinalWizardStep = currentStep === DROP_TIP_SUCCESS // The happy path always ends with this step.\\\\n\\\\n  const isOnDevice = useSelector(getIsOnDevice)\\\\n  const initiateExitUtils = useInitiateExit()\\\\n  const {\\\\n    confirm: confirmExit,\\\\n    showConfirmation: showConfirmExit,\\\\n    cancel: cancelExit,\\\\n  } = useConditionalConfirm(dropTipCommands.handleCleanUpAndClose, true)\\\\n\\\\n  const errorComponents = useDropTipErrorComponents({\\\\n    isOnDevice,\\\\n    errorDetails,\\\\n    handleMustHome: dropTipCommands.handleMustHome,\\\\n  })\\\\n\\\\n  const goBackRunValid = (): Promise<void> => {\\\\n    if (activeMaintenanceRunId != null || issuedCommandsType === \\'fixit\\') {\\\\n      return goBack()\\\\n    } else {\\\\n      return Promise.reject(new Error(\\'No active maintenance run.\\'))\\\\n    }\\\\n  }\\\\n\\\\n  // Either proceed to drop tip if blowout or execute the close flow routine, accounting for the commands type.\\\\n  const proceedWithConditionalClose = (): Promise<void> => {\\\\n    if (isFinalWizardStep) {\\\\n      return dropTipCommands.handleCleanUpAndClose()\\\\n    } else {\\\\n      return proceed()\\\\n    }\\\\n  }\\\\n\\\\n  return (\\\\n    <DropTipWizardContainer\\\\n      {...props}\\\\n      {...initiateExitUtils}\\\\n      isOnDevice={isOnDevice}\\\\n      isFinalWizardStep={isFinalWizardStep}\\\\n      confirmExit={confirmExit}\\\\n      cancelExit={cancelExit}\\\\n      showConfirmExit={showConfirmExit}\\\\n      errorComponents={errorComponents}\\\\n      proceedWithConditionalClose={proceedWithConditionalClose}\\\\n      goBackRunValid={goBackRunValid}\\\\n    />\\\\n  )\\\\n}\\\\n\\\\nexport function DropTipWizardContainer(\\\\n  props: DropTipWizardContainerProps\\\\n): JSX.Element {\\\\n  const { issuedCommandsType } = props\\\\n\\\\n  const buildDTWizType = (): JSX.Element => {\\\\n    if (issuedCommandsType === \\'fixit\\') {\\\\n      return <DropTipWizardFixitType {...props} />\\\\n    } else {\\\\n      return <DropTipWizardSetupType {...props} />\\\\n    }\\\\n  }\\\\n\\\\n  return buildDTWizType()\\\\n}\\\\n\\\\nexport function DropTipWizardFixitType(\\\\n  props: DropTipWizardContainerProps\\\\n): JSX.Element {\\\\n  return (\\\\n    <Flex css={INTERVENTION_CONTAINER_STYLE}>\\\\n      <DropTipWizardContent {...props} />\\\\n    </Flex>\\\\n  )\\\\n}\\\\n\\\\nexport function DropTipWizardSetupType(\\\\n  props: DropTipWizardContainerProps\\\\n): JSX.Element {\\\\n  return createPortal(\\\\n    props.isOnDevice ? (\\\\n      <Flex css={SIMPLE_CONTAINER_STYLE}>\\\\n        <DropTipWizardHeader {...props} />\\\\n        <Flex css={SIMPLE_CONTENT_CONTAINER_STYLE}>\\\\n          <DropTipWizardContent {...props} />\\\\n        </Flex>\\\\n      </Flex>\\\\n    ) : (\\\\n      <ModalShell\\\\n        css={SIMPLE_CONTAINER_STYLE}\\\\n        header={<DropTipWizardHeader {...props} />}\\\\n      >\\\\n        <Flex css={SIMPLE_CONTENT_CONTAINER_STYLE}>\\\\n          <DropTipWizardContent {...props} />\\\\n        </Flex>\\\\n      </ModalShell>\\\\n    ),\\\\n    getTopPortalEl()\\\\n  )\\\\n}\\\\n\\\\nexport const DropTipWizardContent = (\\\\n  props: DropTipWizardContainerProps\\\\n): JSX.Element => {\\\\n  const {\\\\n    activeMaintenanceRunId,\\\\n    currentStep,\\\\n    currentRoute,\\\\n    errorDetails,\\\\n    isCommandInProgress,\\\\n    issuedCommandsType,\\\\n    isExiting,\\\\n    showConfirmExit,\\\\n  } = props\\\\n\\\\n  const { t } = useTranslation(\\'drop_tip_wizard\\')\\\\n  const confirmPositionUtils = useConfirmPosition(currentStep)\\\\n\\\\n  function buildGettingReady(): JSX.Element {\\\\n    return <InProgressModal description={t(\\'getting_ready\\')} />\\\\n  }\\\\n\\\\n  function buildRobotInMotion(): JSX.Element {\\\\n    return <InProgressModal description={t(\\'stand_back_robot_in_motion\\')} />\\\\n  }\\\\n\\\\n  function buildRobotPipetteMoving(): JSX.Element {\\\\n    return (\\\\n      <InProgressModal\\\\n        description={\\\\n          currentRoute === DT_ROUTES.BLOWOUT\\\\n            ? t(\\'stand_back_blowing_out\\')\\\\n            : t(\\'stand_back_dropping_tips\\')\\\\n        }\\\\n      />\\\\n    )\\\\n  }\\\\n\\\\n  function buildShowExitConfirmation(): JSX.Element {\\\\n    return <ExitConfirmation {...props} />\\\\n  }\\\\n\\\\n  function buildErrorScreen(): JSX.Element {\\\\n    return <ErrorInfo {...props} />\\\\n  }\\\\n\\\\n  function buildBeforeBeginning(): JSX.Element {\\\\n    return <BeforeBeginning {...props} />\\\\n  }\\\\n\\\\n  function buildChooseLocation(): JSX.Element {\\\\n    return <ChooseLocation {...props} {...confirmPositionUtils} />\\\\n  }\\\\n\\\\n  function buildChooseDeckLocation(): JSX.Element {\\\\n    return <ChooseDeckLocation {...props} />\\\\n  }\\\\n\\\\n  function buildJogToPosition(): JSX.Element {\\\\n    return <JogToPosition {...props} {...confirmPositionUtils} />\\\\n  }\\\\n\\\\n  function buildConfirmPosition(): JSX.Element {\\\\n    return <ConfirmPosition {...props} {...confirmPositionUtils} />\\\\n  }\\\\n\\\\n  function buildSuccess(): JSX.Element {\\\\n    return <Success {...props} />\\\\n  }\\\\n\\\\n  function buildModalContent(): JSX.Element {\\\\n    // Don\\'t render the spinner screen for 1 render cycle on fixit commands.\\\\n\\\\n    if (errorDetails != null) {\\\\n      return buildErrorScreen()\\\\n    } else if (\\\\n      currentStep === BEFORE_BEGINNING &&\\\\n      issuedCommandsType === \\'fixit\\'\\\\n    ) {\\\\n      return buildBeforeBeginning()\\\\n    } else if (\\\\n      activeMaintenanceRunId == null &&\\\\n      issuedCommandsType === \\'setup\\'\\\\n    ) {\\\\n      return buildGettingReady()\\\\n    } else if (confirmPositionUtils.isRobotPipetteMoving) {\\\\n      return buildRobotPipetteMoving()\\\\n    } else if (isCommandInProgress || isExiting) {\\\\n      return buildRobotInMotion()\\\\n    } else if (showConfirmExit) {\\\\n      return buildShowExitConfirmation()\\\\n    } else if (currentStep === BEFORE_BEGINNING) {\\\\n      return buildBeforeBeginning()\\\\n    } else if (currentStep === CHOOSE_LOCATION_OPTION) {\\\\n      return buildChooseLocation()\\\\n    } else if (\\\\n      currentStep === CHOOSE_BLOWOUT_LOCATION ||\\\\n      currentStep === CHOOSE_DROP_TIP_LOCATION\\\\n    ) {\\\\n      return buildChooseDeckLocation()\\\\n    } else if (\\\\n      currentStep === POSITION_AND_BLOWOUT ||\\\\n      currentStep === POSITION_AND_DROP_TIP\\\\n    ) {\\\\n      return buildJogToPosition()\\\\n    } else if (currentStep === CONFIRM_POSITION) {\\\\n      return buildConfirmPosition()\\\\n    } else if (\\\\n      currentStep === BLOWOUT_SUCCESS ||\\\\n      currentStep === DROP_TIP_SUCCESS\\\\n    ) {\\\\n      return buildSuccess()\\\\n    } else {\\\\n      return <div>UNASSIGNED STEP</div>\\\\n    }\\\\n  }\\\\n\\\\n  return buildModalContent()\\\\n}\\\\n\\\\n// Controls closing drop tip flow. Because DT flows may be closed from multiple components and,\\\\n// emit actions to the server, ensure flows may be closed only once.\\\\nfunction useInitiateExit(): {\\\\n  isExitInitiated: boolean\\\\n  toggleExitInitiated: () => void\\\\n} {\\\\n  const [isExitInitiated, setIsExitInitiated] = useState(false)\\\\n\\\\n  const toggleExitInitiated = (): void => {\\\\n    setIsExitInitiated(true)\\\\n  }\\\\n\\\\n  return { isExitInitiated, toggleExitInitiated }\\\\n}\\\\n\\\\nconst SHARED_STYLE = `\\\\n  display: ${DISPLAY_FLEX};\\\\n  flex-direction: ${DIRECTION_COLUMN};\\\\n  overflow-y: ${OVERFLOW_AUTO};\\\\n  \\\\n  @media ${RESPONSIVENESS.touchscreenMediaQuerySpecs} {\\\\n    overflow: ${OVERFLOW_HIDDEN};\\\\n  }\\\\n`\\\\n\\\\nconst INTERVENTION_CONTAINER_STYLE = css`\\\\n  ${SHARED_STYLE}\\\\n  padding: ${SPACING.spacing32};\\\\n  grid-gap: ${SPACING.spacing24};\\\\n  height: 100%;\\\\n  width: 100%;\\\\n\\\\n  @media ${RESPONSIVENESS.touchscreenMediaQuerySpecs} {\\\\n    grid-gap: ${SPACING.spacing32};\\\\n  }\\\\n`\\\\n\\\\nconst SIMPLE_CONTAINER_STYLE = css`\\\\n  ${SHARED_STYLE}\\\\n  width: 47rem;\\\\n  min-height: 26.75rem;\\\\n\\\\n  // TODO(jh 09-17-24): This is effectively making a ModalShell analogue on the ODD, since one does not exist.\\\\n  //  Consider making one.\\\\n  @media ${RESPONSIVENESS.touchscreenMediaQuerySpecs} {\\\\n    position: ${POSITION_ABSOLUTE};\\\\n    width: 62rem;\\\\n    height: 35.5rem;\\\\n    left: 16px;\\\\n    top: 16px;\\\\n    border: ${BORDERS.lineBorder};\\\\n    box-shadow: ${BORDERS.shadowSmall};\\\\n    border-radius: ${BORDERS.borderRadius16};\\\\n    background-color: ${COLORS.white};\\\\n  }\\\\n`\\\\n\\\\nconst SIMPLE_CONTENT_CONTAINER_STYLE = css`\\\\n  display: ${DISPLAY_FLEX};\\\\n  flex-direction: ${DIRECTION_COLUMN};\\\\n  justify-content: ${JUSTIFY_SPACE_BETWEEN};\\\\n  width: 100%;\\\\n  height: 100%;\\\\n  padding: ${SPACING.spacing32};\\\\n  flex: 1;\\\\n  grid-gap: ${SPACING.spacing24};\\\\n\\\\n  @media ${RESPONSIVENESS.touchscreenMediaQuerySpecs} {\\\\n    grid-gap: ${SPACING.spacing32};\\\\n  }\\\\n`\\\\n\"}', '{\"file_content\": \"import { vi, describe, it, expect, beforeEach } from \\'vitest\\'\\\\nimport { screen } from \\'@testing-library/react\\'\\\\n\\\\nimport { renderWithProviders } from \\'/app/__testing-utils__\\'\\\\nimport { i18n } from \\'/app/i18n\\'\\\\nimport { mockDropTipWizardContainerProps } from \\'../__fixtures__\\'\\\\nimport { DropTipWizardContent, DropTipWizardContainer } from \\'../DropTipWizard\\'\\\\nimport { DropTipWizardHeader } from \\'../DropTipWizardHeader\\'\\\\nimport { InProgressModal } from \\'/app/molecules/InProgressModal\\'\\\\nimport { ExitConfirmation } from \\'../ExitConfirmation\\'\\\\nimport {\\\\n  BeforeBeginning,\\\\n  ChooseLocation,\\\\n  JogToPosition,\\\\n  Success,\\\\n  ConfirmPosition,\\\\n  useConfirmPosition,\\\\n  ChooseDeckLocation,\\\\n} from \\'../steps\\'\\\\nimport { ErrorInfo } from \\'../ErrorInfo\\'\\\\nimport {\\\\n  BEFORE_BEGINNING,\\\\n  CHOOSE_BLOWOUT_LOCATION,\\\\n  CHOOSE_DROP_TIP_LOCATION,\\\\n  POSITION_AND_BLOWOUT,\\\\n  POSITION_AND_DROP_TIP,\\\\n  BLOWOUT_SUCCESS,\\\\n  DROP_TIP_SUCCESS,\\\\n  CHOOSE_LOCATION_OPTION,\\\\n  CONFIRM_POSITION,\\\\n} from \\'../constants\\'\\\\n\\\\nimport type { ComponentProps } from \\'react\\'\\\\n\\\\nvi.mock(\\'/app/molecules/InProgressModal\\')\\\\nvi.mock(\\'../ExitConfirmation\\')\\\\nvi.mock(\\'../steps\\')\\\\nvi.mock(\\'../ErrorInfo\\')\\\\nvi.mock(\\'../DropTipWizardHeader\\')\\\\n\\\\nconst renderDropTipWizardContainer = (\\\\n  props: ComponentProps<typeof DropTipWizardContainer>\\\\n) => {\\\\n  return renderWithProviders(<DropTipWizardContainer {...props} />, {\\\\n    i18nInstance: i18n,\\\\n  })[0]\\\\n}\\\\n\\\\ndescribe(\\'DropTipWizardContainer\\', () => {\\\\n  let props: ComponentProps<typeof DropTipWizardContainer>\\\\n\\\\n  beforeEach(() => {\\\\n    props = mockDropTipWizardContainerProps\\\\n\\\\n    vi.mocked(DropTipWizardHeader).mockReturnValue(\\\\n      <div>MOCK WIZARD HEADER</div>\\\\n    )\\\\n\\\\n    vi.mocked(useConfirmPosition).mockReturnValue({\\\\n      toggleIsRobotPipetteMoving: vi.fn(),\\\\n      isRobotPipetteMoving: false,\\\\n    })\\\\n  })\\\\n\\\\n  it(\\'renders the special-cased Fixit view if the issuedCommandsType is fixit without a header\\', () => {\\\\n    renderDropTipWizardContainer({ ...props, issuedCommandsType: \\'fixit\\' })\\\\n\\\\n    expect(screen.queryByText(\\'MOCK WIZARD HEADER\\')).not.toBeInTheDocument()\\\\n  })\\\\n\\\\n  it(\\'renders the setup view by default with a header\\', () => {\\\\n    renderDropTipWizardContainer(props)\\\\n\\\\n    screen.getByText(\\'MOCK WIZARD HEADER\\')\\\\n  })\\\\n})\\\\n\\\\nconst renderDropTipWizardContent = (\\\\n  props: ComponentProps<typeof DropTipWizardContent>\\\\n) => {\\\\n  return renderWithProviders(<DropTipWizardContent {...props} />, {\\\\n    i18nInstance: i18n,\\\\n  })[0]\\\\n}\\\\n\\\\ndescribe(\\'DropTipWizardContent\\', () => {\\\\n  let props: ComponentProps<typeof DropTipWizardContent>\\\\n\\\\n  beforeEach(() => {\\\\n    props = mockDropTipWizardContainerProps\\\\n\\\\n    vi.mocked(InProgressModal).mockReturnValue(\\\\n      <div>MOCK_IN_PROGRESS_MODAL</div>\\\\n    )\\\\n    vi.mocked(ExitConfirmation).mockReturnValue(\\\\n      <div>MOCK_EXIT_CONFIRMATION</div>\\\\n    )\\\\n    vi.mocked(BeforeBeginning).mockReturnValue(<div>MOCK_BEFORE_BEGINNING</div>)\\\\n    vi.mocked(ChooseLocation).mockReturnValue(<div>MOCK_CHOOSE_LOCATION</div>)\\\\n    vi.mocked(ChooseDeckLocation).mockReturnValue(\\\\n      <div>MOCK_CHOOSE_DECK_LOCATION</div>\\\\n    )\\\\n    vi.mocked(ConfirmPosition).mockReturnValue(<div>MOCK_CONFIRM_POSITION</div>)\\\\n    vi.mocked(JogToPosition).mockReturnValue(<div>MOCK_JOG_TO_POSITION</div>)\\\\n    vi.mocked(Success).mockReturnValue(<div>MOCK_SUCCESS</div>)\\\\n    vi.mocked(ErrorInfo).mockReturnValue(<div>MOCK_ERROR_INFO</div>)\\\\n  })\\\\n\\\\n  it(`renders InProgressModal when activeMaintenanceRunId is null`, () => {\\\\n    renderDropTipWizardContent({ ...props, activeMaintenanceRunId: null })\\\\n\\\\n    screen.getByText(\\'MOCK_IN_PROGRESS_MODAL\\')\\\\n  })\\\\n\\\\n  it(`renders InProgressModal when isCommandInProgress is true`, () => {\\\\n    renderDropTipWizardContent({ ...props, isCommandInProgress: true })\\\\n\\\\n    screen.getByText(\\'MOCK_IN_PROGRESS_MODAL\\')\\\\n  })\\\\n\\\\n  it(`renders InProgressModal when isExiting is true`, () => {\\\\n    renderDropTipWizardContent({ ...props, isExiting: true })\\\\n\\\\n    screen.getByText(\\'MOCK_IN_PROGRESS_MODAL\\')\\\\n  })\\\\n\\\\n  it(`renders ExitConfirmation when showConfirmExit is true`, () => {\\\\n    renderDropTipWizardContent({ ...props, showConfirmExit: true })\\\\n\\\\n    screen.getByText(\\'MOCK_EXIT_CONFIRMATION\\')\\\\n  })\\\\n\\\\n  it(`renders ErrorInfo when errorDetails is not null`, () => {\\\\n    renderDropTipWizardContent({\\\\n      ...props,\\\\n      errorDetails: { message: \\'MOCK_MESSAGE\\' },\\\\n    })\\\\n\\\\n    screen.getByText(\\'MOCK_ERROR_INFO\\')\\\\n  })\\\\n\\\\n  it(`renders BeforeBeginning when currentStep is ${BEFORE_BEGINNING}`, () => {\\\\n    renderDropTipWizardContent({ ...props, currentStep: BEFORE_BEGINNING })\\\\n\\\\n    screen.getByText(\\'MOCK_BEFORE_BEGINNING\\')\\\\n  })\\\\n\\\\n  it(`renders ChooseLocation when currentStep is ${CHOOSE_LOCATION_OPTION}`, () => {\\\\n    renderDropTipWizardContent({\\\\n      ...props,\\\\n      currentStep: CHOOSE_LOCATION_OPTION,\\\\n    })\\\\n\\\\n    screen.getByText(\\'MOCK_CHOOSE_LOCATION\\')\\\\n  })\\\\n\\\\n  it(`renders ChooseDeckLocation when currentStep is ${CHOOSE_BLOWOUT_LOCATION}`, () => {\\\\n    renderDropTipWizardContent({\\\\n      ...props,\\\\n      currentStep: CHOOSE_BLOWOUT_LOCATION,\\\\n    })\\\\n\\\\n    screen.getByText(\\'MOCK_CHOOSE_DECK_LOCATION\\')\\\\n  })\\\\n\\\\n  it(`renders ChooseDeckLocation when currentStep is ${CHOOSE_DROP_TIP_LOCATION}`, () => {\\\\n    renderDropTipWizardContent({\\\\n      ...props,\\\\n      currentStep: CHOOSE_DROP_TIP_LOCATION,\\\\n    })\\\\n\\\\n    screen.getByText(\\'MOCK_CHOOSE_DECK_LOCATION\\')\\\\n  })\\\\n\\\\n  it(`renders ConfirmPosition when currentStep is ${CONFIRM_POSITION}`, () => {\\\\n    renderDropTipWizardContent({\\\\n      ...props,\\\\n      currentStep: CONFIRM_POSITION,\\\\n    })\\\\n\\\\n    screen.getByText(\\'MOCK_CONFIRM_POSITION\\')\\\\n  })\\\\n\\\\n  it(`renders JogToPosition when currentStep is ${POSITION_AND_BLOWOUT} `, () => {\\\\n    renderDropTipWizardContent({ ...props, currentStep: POSITION_AND_BLOWOUT })\\\\n\\\\n    screen.getByText(\\'MOCK_JOG_TO_POSITION\\')\\\\n  })\\\\n\\\\n  it(`renders JogToPosition when currentStep is ${POSITION_AND_DROP_TIP}`, () => {\\\\n    renderDropTipWizardContent({ ...props, currentStep: POSITION_AND_DROP_TIP })\\\\n\\\\n    screen.getByText(\\'MOCK_JOG_TO_POSITION\\')\\\\n  })\\\\n\\\\n  it(`renders Success when currentStep is ${BLOWOUT_SUCCESS}`, () => {\\\\n    renderDropTipWizardContent({ ...props, currentStep: BLOWOUT_SUCCESS })\\\\n\\\\n    screen.getByText(\\'MOCK_SUCCESS\\')\\\\n  })\\\\n\\\\n  it(`renders Success when currentStep is ${DROP_TIP_SUCCESS}`, () => {\\\\n    renderDropTipWizardContent({ ...props, currentStep: DROP_TIP_SUCCESS })\\\\n\\\\n    screen.getByText(\\'MOCK_SUCCESS\\')\\\\n  })\\\\n})\\\\n\"}', '{\"file_content\": \"import { css } from \\'styled-components\\'\\\\nimport { useEffect, useState } from \\'react\\'\\\\nimport { useTranslation } from \\'react-i18next\\'\\\\n\\\\nimport {\\\\n  ALIGN_CENTER,\\\\n  ALIGN_FLEX_END,\\\\n  BORDERS,\\\\n  Btn,\\\\n  COLORS,\\\\n  CURSOR_POINTER,\\\\n  DIRECTION_COLUMN,\\\\n  Flex,\\\\n  Icon,\\\\n  InputField,\\\\n  JUSTIFY_SPACE_BETWEEN,\\\\n  NO_WRAP,\\\\n  PrimaryButton,\\\\n  SPACING,\\\\n  StyledText,\\\\n  TYPOGRAPHY,\\\\n} from \\'@opentrons/components\\'\\\\nimport {\\\\n  isTimeFormatMinutesSeconds,\\\\n  temperatureRangeFieldValue,\\\\n} from \\'../../../../../../steplist/fieldLevel/errors\\'\\\\nimport {\\\\n  maskToFloat,\\\\n  maskToInteger,\\\\n  maskToTime,\\\\n} from \\'../../../../../../steplist/fieldLevel/processing\\'\\\\nimport { uuid } from \\'../../../../../../utils\\'\\\\nimport { getTimeFromString, getStepIndex } from \\'./utils\\'\\\\n\\\\nimport type { ThermocyclerStepTypeGeneral } from \\'./ThermocyclerProfileModal\\'\\\\nimport type { ThermocyclerStepType } from \\'./ThermocyclerStep\\'\\\\n\\\\nexport interface ThermocyclerCycleType {\\\\n  id: string\\\\n  title: string\\\\n  steps: ThermocyclerStepType[]\\\\n  type: \\'profileCycle\\'\\\\n  repetitions: string\\\\n}\\\\n\\\\ninterface CycleStepValues {\\\\n  value: string | null\\\\n  error: string | null\\\\n  wasAccessed?: boolean\\\\n}\\\\ninterface CycleStepType {\\\\n  name: CycleStepValues\\\\n  temp: CycleStepValues\\\\n  time: CycleStepValues\\\\n}\\\\n\\\\ninterface ThermocyclerCycleProps {\\\\n  steps: ThermocyclerStepTypeGeneral[]\\\\n  setSteps: React.Dispatch<React.SetStateAction<ThermocyclerStepTypeGeneral[]>>\\\\n  setShowCreateNewCycle: React.Dispatch<React.SetStateAction<boolean>>\\\\n  step?: ThermocyclerCycleType\\\\n  backgroundColor?: string\\\\n  readOnly?: boolean\\\\n  setIsInEdit: React.Dispatch<React.SetStateAction<boolean>>\\\\n}\\\\n\\\\nexport function ThermocyclerCycle(props: ThermocyclerCycleProps): JSX.Element {\\\\n  const {\\\\n    setShowCreateNewCycle,\\\\n    step,\\\\n    steps,\\\\n    setSteps,\\\\n    backgroundColor = COLORS.grey30,\\\\n    setIsInEdit,\\\\n    readOnly = true,\\\\n  } = props\\\\n  const { i18n, t } = useTranslation([\\'application\\', \\'form\\'])\\\\n  const [hover, setHover] = useState<boolean>(false)\\\\n  const [showEdit, setShowEditCurrentCycle] = useState<boolean>(!readOnly)\\\\n\\\\n  const [orderedCycleStepIds, setOrderedCycleStepIds] = useState<string[]>(\\\\n    step?.steps.map(cycleStep => cycleStep.id) ?? []\\\\n  )\\\\n  const [cycleStepsById, setCycleStepsById] = useState(\\\\n    step?.steps.reduce<Record<string, CycleStepType>>(\\\\n      (acc, { id, title, temperature, durationMinutes, durationSeconds }) => {\\\\n        return {\\\\n          ...acc,\\\\n          [id]: {\\\\n            name: { value: title ?? null, error: null },\\\\n            temp: {\\\\n              value: temperature ?? null,\\\\n              error: null,\\\\n              wasAccessed: false,\\\\n            },\\\\n            time: {\\\\n              value:\\\\n                durationMinutes != null && durationSeconds != null\\\\n                  ? `${durationMinutes}:${durationSeconds}`\\\\n                  : null,\\\\n              error: null,\\\\n              wasAccessed: false,\\\\n            },\\\\n          },\\\\n        }\\\\n      },\\\\n      {}\\\\n    ) ?? {}\\\\n  )\\\\n  const [repetitions, setRepetitions] = useState<string | undefined>(\\\\n    step?.repetitions\\\\n  )\\\\n\\\\n  const cycleId = step?.id ?? null\\\\n  const isStepStateError =\\\\n    Object.values(cycleStepsById).some(cycleStep =>\\\\n      Object.values(cycleStep).some(\\\\n        ({ value, error }) => value == null || value === \\'\\' || error != null\\\\n      )\\\\n    ) ||\\\\n    repetitions == null ||\\\\n    repetitions === \\'\\'\\\\n\\\\n  const blankStep: CycleStepType = {\\\\n    name: {\\\\n      value: null,\\\\n      error: null,\\\\n    },\\\\n    temp: {\\\\n      value: null,\\\\n      error: null,\\\\n    },\\\\n    time: {\\\\n      value: null,\\\\n      error: null,\\\\n    },\\\\n  }\\\\n\\\\n  useEffect(() => {\\\\n    if (orderedCycleStepIds.length === 0) {\\\\n      // prepopulate with blank step on mount if not editing\\\\n      handleAddCycleStep()\\\\n      setIsInEdit(true)\\\\n    }\\\\n  }, [])\\\\n\\\\n  const handleAddCycleStep = (): void => {\\\\n    const newStepId = uuid()\\\\n    setOrderedCycleStepIds([...orderedCycleStepIds, newStepId])\\\\n    setCycleStepsById({ ...cycleStepsById, [newStepId]: blankStep })\\\\n  }\\\\n\\\\n  const handleDeleteStep = (stepId: string): void => {\\\\n    const filteredOrdredCycleStepIds = orderedCycleStepIds.filter(\\\\n      id => id !== stepId\\\\n    )\\\\n    setOrderedCycleStepIds(filteredOrdredCycleStepIds)\\\\n    setCycleStepsById(\\\\n      filteredOrdredCycleStepIds.reduce((acc, id) => {\\\\n        return id !== stepId\\\\n          ? {\\\\n              ...acc,\\\\n              [id]: cycleStepsById[id],\\\\n            }\\\\n          : acc\\\\n      }, {})\\\\n    )\\\\n  }\\\\n  const handleDeleteCycle = (): void => {\\\\n    if (cycleId != null) {\\\\n      setSteps(\\\\n        steps.filter((s: any) => {\\\\n          return s.id !== cycleId\\\\n        })\\\\n      )\\\\n    } else {\\\\n      setShowCreateNewCycle(false)\\\\n    }\\\\n    setIsInEdit(false)\\\\n  }\\\\n  const handleValueUpdate = (\\\\n    stepId: string,\\\\n    field: \\'name\\' | \\'temp\\' | \\'time\\',\\\\n    value: string,\\\\n    errorCheck?: (value: any) => string | null\\\\n  ): void => {\\\\n    setCycleStepsById({\\\\n      ...cycleStepsById,\\\\n      [stepId]: {\\\\n        ...cycleStepsById[stepId],\\\\n        [field]: {\\\\n          value,\\\\n          error: errorCheck?.(value) ?? null,\\\\n        },\\\\n      },\\\\n    })\\\\n  }\\\\n  const handleSaveCycle = (): void => {\\\\n    const orderedCycleSteps = orderedCycleStepIds.map(cycleStepId => {\\\\n      const step = cycleStepsById[cycleStepId]\\\\n      const { minutes, seconds } = getTimeFromString(step.time.value ?? \\'\\')\\\\n      const cycleStepData: ThermocyclerStepType = {\\\\n        durationMinutes: minutes,\\\\n        durationSeconds: seconds,\\\\n        id: cycleStepId,\\\\n        temperature: step.temp.value ?? \\'\\',\\\\n        title: step.name.value ?? \\'\\',\\\\n        type: \\'profileStep\\',\\\\n      }\\\\n      return cycleStepData\\\\n    })\\\\n    const cycleData: ThermocyclerCycleType = {\\\\n      id: cycleId ?? uuid(),\\\\n      title: \\'\\',\\\\n      steps: orderedCycleSteps,\\\\n      type: \\'profileCycle\\',\\\\n      repetitions: repetitions ?? \\'\\',\\\\n    }\\\\n    const existingCycleIndex = steps.findIndex(step => step.id === cycleId)\\\\n    if (existingCycleIndex >= 0) {\\\\n      // editing a cycle that was already created\\\\n      setSteps([\\\\n        ...steps.slice(0, existingCycleIndex),\\\\n        cycleData,\\\\n        ...steps.slice(existingCycleIndex + 1),\\\\n      ])\\\\n    } else {\\\\n      // append to end of steps\\\\n      setSteps([...steps, cycleData])\\\\n    }\\\\n    setShowCreateNewCycle(false)\\\\n    setShowEditCurrentCycle(false)\\\\n    setIsInEdit(false)\\\\n  }\\\\n\\\\n  const header = showEdit ? (\\\\n    <Flex\\\\n      padding={`${SPACING.spacing12} ${SPACING.spacing16}`}\\\\n      justifyContent={JUSTIFY_SPACE_BETWEEN}\\\\n      width=\\\\\"100%\\\\\"\\\\n    >\\\\n      <Flex gridGap={SPACING.spacing24} alignItems={ALIGN_CENTER}>\\\\n        <StyledText\\\\n          desktopStyle=\\\\\"bodyDefaultRegular\\\\\"\\\\n          borderRadius={BORDERS.borderRadius4}\\\\n          backgroundColor={`${COLORS.black90}${COLORS.opacity20HexCode}`}\\\\n          padding={`${SPACING.spacing2} ${SPACING.spacing8}`}\\\\n        >\\\\n          {cycleId != null ? getStepIndex(steps, cycleId) : steps.length + 1}\\\\n        </StyledText>\\\\n        <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">\\\\n          {i18n.format(\\\\n            t(\\'form:step_edit_form.field.thermocyclerProfile.cycle\\'),\\\\n            \\'capitalize\\'\\\\n          )}\\\\n        </StyledText>\\\\n      </Flex>\\\\n      <Flex gridGap={SPACING.spacing8}>\\\\n        <Btn\\\\n          onClick={handleDeleteCycle}\\\\n          whiteSpace={NO_WRAP}\\\\n          textDecoration={TYPOGRAPHY.textDecorationUnderline}\\\\n        >\\\\n          <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">\\\\n            {i18n.format(\\\\n              t(\\'form:step_edit_form.field.thermocyclerProfile.delete\\'),\\\\n              \\'capitalize\\'\\\\n            )}\\\\n          </StyledText>\\\\n        </Btn>\\\\n        <PrimaryButton onClick={handleSaveCycle} disabled={isStepStateError}>\\\\n          <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">\\\\n            {i18n.format(t(\\'save\\'), \\'capitalize\\')}\\\\n          </StyledText>\\\\n        </PrimaryButton>\\\\n      </Flex>\\\\n    </Flex>\\\\n  ) : (\\\\n    <Flex\\\\n      padding={`${SPACING.spacing12} ${SPACING.spacing16}`}\\\\n      justifyContent={JUSTIFY_SPACE_BETWEEN}\\\\n      width=\\\\\"100%\\\\\"\\\\n      backgroundColor={backgroundColor}\\\\n      borderRadius={BORDERS.borderRadius4}\\\\n      onMouseEnter={() => {\\\\n        setHover(true)\\\\n      }}\\\\n      onMouseLeave={() => {\\\\n        setHover(false)\\\\n      }}\\\\n    >\\\\n      <Flex gridGap={SPACING.spacing24} alignItems={ALIGN_CENTER}>\\\\n        <StyledText\\\\n          desktopStyle=\\\\\"bodyDefaultRegular\\\\\"\\\\n          borderRadius={BORDERS.borderRadius4}\\\\n          backgroundColor={`${COLORS.black90}${COLORS.opacity20HexCode}`}\\\\n          padding={`${SPACING.spacing2} ${SPACING.spacing8}`}\\\\n        >\\\\n          {getStepIndex(steps, cycleId ?? \\'\\')}\\\\n        </StyledText>\\\\n        <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">\\\\n          {i18n.format(\\\\n            t(\\'form:step_edit_form.field.thermocyclerProfile.cycles\\', {\\\\n              repetitions,\\\\n            }),\\\\n            \\'capitalize\\'\\\\n          )}\\\\n        </StyledText>\\\\n      </Flex>\\\\n      <Flex gridGap={SPACING.spacing8}>\\\\n        {hover ? (\\\\n          <Btn\\\\n            whiteSpace={NO_WRAP}\\\\n            textDecoration={TYPOGRAPHY.textDecorationUnderline}\\\\n            onClick={() => {\\\\n              setShowEditCurrentCycle(true)\\\\n              setIsInEdit(true)\\\\n            }}\\\\n          >\\\\n            <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">\\\\n              {i18n.format(t(\\'edit\\'), \\'capitalize\\')}\\\\n            </StyledText>\\\\n          </Btn>\\\\n        ) : null}\\\\n        <Flex\\\\n          css={css`\\\\n            &:hover {\\\\n              background-color: ${COLORS.grey40};\\\\n            }\\\\n          `}\\\\n          borderRadius={BORDERS.borderRadius4}\\\\n          cursor={CURSOR_POINTER}\\\\n          onClick={handleDeleteCycle}\\\\n        >\\\\n          <Icon name=\\\\\"close\\\\\" size=\\\\\"1.5rem\\\\\" />\\\\n        </Flex>\\\\n      </Flex>\\\\n    </Flex>\\\\n  )\\\\n  const bodyContent = (\\\\n    <Flex\\\\n      flexDirection={DIRECTION_COLUMN}\\\\n      gridGap={SPACING.spacing8}\\\\n      alignItems={ALIGN_FLEX_END}\\\\n      padding={SPACING.spacing12}\\\\n      onMouseEnter={() => {\\\\n        setHover(true)\\\\n      }}\\\\n      onMouseLeave={() => {\\\\n        setHover(false)\\\\n      }}\\\\n    >\\\\n      <Flex\\\\n        flexDirection={DIRECTION_COLUMN}\\\\n        gridGap={SPACING.spacing4}\\\\n        width=\\\\\"100%\\\\\"\\\\n      >\\\\n        {orderedCycleStepIds.map((cycleStepId, cycleStepIndex) => {\\\\n          const stepState = cycleStepsById[cycleStepId]\\\\n          return showEdit ? (\\\\n            <Flex\\\\n              key={cycleStepId}\\\\n              gridGap={SPACING.spacing24}\\\\n              backgroundColor={COLORS.grey10}\\\\n              padding={SPACING.spacing12}\\\\n              borderRadius={BORDERS.borderRadius4}\\\\n            >\\\\n              <Flex\\\\n                flexDirection={DIRECTION_COLUMN}\\\\n                gridGap={SPACING.spacing4}\\\\n                width=\\\\\"33%\\\\\"\\\\n              >\\\\n                <InputField\\\\n                  title={i18n.format(\\\\n                    t(\\'form:step_edit_form.field.thermocyclerProfile.name\\'),\\\\n                    \\'capitalize\\'\\\\n                  )}\\\\n                  value={stepState.name.value}\\\\n                  onChange={(e: React.ChangeEvent<any>) => {\\\\n                    handleValueUpdate(\\\\n                      cycleStepId,\\\\n                      \\'name\\',\\\\n                      e.target.value as string\\\\n                    )\\\\n                  }}\\\\n                />\\\\n              </Flex>\\\\n              <Flex\\\\n                flexDirection={DIRECTION_COLUMN}\\\\n                gridGap={SPACING.spacing4}\\\\n                width=\\\\\"33%\\\\\"\\\\n              >\\\\n                <InputField\\\\n                  title={i18n.format(\\\\n                    t(\\\\n                      \\'form:step_edit_form.field.thermocyclerState.block.temperature\\'\\\\n                    ),\\\\n                    \\'capitalize\\'\\\\n                  )}\\\\n                  units={t(\\'units.degrees\\')}\\\\n                  value={stepState.temp.value}\\\\n                  onChange={(e: React.ChangeEvent<any>) => {\\\\n                    handleValueUpdate(\\\\n                      cycleStepId,\\\\n                      \\'temp\\',\\\\n                      maskToFloat(e.target.value),\\\\n                      temperatureRangeFieldValue(4, 96)\\\\n                    )\\\\n                  }}\\\\n                  onBlur={() => {\\\\n                    setCycleStepsById({\\\\n                      ...cycleStepsById,\\\\n                      [cycleStepId]: {\\\\n                        ...stepState,\\\\n                        temp: {\\\\n                          ...stepState.temp,\\\\n                          wasAccessed: true,\\\\n                        },\\\\n                      },\\\\n                    })\\\\n                  }}\\\\n                  error={\\\\n                    stepState.temp.wasAccessed ? stepState.temp.error : null\\\\n                  }\\\\n                />\\\\n              </Flex>\\\\n              <Flex\\\\n                flexDirection={DIRECTION_COLUMN}\\\\n                gridGap={SPACING.spacing4}\\\\n                width=\\\\\"33%\\\\\"\\\\n              >\\\\n                <InputField\\\\n                  title={i18n.format(\\\\n                    t(\\'form:step_edit_form.field.thermocyclerProfile.time\\'),\\\\n                    \\'capitalize\\'\\\\n                  )}\\\\n                  units={t(\\'units.time\\')}\\\\n                  value={stepState.time.value}\\\\n                  onChange={(e: React.ChangeEvent<any>) => {\\\\n                    handleValueUpdate(\\\\n                      cycleStepId,\\\\n                      \\'time\\',\\\\n                      maskToTime(e.target.value),\\\\n                      isTimeFormatMinutesSeconds\\\\n                    )\\\\n                  }}\\\\n                  onBlur={() => {\\\\n                    setCycleStepsById({\\\\n                      ...cycleStepsById,\\\\n                      [cycleStepId]: {\\\\n                        ...stepState,\\\\n                        time: {\\\\n                          ...stepState.time,\\\\n                          wasAccessed: true,\\\\n                        },\\\\n                      },\\\\n                    })\\\\n                  }}\\\\n                  error={\\\\n                    stepState.time.wasAccessed ? stepState.time.error : null\\\\n                  }\\\\n                />\\\\n              </Flex>\\\\n              <Flex\\\\n                css={css`\\\\n                  &:hover {\\\\n                    background-color: ${COLORS.grey40};\\\\n                  }\\\\n                `}\\\\n                borderRadius={BORDERS.borderRadius4}\\\\n                cursor={CURSOR_POINTER}\\\\n                onClick={() => {\\\\n                  handleDeleteStep(cycleStepId)\\\\n                }}\\\\n                alignSelf={ALIGN_CENTER}\\\\n              >\\\\n                <Icon name=\\\\\"close\\\\\" size=\\\\\"1.5rem\\\\\" />\\\\n              </Flex>\\\\n            </Flex>\\\\n          ) : (\\\\n            <Flex\\\\n              key={cycleStepId}\\\\n              gridGap={SPACING.spacing24}\\\\n              backgroundColor={COLORS.grey10}\\\\n              padding={SPACING.spacing12}\\\\n              borderRadius={BORDERS.borderRadius4}\\\\n            >\\\\n              <StyledText\\\\n                desktopStyle=\\\\\"bodyDefaultRegular\\\\\"\\\\n                backgroundColor={COLORS.grey40}\\\\n                padding={`${SPACING.spacing2} ${SPACING.spacing8} `}\\\\n                borderRadius={BORDERS.borderRadius4}\\\\n              >{`${getStepIndex(steps, cycleId ?? \\'\\')}.${\\\\n                cycleStepIndex + 1\\\\n              }`}</StyledText>\\\\n              <StyledText desktopStyle=\\\\\"bodyDefaultRegular\\\\\">{`${\\\\n                stepState.name.value\\\\n              }, ${stepState.temp.value}${t(\\'units.degrees\\')}, ${\\\\n                stepState.time.value\\\\n              }, `}</StyledText>\\\\n\"}', '{\"file_content\": \"[Unit]\\\\nDescription=Opentrons System Resource Tracker\\\\nAfter=opentrons-robot-server.service\\\\n\\\\n[Service]\\\\nType=notify\\\\nExecStart=python3 -m performance_metrics.system_resource_tracker\\\\nStateDirectory=system-resource-tracker\\\\nEnvironment=PYTHONPATH=/opt/opentrons-robot-server\\\\nEnvironment=OT_SYSTEM_RESOURCE_TRACKER_ENABLED=true\\\\nEnvironment=OT_SYSTEM_RESOURCE_TRACKER_REFRESH_INTERVAL=15.0\\\\n\\\\nRestart=no\\\\nTimeoutSec=10s\\\\n\\\\n[Install]\\\\nWantedBy=multi-user.target\\\\n\"}', '{\"file_content\": \"include ../scripts/python.mk\\\\ninclude ../scripts/push.mk\\\\n\\\\not_project := $(OPENTRONS_PROJECT)\\\\nproject_rs_default = $(if $(ot_project),$(ot_project),robot-stack)\\\\nproject_ir_default = $(if $(ot_project),$(ot_project),ot3)\\\\n\\\\nSHX := npx shx\\\\n\\\\n# Host key location for robot\\\\nssh_key ?= $(default_ssh_key)\\\\n# Other SSH args for robot\\\\nssh_opts ?= $(default_ssh_opts) -q\\\\n# Helper to safely bundle ssh options\\\\nssh_helper = $(if $(ssh_key),-i $(ssh_key)) $(ssh_opts)\\\\n\\\\n# Defined separately than the clean target so the wheel file doesn\\\\u2019t have to\\\\n# depend on a PHONY target\\\\n\\\\n# Find the version of the wheel from git using a helper script. We\\\\n# use python here so we can use the same version normalization that will be\\\\n# used to create the wheel.\\\\nwheel_file = dist/$(call python_get_wheelname,performance-metrics,$(project_rs_default),performance_metrics,$(BUILD_NUMBER))\\\\n\\\\n# Find the version of the sdist file from git using a helper script.\\\\nsdist_file = dist/$(call python_get_sdistname,performance-metrics,$(project_rs_default),performance_metrics)\\\\n\\\\n# Find the branch, sha, version that will be used to update the VERSION.json file\\\\nversion_file = $(call python_get_git_version,performance-metrics,$(project_rs_default),performance_metrics)\\\\n\\\\n\\\\nclean_cmd = $(SHX) rm -rf \\'build\\' \\'**/*.egg-info\\' \\'**/__pycache__\\' **/*.pyc \\'.mypy_cache\\' \\'.pytest_cache\\'\\\\nclean_wheel_cmd = $(clean_cmd) dist/*.whl\\\\nclean_sdist_cmd = $(clean_cmd) dist/*.tar.gz\\\\nclean_all_cmd = $(clean_cmd) dist\\\\n\\\\n.PHONY: lint\\\\nlint:\\\\n\\\\t$(python) -m black --check .\\\\n\\\\t$(python) -m mypy .\\\\n\\\\t$(python) -m flake8 .\\\\n\\\\n.PHONY: format\\\\nformat:\\\\n\\\\t$(python) -m black .\\\\n\\\\n.PHONY: setup\\\\nsetup:\\\\n\\\\t$(pipenv) sync --dev\\\\n\\\\n.PHONY: teardown\\\\nteardown:\\\\n\\\\t$(pipenv) --rm\\\\n\\\\n.PHONY: clean\\\\nclean:\\\\n\\\\t$(clean_all_cmd)\\\\n\\\\n.PHONY: wheel\\\\nwheel:\\\\n\\\\t$(clean_wheel_cmd)\\\\n\\\\t$(python) setup.py $(wheel_opts) bdist_wheel\\\\n\\\\t$(SHX) rm -rf build\\\\n\\\\t$(SHX) ls dist\\\\n\\\\n.PHONY: sdist\\\\nsdist: export OPENTRONS_PROJECT=$(project_rs_default)\\\\nsdist:\\\\n\\\\t$(clean_sdist_cmd)\\\\n\\\\t$(python) setup.py sdist\\\\n\\\\t$(SHX) rm -rf build\\\\n\\\\t$(SHX) ls dist\\\\n\\\\n.PHONY: push-no-restart\\\\npush-no-restart: wheel\\\\n\\\\t$(call push-python-package,$(host),$(ssh_key),$(ssh_opts),$(wheel_file))\\\\n\\\\n.PHONY: push\\\\npush: push-no-restart\\\\n\\\\t$(call restart-service,$(host),$(ssh_key),$(ssh_opts),\\\\\"opentrons-robot-server\\\\\")\\\\n\\\\n.PHONY: push-no-restart-ot3\\\\npush-no-restart-ot3: sdist\\\\n\\\\t$(call push-python-sdist,$(host),$(ssh_key),$(ssh_opts),$(sdist_file),/opt/opentrons-robot-server,performance_metrics,src,,$(version_file))\\\\n\\\\n.PHONY: push-ot3\\\\npush-ot3: push-no-restart-ot3\\\\n\\\\t$(call restart-service,$(host),$(ssh_key),$(ssh_opts),\\\\\"opentrons-robot-server\\\\\")\\\\n\\\\n.PHONY: override-robot-version\\\\noverride-robot-version:\\\\n\\\\t$(eval update_dict := \\'{\\\\\"opentrons_api_version\\\\\": \\\\\"$(version)\\\\\", \\\\\"update_server_version\\\\\": \\\\\"$(version)\\\\\", \\\\\"robot_server_version\\\\\": \\\\\"$(version)\\\\\", \\\\\"server_utils_version\\\\\": \\\\\"$(version)\\\\\", \\\\\"opentrons_hardware_version\\\\\": \\\\\"$(version)\\\\\"}\\')\\\\n\\\\t$(call sync-version-file,$(host),$(ssh_key),$(ssh_opts),\\'$(update_dict)\\')\\\\n\\\\t$(call restart-service,$(host),$(ssh_key),$(ssh_opts),\\\\\"opentrons-robot-server\\\\\")\\\\n\\\\n\\\\n.PHONY: set-performance-metrics-ff\\\\nset-performance-metrics-ff:\\\\n\\\\t@curl \\\\\\\\\\\\n\\\\t--silent \\\\\\\\\\\\n    -H \\\\\"opentrons-version: *\\\\\" \\\\\\\\\\\\n    -X POST $(host):31950/settings \\\\\\\\\\\\n    -H \\\\\"content-type: application/json\\\\\" \\\\\\\\\\\\n    -d \\'{\\\\\"id\\\\\": \\\\\"enablePerformanceMetrics\\\\\", \\\\\"value\\\\\": true}\\'\\\\n\\\\n.PHONY: unset-performance-metrics-ff\\\\nunset-performance-metrics-ff:\\\\n\\\\t@curl \\\\\\\\\\\\n\\\\t--silent \\\\\\\\\\\\n\\\\t-H \\\\\"opentrons-version: *\\\\\" \\\\\\\\\\\\n\\\\t-X POST $(host):31950/settings \\\\\\\\\\\\n\\\\t-H \\\\\"content-type: application/json\\\\\" \\\\\\\\\\\\n\\\\t-d \\'{\\\\\"id\\\\\": \\\\\"enablePerformanceMetrics\\\\\", \\\\\"value\\\\\": false}\\'\\\\n\\\\n.PHONY: test\\\\ntest:\\\\n\\\\t$(pytest) tests\\\\n\\\\n.PHONY: setup-remote-flex\\\\nsetup-remote-flex:\\\\n\\\\n\\\\t@echo \\\\\"Setting up remote Flex...\\\\\"\\\\n\\\\t@echo \\\\\"Pushing performance-metrics package to Flex\\\\\"\\\\t\\\\n\\\\n\\\\t@$(MAKE) push-no-restart-ot3 host=$(host) ssh_key=$(ssh_key) 2>&1 | grep -v \\\\\"Permanently added\\\\\" > /dev/null\\\\n\\\\n\\\\t@echo \\\\\"Pushing api package to Flex\\\\\"\\\\n\\\\t@$(MAKE) -C ../api push-no-restart-ot3 host=$(host) ssh_key=$(ssh_key) 2>&1 | grep -v \\\\\"Permanently added\\\\\" > /dev/null\\\\n\\\\n\\\\t@echo \\\\\"Pushing robot-server package to Flex and restarting robot server\\\\\"\\\\n\\\\t@$(MAKE) -C ../robot-server push-ot3 host=$(host) ssh_key=$(ssh_key) 2>&1 | grep -v \\\\\"Permanently added\\\\\" > /dev/null\\\\n\\\\n\\\\t@echo \\\\\"Setting performance metrics feature flag\\\\\"\\\\n\\\\t@$(MAKE) set-performance-metrics-ff host=$(host) 2>&1 > /dev/null\\\\n\\\\n\\\\n.PHONY: start-remote-system-resource-tracker\\\\nstart-remote-system-resource-tracker:\\\\n\\\\t@echo \\\\\"Triggering system resource tracker on host $(host)...\\\\\"\\\\n\\\\t@ssh -i $(ssh_key) root@$(host) \\\\\\\\\\\\n\\\\t\\\\t\\\\\"cd /opt/opentrons-robot-server; \\\\\\\\\\\\n\\\\t\\\\tOT_SYSTEM_RESOURCE_TRACKER_ENABLED=true \\\\\\\\\\\\n\\\\t\\\\t$${refresh_interval:+OT_SYSTEM_RESOURCE_TRACKER_REFRESH_INTERVAL=$$refresh_interval} \\\\\\\\\\\\n\\\\t\\\\t$${process_filters:+OT_SYSTEM_RESOURCE_TRACKER_PROCESS_FILTERS=$$process_filters} \\\\\\\\\\\\n\\\\t\\\\t$${storage_dir:+OT_SYSTEM_RESOURCE_TRACKER_STORAGE_DIR=$$storage_dir} \\\\\\\\\\\\n\\\\t\\\\t$${logging_level:+OT_SYSTEM_RESOURCE_TRACKER_LOGGING_LEVEL=$$logging_level} \\\\\\\\\\\\n\\\\t\\\\tpython3 -m performance_metrics.system_resource_tracker\\\\\"\\\\n\\\\n\\\\n.PHONY: setup-system-resource-tracker-systemd-service\\\\nsetup-system-resource-tracker-systemd-service:\\\\n\\\\t@echo \\\\\"Setting up system resource tracker systemd service\\\\\"\\\\n\\\\t@$(call push-systemd-unit ,$(host),$(ssh_key),$(ssh_opts),$(FILENAME))\\\\n\\\\n\\\\n\\\\t@echo \\\\\"Enabling system resource tracker service\\\\\"\\\\n\\\\t@ssh -i $(ssh_key) root@$(host) \\\\\"\\\\\\\\\\\\n\\\\t\\\\tmount -o remount,rw / && \\\\\\\\\\\\n\\\\t\\\\tsystemctl enable system-resource-tracker --quiet || \\\\\\\\\\\\n\\\\t\\\\tmount -o remount,ro /\\\\\"\\\\n\\\\n\\\\t@echo \\\\\"Starting system resource tracker service\\\\\"\\\\n\\\\t@$(call restart-service,$(host),$(ssh_key),$(ssh_opts),system-resource-tracker)\\\\n\\\\n\\\\n.PHONY: setup-prod-system-resource-tracker-systemd-service\\\\nsetup-prod-system-resource-tracker-systemd-service: FILENAME=system-resource-tracker.service\\\\nsetup-prod-system-resource-tracker-systemd-service: setup-system-resource-tracker-systemd-service\\\\n\\\\n.PHONY: setup-dev-system-resource-tracker-systemd-service\\\\nsetup-dev-system-resource-tracker-systemd-service: FILENAME=system-resource-tracker-dev.service\\\\nsetup-dev-system-resource-tracker-systemd-service: setup-system-resource-tracker-systemd-service\\\\n\\\\n\\\\n.PHONY: cleanup-remote-flex\\\\n# Default value for the data folder path\\\\nDATA_FOLDER ?= /data/performance_metrics_data\\\\nDEV_DATA_FOLDER ?= /data/performance_metrics_data_dev\\\\n\\\\ncleanup-remote-flex:\\\\n\\\\t@echo \\\\\"Cleaning up performance metrics on host $(host)...\\\\\"\\\\n\\\\t\\\\n\\\\t# Note not using || to exit on error because it only looks to see \\\\n\\\\t# if the previous command failed, whereas we want to catch any error or a successful exit\\\\n\\\\n\\\\t@ssh -i $(ssh_key) root@$(host) \\\\\"\\\\\\\\\\\\n\\\\t\\\\ttrap \\'echo \\\\\\\\\\\\\"Remounting filesystem as read-only\\\\\\\\\\\\\" && mount -o remount,ro /\\' EXIT ERR && \\\\\\\\\\\\n\\\\t\\\\techo \\'Configuring remote file system to read/write\\' && \\\\\\\\\\\\n\\\\t\\\\tmount -o remount,rw / && \\\\\\\\\\\\n\\\\t\\\\techo \\'Stopping system-resource-tracker\\' && \\\\\\\\\\\\n\\\\t\\\\tsystemctl stop system-resource-tracker && \\\\\\\\\\\\n\\\\t\\\\techo \\'Disabling system-resource-tracker\\' && \\\\\\\\\\\\n\\\\t\\\\tsystemctl disable system-resource-tracker && \\\\\\\\\\\\n\\\\t\\\\techo \\'Removing service file, data folders, and performance_metrics package\\' && \\\\\\\\\\\\n\\\\t\\\\trm -rf \\\\\\\\\\\\n\\\\t\\\\t\\\\t/etc/systemd/system/system-resource-tracker.service \\\\\\\\\\\\n\\\\t\\\\t\\\\t$(DATA_FOLDER) \\\\\\\\\\\\n\\\\t\\\\t\\\\t$(DEV_DATA_FOLDER) \\\\\\\\\\\\n\\\\t\\\\t\\\\t/opt/opentrons-robot-server/performance_metrics* && \\\\\\\\\\\\n\\\\t\\\\techo \\'Reloading daemon\\' && \\\\\\\\\\\\n\\\\t\\\\tsystemctl daemon-reload && \\\\\\\\\\\\n\\\\t\\\\techo \\'Checking system-resource-tracker status\\' && \\\\\\\\\\\\n\\\\t\\\\tif systemctl is-active system-resource-tracker --quiet; then \\\\\\\\\\\\n\\\\t\\\\t\\\\techo \\'Error: system-resource-tracker is still active\\'; \\\\\\\\\\\\n\\\\t\\\\t\\\\texit 1; \\\\\\\\\\\\n\\\\t\\\\telse \\\\\\\\\\\\n\\\\t\\\\t\\\\techo \\'system-resource-tracker is not active\\'; \\\\\\\\\\\\n\\\\t\\\\tfi\\\\\"\\\\t\\\\t\\\\n\\\\n\\\\t@echo \\\\\"Unsetting performance metrics feature flag\\\\\"\\\\n\\\\t@$(MAKE) unset-performance-metrics-ff host=$(host) 2>&1 > /dev/null\\\\n\"}', '{\"file_content\": \"import logging\\\\nimport os\\\\nimport shutil\\\\nimport subprocess\\\\nimport sys\\\\nfrom pathlib import Path\\\\nfrom typing import Optional\\\\n\\\\nfrom packaging import version\\\\n\\\\nfrom pipx.constants import FETCH_MISSING_PYTHON, WINDOWS\\\\nfrom pipx.standalone_python import download_python_build_standalone\\\\nfrom pipx.util import PipxError\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\n\\\\ndef has_venv() -> bool:\\\\n    try:\\\\n        import venv  # noqa: F401\\\\n    except ImportError:\\\\n        return False\\\\n    return True\\\\n\\\\n\\\\nclass InterpreterResolutionError(PipxError):\\\\n    def __init__(self, source: str, version: str, wrap_message: bool = True):\\\\n        self.source = source\\\\n        self.version = version\\\\n        potentially_path = \\\\\"/\\\\\" in version\\\\n        potentially_pylauncher = \\\\\"python\\\\\" not in version and not potentially_path\\\\n\\\\n        message = (\\\\n            f\\\\\"No executable for the provided Python version \\'{version}\\' found in {source}.\\\\\"\\\\n            \\\\\" Please make sure the provided version is \\\\\"\\\\n        )\\\\n        if source == \\\\\"py launcher\\\\\":\\\\n            message += \\\\\"listed when running `py --list`.\\\\\"\\\\n        if source == \\\\\"PATH\\\\\":\\\\n            message += \\\\\"on your PATH or the file path is valid. \\\\\"\\\\n            if potentially_path:\\\\n                message += \\\\\"The provided version looks like a path, but no executable was found there.\\\\\"\\\\n            if potentially_pylauncher:\\\\n                message += (\\\\n                    \\\\\"The provided version looks like a version, \\\\\"\\\\n                    \\\\\"but both the python command and the Python Launcher were not found on PATH.\\\\\"\\\\n                )\\\\n        if source == \\\\\"the python-build-standalone project\\\\\":\\\\n            message += \\\\\"listed in https://github.com/indygreg/python-build-standalone/releases/latest.\\\\\"\\\\n        super().__init__(message, wrap_message)\\\\n\\\\n\\\\ndef find_unix_command_python(python_version: str) -> Optional[str]:\\\\n    try:\\\\n        parsed_python_version = version.parse(python_version)\\\\n    except version.InvalidVersion:\\\\n        logger.info(f\\\\\"Invalid Python version: {python_version}\\\\\")\\\\n        return None\\\\n\\\\n    if (\\\\n        parsed_python_version.epoch != 0\\\\n        or parsed_python_version.is_devrelease\\\\n        or parsed_python_version.is_postrelease\\\\n        or parsed_python_version.is_prerelease\\\\n    ):\\\\n        logger.info(f\\\\\"Unsupported Python version: {python_version}\\\\\")\\\\n        return None\\\\n\\\\n    # Python command could be `python3` or `python3.x` without micro version component\\\\n    python_command = f\\\\\"python{\\'.\\'.join(python_version.split(\\'.\\')[:2])}\\\\\"\\\\n\\\\n    python_path = shutil.which(python_command)\\\\n    if not python_path:\\\\n        logger.info(f\\\\\"Command `{python_command}` was not found on the system\\\\\")\\\\n        return None\\\\n\\\\n    if parsed_python_version.micro != 0:\\\\n        logger.warning(\\\\n            f\\\\\"The command \\'{python_command}\\' located at \\'{python_path}\\' will be used. \\\\\"\\\\n            f\\\\\"It may not match the specified version {python_version} at the micro/patch level.\\\\\"\\\\n        )\\\\n\\\\n    return python_path\\\\n\\\\n\\\\ndef find_python_interpreter(python_version: str, fetch_missing_python: bool = False) -> str:\\\\n    if Path(python_version).is_file() or shutil.which(python_version):\\\\n        return python_version\\\\n\\\\n    if not WINDOWS:\\\\n        python_unix_command = find_unix_command_python(python_version)\\\\n        if python_unix_command:\\\\n            return python_unix_command\\\\n\\\\n    try:\\\\n        py_executable = find_py_launcher_python(python_version)\\\\n        if py_executable:\\\\n            return py_executable\\\\n    except (subprocess.CalledProcessError, FileNotFoundError) as e:\\\\n        raise InterpreterResolutionError(source=\\\\\"py launcher\\\\\", version=python_version) from e\\\\n\\\\n    if fetch_missing_python or FETCH_MISSING_PYTHON:\\\\n        try:\\\\n            return download_python_build_standalone(python_version)\\\\n        except PipxError as e:\\\\n            raise InterpreterResolutionError(source=\\\\\"the python-build-standalone project\\\\\", version=python_version) from e\\\\n\\\\n    raise InterpreterResolutionError(source=\\\\\"PATH\\\\\", version=python_version)\\\\n\\\\n\\\\n# The following code was copied from https://github.com/uranusjr/pipx-standalone\\\\n# which uses the same technique to build a completely standalone pipx\\\\n# distribution.\\\\n#\\\\n# If we are running under the Windows embeddable distribution,\\\\n# venv isn\\'t available (and we probably don\\'t want to use the\\\\n# embeddable distribution as our applications\\' base Python anyway)\\\\n# so we try to locate the system Python and use that instead.\\\\n\\\\n\\\\ndef find_py_launcher_python(python_version: Optional[str] = None) -> Optional[str]:\\\\n    py = shutil.which(\\\\\"py\\\\\")\\\\n    if py and python_version:\\\\n        python_semver = python_version\\\\n        if python_version.startswith(\\\\\"python\\\\\"):\\\\n            logger.warning(\\\\n                \\\\\"Removing `python` from the start of the version, as pylauncher just expects the semantic version\\\\\"\\\\n            )\\\\n            python_semver = python_semver.lstrip(\\\\\"python\\\\\")\\\\n        py = subprocess.run(\\\\n            [py, f\\\\\"-{python_semver}\\\\\", \\\\\"-c\\\\\", \\\\\"import sys; print(sys.executable)\\\\\"],\\\\n            capture_output=True,\\\\n            text=True,\\\\n            check=True,\\\\n        ).stdout.strip()\\\\n    return py\\\\n\\\\n\\\\ndef _find_default_windows_python() -> str:\\\\n    if has_venv():\\\\n        return sys.executable\\\\n    python = find_py_launcher_python() or shutil.which(\\\\\"python\\\\\")\\\\n\\\\n    if python is None:\\\\n        raise PipxError(\\\\\"No suitable Python found\\\\\")\\\\n\\\\n    # If the path contains \\\\\"WindowsApps\\\\\", it\\'s the store python\\\\n    if \\\\\"WindowsApps\\\\\" not in python:\\\\n        return python\\\\n\\\\n    # Special treatment to detect Windows Store stub.\\\\n    # https://twitter.com/zooba/status/1212454929379581952\\\\n\\\\n    proc = subprocess.run([python, \\\\\"-V\\\\\"], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, check=False)\\\\n    if proc.returncode != 0:\\\\n        # Cover the 9009 return code pre-emptively.\\\\n        raise PipxError(\\\\\"No suitable Python found\\\\\")\\\\n    if not proc.stdout.strip():\\\\n        # A real Python should print version, Windows Store stub won\\'t.\\\\n        raise PipxError(\\\\\"No suitable Python found\\\\\")\\\\n    return python  # This executable seems to work.\\\\n\\\\n\\\\ndef _get_sys_executable() -> str:\\\\n    if WINDOWS:\\\\n        return _find_default_windows_python()\\\\n    else:\\\\n        return str(Path(sys.executable).resolve())\\\\n\\\\n\\\\ndef _get_absolute_python_interpreter(env_python: str) -> str:\\\\n    which_python = shutil.which(env_python)\\\\n    if not which_python:\\\\n        raise PipxError(f\\\\\"Default python interpreter \\'{env_python}\\' is invalid.\\\\\")\\\\n    return which_python\\\\n\\\\n\\\\nenv_default_python = os.environ.get(\\\\\"PIPX_DEFAULT_PYTHON\\\\\")\\\\n\\\\nif not env_default_python:\\\\n    DEFAULT_PYTHON = _get_sys_executable()\\\\nelse:\\\\n    DEFAULT_PYTHON = _get_absolute_python_interpreter(env_default_python)\\\\n\"}', '{\"file_content\": \"import logging\\\\nimport subprocess\\\\nfrom pathlib import Path\\\\nfrom typing import List\\\\n\\\\nfrom packaging import version\\\\n\\\\nfrom pipx import commands, constants, paths, standalone_python\\\\nfrom pipx.animate import animate\\\\nfrom pipx.pipx_metadata_file import PipxMetadata\\\\nfrom pipx.util import is_paths_relative, rmdir\\\\nfrom pipx.venv import Venv, VenvContainer\\\\n\\\\nlogger = logging.getLogger(__name__)\\\\n\\\\n\\\\ndef get_installed_standalone_interpreters() -> List[Path]:\\\\n    return [python_dir for python_dir in paths.ctx.standalone_python_cachedir.iterdir() if python_dir.is_dir()]\\\\n\\\\n\\\\ndef get_venvs_using_standalone_interpreter(venv_container: VenvContainer) -> List[Venv]:\\\\n    venvs: list[Venv] = []\\\\n    for venv_dir in venv_container.iter_venv_dirs():\\\\n        venv = Venv(venv_dir)\\\\n        if venv.pipx_metadata.source_interpreter:\\\\n            venvs.append(venv)\\\\n    return venvs\\\\n\\\\n\\\\ndef get_interpreter_users(interpreter: Path, venvs: List[Venv]) -> List[PipxMetadata]:\\\\n    return [\\\\n        venv.pipx_metadata\\\\n        for venv in venvs\\\\n        if venv.pipx_metadata.source_interpreter\\\\n        and is_paths_relative(venv.pipx_metadata.source_interpreter, interpreter)\\\\n    ]\\\\n\\\\n\\\\ndef list_interpreters(\\\\n    venv_container: VenvContainer,\\\\n):\\\\n    interpreters = get_installed_standalone_interpreters()\\\\n    venvs = get_venvs_using_standalone_interpreter(venv_container)\\\\n    output: list[str] = []\\\\n    output.append(f\\\\\"Standalone interpreters are in {paths.ctx.standalone_python_cachedir}\\\\\")\\\\n    for interpreter in interpreters:\\\\n        output.append(f\\\\\"Python {interpreter.name}\\\\\")\\\\n        used_in = get_interpreter_users(interpreter, venvs)\\\\n        if used_in:\\\\n            output.append(\\\\\"    Used in:\\\\\")\\\\n            for p in used_in:\\\\n                output.append(f\\\\\"     - {p.main_package.package} {p.main_package.package_version}\\\\\")\\\\n        else:\\\\n            output.append(\\\\\"    Unused\\\\\")\\\\n\\\\n    print(\\\\\"\\\\\\\\n\\\\\".join(output))\\\\n    return constants.EXIT_CODE_OK\\\\n\\\\n\\\\ndef prune_interpreters(\\\\n    venv_container: VenvContainer,\\\\n):\\\\n    interpreters = get_installed_standalone_interpreters()\\\\n    venvs = get_venvs_using_standalone_interpreter(venv_container)\\\\n    removed = []\\\\n    for interpreter in interpreters:\\\\n        if get_interpreter_users(interpreter, venvs):\\\\n            continue\\\\n        rmdir(interpreter, safe_rm=True)\\\\n        removed.append(interpreter.name)\\\\n    if removed:\\\\n        print(\\\\\"Successfully removed:\\\\\")\\\\n        for interpreter_name in removed:\\\\n            print(f\\\\\" - Python {interpreter_name}\\\\\")\\\\n    else:\\\\n        print(\\\\\"Nothing to remove\\\\\")\\\\n    return constants.EXIT_CODE_OK\\\\n\\\\n\\\\ndef get_latest_micro_version(\\\\n    current_version: version.Version, latest_python_versions: List[version.Version]\\\\n) -> version.Version:\\\\n    for latest_python_version in latest_python_versions:\\\\n        if current_version.major == latest_python_version.major and current_version.minor == latest_python_version.minor:\\\\n            return latest_python_version\\\\n    return current_version\\\\n\\\\n\\\\ndef upgrade_interpreters(venv_container: VenvContainer, verbose: bool):\\\\n    with animate(\\\\\"Getting the index of the latest standalone python builds\\\\\", not verbose):\\\\n        latest_pythons = standalone_python.list_pythons(use_cache=False)\\\\n\\\\n    parsed_latest_python_versions = []\\\\n    for latest_python_version in latest_pythons:\\\\n        try:\\\\n            parsed_latest_python_versions.append(version.parse(latest_python_version))\\\\n        except version.InvalidVersion:\\\\n            logger.info(f\\\\\"Invalid version found in latest pythons: {latest_python_version}. Skipping.\\\\\")\\\\n\\\\n    upgraded = []\\\\n\\\\n    for interpreter_dir in paths.ctx.standalone_python_cachedir.iterdir():\\\\n        if not interpreter_dir.is_dir():\\\\n            continue\\\\n\\\\n        interpreter_python = interpreter_dir / \\\\\"python.exe\\\\\" if constants.WINDOWS else interpreter_dir / \\\\\"bin\\\\\" / \\\\\"python3\\\\\"\\\\n        interpreter_full_version = (\\\\n            subprocess.run([str(interpreter_python), \\\\\"--version\\\\\"], stdout=subprocess.PIPE, check=True, text=True)\\\\n            .stdout.strip()\\\\n            .split()[1]\\\\n        )\\\\n        try:\\\\n            parsed_interpreter_full_version = version.parse(interpreter_full_version)\\\\n        except version.InvalidVersion:\\\\n            logger.info(f\\\\\"Invalid version found in interpreter at {interpreter_dir}. Skipping.\\\\\")\\\\n            continue\\\\n        latest_micro_version = get_latest_micro_version(parsed_interpreter_full_version, parsed_latest_python_versions)\\\\n        if latest_micro_version > parsed_interpreter_full_version:\\\\n            standalone_python.download_python_build_standalone(\\\\n                f\\\\\"{latest_micro_version.major}.{latest_micro_version.minor}\\\\\",\\\\n                override=True,\\\\n            )\\\\n\\\\n            for venv_dir in venv_container.iter_venv_dirs():\\\\n                venv = Venv(venv_dir)\\\\n                if venv.pipx_metadata.source_interpreter is not None and is_paths_relative(\\\\n                    venv.pipx_metadata.source_interpreter, interpreter_dir\\\\n                ):\\\\n                    print(\\\\n                        f\\\\\"Upgrade the interpreter of {venv.name} from {interpreter_full_version} to {latest_micro_version}\\\\\"\\\\n                    )\\\\n                    commands.reinstall(\\\\n                        venv_dir=venv_dir,\\\\n                        local_bin_dir=paths.ctx.bin_dir,\\\\n                        local_man_dir=paths.ctx.man_dir,\\\\n                        python=str(interpreter_python),\\\\n                        verbose=verbose,\\\\n                    )\\\\n                    upgraded.append((venv.name, interpreter_full_version, latest_micro_version))\\\\n\\\\n    if upgraded:\\\\n        print(\\\\\"Successfully upgraded the interpreter(s):\\\\\")\\\\n        for venv_name, old_version, new_version in upgraded:\\\\n            print(f\\\\\" - {venv_name}: {old_version} -> {new_version}\\\\\")\\\\n    else:\\\\n        print(\\\\\"Nothing to upgrade\\\\\")\\\\n\\\\n    # Any failure to upgrade will raise PipxError, otherwise success\\\\n    return constants.EXIT_CODE_OK\\\\n\\\\n\"}', '{\"file_content\": \"import json\\\\nimport shutil\\\\nimport sys\\\\n\\\\nfrom helpers import (\\\\n    run_pipx_cli,\\\\n)\\\\nfrom package_info import PKG\\\\nfrom pipx import standalone_python\\\\n\\\\nMAJOR_PYTHON_VERSION = sys.version_info.major\\\\n# Minor version 3.8 is not supported for fetching standalone versions\\\\nMINOR_PYTHON_VERSION = sys.version_info.minor if sys.version_info.minor != 8 else 9\\\\nTARGET_PYTHON_VERSION = f\\\\\"{MAJOR_PYTHON_VERSION}.{MINOR_PYTHON_VERSION}\\\\\"\\\\n\\\\noriginal_which = shutil.which\\\\n\\\\n\\\\ndef mock_which(name):\\\\n    if name == TARGET_PYTHON_VERSION:\\\\n        return None\\\\n    return original_which(name)\\\\n\\\\n\\\\ndef test_list_no_standalone_interpreters(pipx_temp_env, monkeypatch, capsys):\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"list\\\\\"])\\\\n\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Standalone interpreters\\\\\" in captured.out\\\\n    assert len(captured.out.splitlines()) == 1\\\\n\\\\n\\\\ndef test_list_used_standalone_interpreters(pipx_temp_env, monkeypatch, mocked_github_api, capsys):\\\\n    monkeypatch.setattr(shutil, \\\\\"which\\\\\", mock_which)\\\\n\\\\n    assert not run_pipx_cli(\\\\n        [\\\\n            \\\\\"install\\\\\",\\\\n            \\\\\"--fetch-missing-python\\\\\",\\\\n            \\\\\"--python\\\\\",\\\\n            TARGET_PYTHON_VERSION,\\\\n            PKG[\\\\\"pycowsay\\\\\"][\\\\\"spec\\\\\"],\\\\n        ]\\\\n    )\\\\n\\\\n    capsys.readouterr()\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"list\\\\\"])\\\\n\\\\n    captured = capsys.readouterr()\\\\n    assert TARGET_PYTHON_VERSION in captured.out\\\\n    assert \\\\\"pycowsay\\\\\" in captured.out\\\\n\\\\n\\\\ndef test_list_unused_standalone_interpreters(pipx_temp_env, monkeypatch, mocked_github_api, capsys):\\\\n    monkeypatch.setattr(shutil, \\\\\"which\\\\\", mock_which)\\\\n\\\\n    assert not run_pipx_cli(\\\\n        [\\\\n            \\\\\"install\\\\\",\\\\n            \\\\\"--fetch-missing-python\\\\\",\\\\n            \\\\\"--python\\\\\",\\\\n            TARGET_PYTHON_VERSION,\\\\n            PKG[\\\\\"pycowsay\\\\\"][\\\\\"spec\\\\\"],\\\\n        ]\\\\n    )\\\\n\\\\n    assert not run_pipx_cli([\\\\\"uninstall\\\\\", \\\\\"pycowsay\\\\\"])\\\\n    capsys.readouterr()\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"list\\\\\"])\\\\n\\\\n    captured = capsys.readouterr()\\\\n    assert TARGET_PYTHON_VERSION in captured.out\\\\n    assert \\\\\"pycowsay\\\\\" not in captured.out\\\\n    assert \\\\\"Unused\\\\\" in captured.out\\\\n\\\\n\\\\ndef test_prune_unused_standalone_interpreters(pipx_temp_env, monkeypatch, mocked_github_api, capsys):\\\\n    monkeypatch.setattr(shutil, \\\\\"which\\\\\", mock_which)\\\\n\\\\n    assert not run_pipx_cli(\\\\n        [\\\\n            \\\\\"install\\\\\",\\\\n            \\\\\"--fetch-missing-python\\\\\",\\\\n            \\\\\"--python\\\\\",\\\\n            TARGET_PYTHON_VERSION,\\\\n            PKG[\\\\\"pycowsay\\\\\"][\\\\\"spec\\\\\"],\\\\n        ]\\\\n    )\\\\n\\\\n    capsys.readouterr()\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"prune\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Nothing to remove\\\\\" in captured.out\\\\n\\\\n    assert not run_pipx_cli([\\\\\"uninstall\\\\\", \\\\\"pycowsay\\\\\"])\\\\n    capsys.readouterr()\\\\n\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"prune\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Successfully removed:\\\\\" in captured.out\\\\n    assert f\\\\\"- Python {TARGET_PYTHON_VERSION}\\\\\" in captured.out\\\\n\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"list\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Standalone interpreters\\\\\" in captured.out\\\\n    assert len(captured.out.splitlines()) == 1\\\\n\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"prune\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Nothing to remove\\\\\" in captured.out\\\\n\\\\n\\\\ndef test_upgrade_standalone_interpreter(pipx_temp_env, root, monkeypatch, capsys):\\\\n    monkeypatch.setattr(shutil, \\\\\"which\\\\\", mock_which)\\\\n\\\\n    with open(root / \\\\\"testdata\\\\\" / \\\\\"standalone_python_index_20240107.json\\\\\") as f:\\\\n        new_index = json.load(f)\\\\n    monkeypatch.setattr(standalone_python, \\\\\"get_or_update_index\\\\\", lambda _: new_index)\\\\n\\\\n    assert not run_pipx_cli(\\\\n        [\\\\n            \\\\\"install\\\\\",\\\\n            \\\\\"--fetch-missing-python\\\\\",\\\\n            \\\\\"--python\\\\\",\\\\n            TARGET_PYTHON_VERSION,\\\\n            PKG[\\\\\"pycowsay\\\\\"][\\\\\"spec\\\\\"],\\\\n        ]\\\\n    )\\\\n\\\\n    with open(root / \\\\\"testdata\\\\\" / \\\\\"standalone_python_index_20240224.json\\\\\") as f:\\\\n        new_index = json.load(f)\\\\n    monkeypatch.setattr(standalone_python, \\\\\"get_or_update_index\\\\\", lambda _: new_index)\\\\n\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"upgrade\\\\\"])\\\\n\\\\n\\\\ndef test_upgrade_standalone_interpreter_nothing_to_upgrade(pipx_temp_env, capsys):\\\\n    assert not run_pipx_cli([\\\\\"interpreter\\\\\", \\\\\"upgrade\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Nothing to upgrade\\\\\" in captured.out\\\\n\\\\n\"}', '{\"file_content\": \"import sys\\\\nfrom io import BytesIO, TextIOWrapper\\\\nfrom unittest import mock\\\\n\\\\nimport pytest  # type: ignore[import-not-found]\\\\n\\\\nfrom pipx.emojis import use_emojis\\\\n\\\\n\\\\n@pytest.mark.parametrize(\\\\n    \\\\\"PIPX_USE_EMOJI, encoding, expected\\\\\",\\\\n    [\\\\n        # utf-8\\\\n        (None, \\\\\"utf-8\\\\\", True),\\\\n        (\\\\\"\\\\\", \\\\\"utf-8\\\\\", False),\\\\n        (\\\\\"0\\\\\", \\\\\"utf-8\\\\\", False),\\\\n        (\\\\\"1\\\\\", \\\\\"utf-8\\\\\", True),\\\\n        (\\\\\"true\\\\\", \\\\\"utf-8\\\\\", True),\\\\n        (\\\\\"tru\\\\\", \\\\\"utf-8\\\\\", False),  # codespell:ignore tru\\\\n        (\\\\\"True\\\\\", \\\\\"utf-8\\\\\", True),\\\\n        (\\\\\"false\\\\\", \\\\\"utf-8\\\\\", False),\\\\n        # latin_1 (alias: iso-8859-1)\\\\n        (None, \\\\\"latin_1\\\\\", False),\\\\n        (\\\\\"\\\\\", \\\\\"latin_1\\\\\", False),\\\\n        (\\\\\"0\\\\\", \\\\\"latin_1\\\\\", False),\\\\n        (\\\\\"1\\\\\", \\\\\"latin_1\\\\\", True),\\\\n        (\\\\\"true\\\\\", \\\\\"latin_1\\\\\", True),\\\\n        (\\\\\"tru\\\\\", \\\\\"latin_1\\\\\", False),  # codespell:ignore tru\\\\n        (\\\\\"True\\\\\", \\\\\"latin_1\\\\\", True),\\\\n        (\\\\\"false\\\\\", \\\\\"latin_1\\\\\", False),\\\\n        # cp1252\\\\n        (None, \\\\\"cp1252\\\\\", False),\\\\n        (\\\\\"\\\\\", \\\\\"cp1252\\\\\", False),\\\\n        (\\\\\"0\\\\\", \\\\\"cp1252\\\\\", False),\\\\n        (\\\\\"1\\\\\", \\\\\"cp1252\\\\\", True),\\\\n        (\\\\\"true\\\\\", \\\\\"cp1252\\\\\", True),\\\\n        (\\\\\"tru\\\\\", \\\\\"cp1252\\\\\", False),  # codespell:ignore tru\\\\n        (\\\\\"True\\\\\", \\\\\"cp1252\\\\\", True),\\\\n        (\\\\\"false\\\\\", \\\\\"cp1252\\\\\", False),\\\\n    ],\\\\n)\\\\ndef test_use_emojis(monkeypatch, PIPX_USE_EMOJI, encoding, expected):\\\\n    with mock.patch.object(sys, \\\\\"stderr\\\\\", TextIOWrapper(BytesIO(), encoding=encoding)):\\\\n        if PIPX_USE_EMOJI is not None:\\\\n            monkeypatch.setenv(\\\\\"PIPX_USE_EMOJI\\\\\", PIPX_USE_EMOJI)\\\\n        assert use_emojis() is expected\\\\n\\\\n\"}', '{\"file_content\": \"import fnmatch\\\\nfrom pathlib import Path\\\\n\\\\nfrom helpers import run_pipx_cli, skip_if_windows\\\\nfrom pipx import paths\\\\nfrom pipx.commands.environment import ENVIRONMENT_VARIABLES\\\\nfrom pipx.paths import get_expanded_environ\\\\n\\\\n\\\\ndef test_cli(pipx_temp_env, monkeypatch, capsys):\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_HOME=*subdir/pipxhome*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_BIN_DIR=*otherdir/pipxbindir*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_MAN_DIR=*otherdir/pipxmandir*\\\\\")\\\\n    assert \\\\\"PIPX_SHARED_LIBS\\\\\" in captured.out\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_LOCAL_VENVS=*subdir/pipxhome/venvs*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_LOG_DIR=*subdir/pipxhome/logs*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_TRASH_DIR=*subdir/pipxhome/.trash*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_VENV_CACHEDIR=*subdir/pipxhome/.cache*\\\\\")\\\\n    # Checking just for the sake of completeness\\\\n    for env_var in ENVIRONMENT_VARIABLES:\\\\n        assert env_var in captured.out\\\\n\\\\n\\\\ndef test_cli_with_args(monkeypatch, capsys):\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_HOME\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_BIN_DIR\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_MAN_DIR\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_SHARED_LIBS\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_LOCAL_VENVS\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_LOG_DIR\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_TRASH_DIR\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_VENV_CACHEDIR\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_DEFAULT_PYTHON\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_USE_EMOJI\\\\\"])\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_HOME_ALLOW_SPACE\\\\\"])\\\\n\\\\n    assert run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"SSS\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Variable not found.\\\\\" in captured.err\\\\n\\\\n\\\\ndef test_resolve_user_dir_in_env_paths(monkeypatch):\\\\n    monkeypatch.setenv(\\\\\"TEST_DIR\\\\\", \\\\\"~/test\\\\\")\\\\n    home = Path.home()\\\\n    env_dir = get_expanded_environ(\\\\\"TEST_DIR\\\\\")\\\\n    assert \\\\\"~\\\\\" not in str(env_dir)\\\\n    assert env_dir == home / \\\\\"test\\\\\"\\\\n    env_dir = get_expanded_environ(\\\\\"THIS_SHOULD_NOT_EXIST\\\\\")\\\\n    assert env_dir is None\\\\n\\\\n\\\\ndef test_allow_space_in_pipx_home(\\\\n    monkeypatch,\\\\n    capsys,\\\\n    tmp_path,\\\\n):\\\\n    home_dir = Path(tmp_path) / \\\\\"path with space\\\\\"\\\\n    monkeypatch.setattr(paths.ctx, \\\\\"_base_home\\\\\", home_dir)\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_HOME_ALLOW_SPACE\\\\\"])\\\\n    paths.ctx.log_warnings()\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Found a space\\\\\" in captured.err\\\\n    assert \\\\\"false\\\\\" in captured.out\\\\n\\\\n    monkeypatch.setenv(\\\\\"PIPX_HOME_ALLOW_SPACE\\\\\", \\\\\"1\\\\\")\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--value\\\\\", \\\\\"PIPX_HOME_ALLOW_SPACE\\\\\"])\\\\n    paths.ctx.log_warnings()\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Found a space\\\\\" not in captured.err\\\\n    assert \\\\\"true\\\\\" in captured.out\\\\n\\\\n    paths.ctx.make_local()\\\\n\\\\n\\\\n@skip_if_windows\\\\ndef test_cli_global(pipx_temp_env, monkeypatch, capsys):\\\\n    assert not run_pipx_cli([\\\\\"environment\\\\\", \\\\\"--global\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_HOME=*global/pipxhome*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_BIN_DIR=*global_otherdir/pipxbindir*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_MAN_DIR=*global_otherdir/pipxmandir*\\\\\")\\\\n    assert \\\\\"PIPX_SHARED_LIBS\\\\\" in captured.out\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_LOCAL_VENVS=*global/pipxhome/venvs*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_LOG_DIR=*global/pipxhome/logs*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_TRASH_DIR=*global/pipxhome/.trash*\\\\\")\\\\n    assert fnmatch.fnmatch(captured.out, \\\\\"*PIPX_VENV_CACHEDIR=*global/pipxhome/.cache*\\\\\")\\\\n    # Checking just for the sake of completeness\\\\n    for env_var in ENVIRONMENT_VARIABLES:\\\\n        assert env_var in captured.out\\\\n\\\\n\"}', '{\"file_content\": \"import logging\\\\nimport os\\\\nimport subprocess\\\\nimport sys\\\\nimport textwrap\\\\nfrom unittest import mock\\\\n\\\\nimport pytest  # type: ignore\\\\n\\\\nimport pipx.main\\\\nimport pipx.util\\\\nfrom helpers import run_pipx_cli\\\\nfrom package_info import PKG\\\\nfrom pipx import constants\\\\n\\\\n\\\\ndef test_help_text(pipx_temp_env, monkeypatch, capsys):\\\\n    mock_exit = mock.Mock(side_effect=ValueError(\\\\\"raised in test to exit early\\\\\"))\\\\n    with mock.patch.object(sys, \\\\\"exit\\\\\", mock_exit), pytest.raises(\\\\n        ValueError, match=\\\\\"raised in test to exit early\\\\\"\\\\n    ):\\\\n        run_pipx_cli([\\\\\"run\\\\\", \\\\\"--help\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Download the latest version of a package\\\\\" in captured.out\\\\n\\\\n\\\\ndef execvpe_mock(cmd_path, cmd_args, env):\\\\n    return_code = subprocess.run(\\\\n        [str(x) for x in cmd_args],\\\\n        env=env,\\\\n        capture_output=False,\\\\n        encoding=\\\\\"utf-8\\\\\",\\\\n        text=True,\\\\n        check=False,\\\\n    ).returncode\\\\n    sys.exit(return_code)\\\\n\\\\n\\\\ndef run_pipx_cli_exit(pipx_cmd_list, assert_exit=None):\\\\n    with pytest.raises(SystemExit) as sys_exit:\\\\n        run_pipx_cli(pipx_cmd_list)\\\\n    if assert_exit is not None:\\\\n        assert sys_exit.type == SystemExit\\\\n        assert sys_exit.value.code == assert_exit\\\\n\\\\n\\\\n@pytest.mark.parametrize(\\\\n    \\\\\"package_name\\\\\", [\\\\\"pycowsay\\\\\", \\\\\"pycowsay==0.0.0.1\\\\\", \\\\\"pycowsay>=0.0.0.1\\\\\"]\\\\n)\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_simple_run(pipx_temp_env, monkeypatch, capsys, package_name):\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", package_name, \\\\\"--help\\\\\"])\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Download the latest version of a package\\\\\" not in captured.out\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_cache(pipx_temp_env, monkeypatch, capsys, caplog):\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"pycowsay\\\\\", \\\\\"cowsay\\\\\", \\\\\"args\\\\\"])\\\\n    caplog.set_level(logging.DEBUG)\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"--verbose\\\\\", \\\\\"pycowsay\\\\\", \\\\\"cowsay\\\\\", \\\\\"args\\\\\"], assert_exit=0)\\\\n    assert \\\\\"Reusing cached venv\\\\\" in caplog.text\\\\n\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"--no-cache\\\\\", \\\\\"pycowsay\\\\\", \\\\\"cowsay\\\\\", \\\\\"args\\\\\"])\\\\n    assert \\\\\"Removing cached venv\\\\\" in caplog.text\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_cachedir_tag(pipx_ultra_temp_env, monkeypatch, capsys, caplog):\\\\n    tag_path = constants.PIPX_VENV_CACHEDIR / \\\\\"CACHEDIR.TAG\\\\\"\\\\n    assert not tag_path.exists()\\\\n\\\\n    # Run pipx to create tag\\\\n    caplog.set_level(logging.DEBUG)\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"pycowsay\\\\\", \\\\\"cowsay\\\\\", \\\\\"args\\\\\"])\\\\n    assert \\\\\"Adding CACHEDIR.TAG to cache directory\\\\\" in caplog.text\\\\n    assert tag_path.exists()\\\\n    caplog.clear()\\\\n\\\\n    # Run pipx again to verify the tag file is not recreated\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"pycowsay\\\\\", \\\\\"cowsay\\\\\", \\\\\"args\\\\\"])\\\\n    assert \\\\\"Adding CACHEDIR.TAG to cache directory\\\\\" not in caplog.text\\\\n    assert tag_path.exists()\\\\n\\\\n    # Verify the tag file starts with the required signature.\\\\n    with tag_path.open(\\\\\"r\\\\\") as tag_file:\\\\n        assert tag_file.read().startswith(\\\\\"Signature: 8a477f597d28d172789f06886806bc55\\\\\")\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_script_from_internet(pipx_temp_env, capsys):\\\\n    run_pipx_cli_exit(\\\\n        [\\\\n            \\\\\"run\\\\\",\\\\n            \\\\\"https://gist.githubusercontent.com/cs01/\\\\\"\\\\n            \\\\\"fa721a17a326e551ede048c5088f9e0f/raw/\\\\\"\\\\n            \\\\\"6bdfbb6e9c1132b1c38fdd2f195d4a24c540c324/pipx-demo.py\\\\\",\\\\n        ],\\\\n        assert_exit=0,\\\\n    )\\\\n\\\\n\\\\n@pytest.mark.parametrize(\\\\n    \\\\\"input_run_args,expected_app_with_args\\\\\",\\\\n    [\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\", \\\\\"hello\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"], [\\\\\"pycowsay\\\\\", \\\\\"--\\\\\", \\\\\"--\\\\\"]),\\\\n        ([\\\\\"--\\\\\", \\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\"], [\\\\\"--\\\\\", \\\\\"pycowsay\\\\\", \\\\\"--\\\\\"]),\\\\n    ],\\\\n)\\\\ndef test_appargs_doubledash(\\\\n    pipx_temp_env, capsys, monkeypatch, input_run_args, expected_app_with_args\\\\n):\\\\n    parser = pipx.main.get_command_parser()\\\\n    monkeypatch.setattr(sys, \\\\\"argv\\\\\", [\\\\\"pipx\\\\\", \\\\\"run\\\\\"] + input_run_args)\\\\n    parsed_pipx_args = parser.parse_args()\\\\n    pipx.main.check_args(parsed_pipx_args)\\\\n    assert parsed_pipx_args.app_with_args == expected_app_with_args\\\\n\\\\n\\\\ndef test_run_ensure_null_pythonpath():\\\\n    env = os.environ.copy()\\\\n    env[\\\\\"PYTHONPATH\\\\\"] = \\\\\"test\\\\\"\\\\n    assert (\\\\n        \\\\\"None\\\\\"\\\\n        in subprocess.run(\\\\n            [\\\\n                sys.executable,\\\\n                \\\\\"-m\\\\\",\\\\n                \\\\\"pipx\\\\\",\\\\n                \\\\\"run\\\\\",\\\\n                \\\\\"ipython\\\\\",\\\\n                \\\\\"-c\\\\\",\\\\n                \\\\\"import os; print(os.environ.get(\\'PYTHONPATH\\'))\\\\\",\\\\n            ],\\\\n            env=env,\\\\n            capture_output=True,\\\\n            text=True,\\\\n            check=True,\\\\n        ).stdout\\\\n    )\\\\n\\\\n\\\\n# packages listed roughly in order of increasing test duration\\\\n@pytest.mark.parametrize(\\\\n    \\\\\"package, package_or_url, app_appargs, skip_win\\\\\",\\\\n    [\\\\n        (\\\\\"pycowsay\\\\\", \\\\\"pycowsay\\\\\", [\\\\\"pycowsay\\\\\", \\\\\"hello\\\\\"], False),\\\\n        (\\\\\"shell-functools\\\\\", PKG[\\\\\"shell-functools\\\\\"][\\\\\"spec\\\\\"], [\\\\\"filter\\\\\", \\\\\"--help\\\\\"], True),\\\\n        (\\\\\"black\\\\\", PKG[\\\\\"black\\\\\"][\\\\\"spec\\\\\"], [\\\\\"black\\\\\", \\\\\"--help\\\\\"], False),\\\\n        (\\\\\"pylint\\\\\", PKG[\\\\\"pylint\\\\\"][\\\\\"spec\\\\\"], [\\\\\"pylint\\\\\", \\\\\"--help\\\\\"], False),\\\\n        (\\\\\"kaggle\\\\\", PKG[\\\\\"kaggle\\\\\"][\\\\\"spec\\\\\"], [\\\\\"kaggle\\\\\", \\\\\"--help\\\\\"], False),\\\\n        (\\\\\"ipython\\\\\", PKG[\\\\\"ipython\\\\\"][\\\\\"spec\\\\\"], [\\\\\"ipython\\\\\", \\\\\"--version\\\\\"], False),\\\\n        (\\\\\"cloudtoken\\\\\", PKG[\\\\\"cloudtoken\\\\\"][\\\\\"spec\\\\\"], [\\\\\"cloudtoken\\\\\", \\\\\"--help\\\\\"], True),\\\\n        (\\\\\"awscli\\\\\", PKG[\\\\\"awscli\\\\\"][\\\\\"spec\\\\\"], [\\\\\"aws\\\\\", \\\\\"--help\\\\\"], True),\\\\n        # (\\\\\"ansible\\\\\", PKG[\\\\\"ansible\\\\\"][\\\\\"spec\\\\\"], [\\\\\"ansible\\\\\", \\\\\"--help\\\\\"]), # takes too long\\\\n    ],\\\\n)\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_package_determination(\\\\n    caplog, pipx_temp_env, package, package_or_url, app_appargs, skip_win\\\\n):\\\\n    if sys.platform.startswith(\\\\\"win\\\\\") and skip_win:\\\\n        # Skip packages with \\'scripts\\' in setup.py that don\\'t work on Windows\\\\n        pytest.skip()\\\\n\\\\n    caplog.set_level(logging.INFO)\\\\n\\\\n    run_pipx_cli_exit(\\\\n        [\\\\\"run\\\\\", \\\\\"--verbose\\\\\", \\\\\"--spec\\\\\", package_or_url, \\\\\"--\\\\\"] + app_appargs\\\\n    )\\\\n\\\\n    assert \\\\\"Cannot determine package name\\\\\" not in caplog.text\\\\n    assert f\\\\\"Determined package name: {package}\\\\\" in caplog.text\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_without_requirements(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    test_str = \\\\\"Hello, world!\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text({repr(test_str)})\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", script.as_uri()])\\\\n    assert out.read_text() == test_str\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_with_requirements(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                # /// pyproject\\\\n                # run.requirements = [\\\\\"requests==2.28.1\\\\\"]\\\\n                # ///\\\\n\\\\n                # Check requests can be imported\\\\n                import requests\\\\n                # Check dependencies of requests can be imported\\\\n                import certifi\\\\n                # Check the installed version\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text(requests.__version__)\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip(),\\\\n        encoding=\\\\\"utf-8\\\\\",\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", script.as_uri()])\\\\n    assert out.read_text() == \\\\\"2.28.1\\\\\"\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_with_args(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                import sys\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text(str(int(sys.argv[1]) + 1))\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", script.as_uri(), \\\\\"1\\\\\"])\\\\n    assert out.read_text() == \\\\\"2\\\\\"\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_with_requirements_and_args(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                # /// pyproject\\\\n                # run.requirements = [\\\\\"packaging\\\\\"]\\\\n                # ///\\\\n                import packaging\\\\n                import sys\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text(str(int(sys.argv[1]) + 1))\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", script.as_uri(), \\\\\"1\\\\\"])\\\\n    assert out.read_text() == \\\\\"2\\\\\"\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_with_invalid_requirement(capsys, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            \\\\\"\\\\\"\\\\\"\\\\n                # /// pyproject\\\\n                # run.requirements = [\\\\\"this is an invalid requirement\\\\\"]\\\\n                # ///\\\\n                print()\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    ret = run_pipx_cli([\\\\\"run\\\\\", script.as_uri()])\\\\n    assert ret == 1\\\\n\\\\n    captured = capsys.readouterr()\\\\n    assert \\\\\"Invalid requirement this is an invalid requirement\\\\\" in captured.err\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_script_by_absolute_name(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    test_str = \\\\\"Hello, world!\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text({repr(test_str)})\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"--path\\\\\", str(script)])\\\\n    assert out.read_text() == test_str\\\\n\\\\n\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_script_by_relative_name(caplog, pipx_temp_env, monkeypatch, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    test_str = \\\\\"Hello, world!\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text({repr(test_str)})\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    with monkeypatch.context() as m:\\\\n        m.chdir(tmp_path)\\\\n        run_pipx_cli_exit([\\\\\"run\\\\\", \\\\\"test.py\\\\\"])\\\\n    assert out.read_text() == test_str\\\\n\\\\n\\\\n@pytest.mark.skipif(\\\\n    not sys.platform.startswith(\\\\\"win\\\\\"), reason=\\\\\"uses windows version format\\\\\"\\\\n)\\\\n@mock.patch(\\\\\"os.execvpe\\\\\", new=execvpe_mock)\\\\ndef test_run_with_windows_python_version(caplog, pipx_temp_env, tmp_path):\\\\n    script = tmp_path / \\\\\"test.py\\\\\"\\\\n    out = tmp_path / \\\\\"output.txt\\\\\"\\\\n    script.write_text(\\\\n        textwrap.dedent(\\\\n            f\\\\\"\\\\\"\\\\\"\\\\n                import sys\\\\n                from pathlib import Path\\\\n                Path({repr(str(out))}).write_text(sys.version)\\\\n            \\\\\"\\\\\"\\\\\"\\\\n        ).strip()\\\\n    )\\\\n    run_pipx_cli_exit([\\\\\"run\\\\\", script.as_uri(), \\\\\"--python\\\\\", \\\\\"3.11\\\\\"])\\\\n    assert \\\\\"3.11\\\\\" in out.read_text()\\\\n\\\\n\"}']}, 'search_code_dependencies': {'number': 20, 'observation': ['cat not find the entity in code knowledge graph', 'cat not find the entity in code knowledge graph', 'cat not find the entity in code knowledge graph', '{\"entities_that_CALL_the_target_entity\": [\"OrganizationEventsEndpointBase\", \"get_snuba_params\", \"handle_data\", \"_data_fn\", \"_discover_data_fn\", \"_get_event_stats\", \"get_event_stats\", \"OrganizationReplayEventsMetaEndpoint\", \"data_fn\"], \"entities_CALLED_by_the_target_entity\": [\"is_equation\"]}', 'cat not find the entity in code knowledge graph', '{\"entities_that_CALL_the_target_entity\": [\"test_MetadataSyncJob_has_default_timeout\", \"test_MetadataSyncJob_takes_overridden_timeout\", \"test_MetadataSyncJob_creates_new_user\", \"test_MetadataSyncJob_creates_new_special_deleted_user\", \"test_MetadataSyncJob_updates_application_state\", \"test_MetadataSyncJob_updates_existing_user\", \"test_MetadataSyncJob_deletes_user\", \"test_MetadataSyncJob_does_not_delete_reserved_deleted_user\", \"test_MetadataSyncJob_reassociates_draftreplies_to_new_account_before_deleting_user\", \"test_MetadataSyncJob_reassociates_draftreplies_to_existing_account_before_deleting_user\", \"test_MetadataSyncJob_reassociates_draftreplies_to_new_local_account_before_deleting_user\", \"test_MetadataSyncJob_replaces_reserved_deleted_user_account\", \"test_MetadataSyncJob_success\", \"test_MetadataSyncJob_success_current_user_name_change\", \"test_MetadataSyncJob_success_with_missing_key\"], \"entities_CALLED_by_the_target_entity\": [\"__init__\", \"call_api\", \"_update_users\"]}', '{\"entities_that_CALL_the_target_entity\": [], \"entities_CALLED_by_the_target_entity\": [\"load\"]}', '{\"entities_that_CALL_the_target_entity\": [\"pluggable_sets_entity\", \"mock_entity\"], \"entities_CALLED_by_the_target_entity\": [\"select_storage\"]}', 'cat not find the entity in code knowledge graph', 'cat not find the entity in code knowledge graph', '{\"entities_that_CALL_the_target_entity\": [\"as_csv_parameter_interface\", \"test_csv_parameter_as_protocol_engine_type\", \"test_csv_parameter\", \"test_csv_parameter_rows\", \"test_csv_parameter_mixed_quotes\", \"test_csv_parameter_additional_kwargs\", \"test_csv_parameter_dont_detect_dialect\", \"test_csv_parameter_trailing_empties\", \"mock_csv_param\", \"run_time_parameters\"], \"entities_CALLED_by_the_target_entity\": [\"__init__\", \"file\", \"file_opened\", \"contents\", \"parse_as_csv\", \"_remove_trailing_empty_rows\"]}', '{\"entities_that_CALL_the_target_entity\": [\"run\", \"plate_reader_actions\", \"extract_py_fields\", \"create_protocols\", \"get_custom_tiprack_definition_for_tlc\", \"execute\", \"initialize_csv_files\", \"AbsorbanceReaderCore\", \"AbstractAbsorbanceReaderCore\", \"AbsorbanceReaderContext\", \"JsonFileReader\", \"PythonAndLegacyFileReader\", \"extract_bundle\", \"_get_standard_labware_definition\", \"simulate\", \"protocol\", \"get_labware_fixture\", \"_get_labware_fixture\", \"get_json_protocol_fixture\", \"_get_json_protocol_fixture\", \"get_bundle_fixture\", \"get_std_labware\", \"_get_bundle_protocol_fixture\", \"test_read\", \"test_absorbance_reader_read_preconditions\", \"get_git_description\", \"Mitutoyo_Digimatic_Indicator\", \"read_stable\", \"Scale\", \"http_get_all_labware_offsets\", \"_read_dial_indicator\", \"_dial_thread\", \"_respond_to_frontend_file_request\", \"_respond_to_data_request\", \"_read\", \"_get_eeprom_info\", \"SerialEmulator\", \"test_property_read_single\", \"test_property_read_multi\", \"test_property_write_single\", \"test_property_write_multi\", \"test_main\", \"test_main_no_left_pipette\", \"test_main_no_right_pipette\", \"get_api_docs\", \"extract_and_remove_api_reference\", \"_read_secret\", \"get_protocol\", \"test_add_key_call\", \"load_shared_data\", \"write_file\", \"unzip_update\", \"hash_file\", \"_rewrite_machine_info\", \"_choose_static_hostname\", \"get_keys\", \"write_fake_rootfs\", \"test_unzip\", \"test_lzma\", \"test_write_update_fails\", \"_get_serial_number\", \"listen\", \"TCPConnection\", \"_read_state\", \"test_connect\", \"test_serial_gadget_success\"], \"entities_CALLED_by_the_target_entity\": [\"CannotPerformModuleAction\", \"requires_version\", \"ProtocolFilesInvalidError\", \"isinstance\", \"model_validate_json\", \"str\", \"parse\", \"read_bytes\", \"cast\", \"model_dump\", \"uri_from_details\", \"read_text\", \"_get_packet\", \"float\", \"_send_packet\", \"sleep\", \"time\", \"ScaleReading\", \"_reconnect\", \"debug\", \"bytes\", \"len\"]}', '{\"entities_that_CALL_the_target_entity\": [\"subject\", \"test_create\"], \"entities_CALLED_by_the_target_entity\": [\"initialize\", \"read\", \"close_lid\", \"open_lid\", \"is_lid_on\"]}', 'cat not find the entity in code knowledge graph', 'cat not find the entity in code knowledge graph', '{\"entities_that_CALL_the_target_entity\": [\"_transform_profile_element\"], \"entities_CALLED_by_the_target_entity\": []}', '{\"entities_that_CALL_the_target_entity\": [\"prebuild_wheels\", \"tests_with_options\", \"cover\", \"zipapp\", \"develop\", \"build\", \"publish\", \"build_docs\", \"watch_docs\", \"build_changelog\", \"build_man\", \"test_all_packages\", \"install_all\", \"reinstall\", \"_upgrade_venv\", \"run_pipx_command\"], \"entities_CALLED_by_the_target_entity\": [\"install_package\", \"zip\", \"get_venv_dir\", \"package_name_from_spec\", \"len\", \"check_upgrade_shared_libs\", \"run_post_install_actions\", \"remove_venv\", \"next\", \"create_venv\", \"exists\", \"iterdir\", \"pipx_wrap\", \"VenvContainer\", \"bool\", \"Venv\", \"upgrade_package_no_metadata\", \"print\"]}', 'cat not find the entity in code knowledge graph', '{\"entities_that_CALL_the_target_entity\": [\"test_use_emojis\"], \"entities_CALLED_by_the_target_entity\": [\"strtobool\", \"encode\", \"getenv\", \"str\"]}', '{\"entities_that_CALL_the_target_entity\": [\"cli\"], \"entities_CALLED_by_the_target_entity\": [\"debug\", \"ensure_pipx_paths\", \"items\", \"get_venv_dir\", \"inject\", \"uninject\", \"reinstall_all\", \"prune_interpreters\", \"install_all\", \"list_packages\", \"canonicalize_name\", \"find_python_interpreter\", \"bool\", \"uninstall_all\", \"pin\", \"unpin\", \"run_pip\", \"upgrade_interpreters\", \"package_is_path\", \"upgrade_all\", \"VenvContainer\", \"upgrade\", \"install\", \"ExitCode\", \"uninstall\", \"vars\", \"str\", \"environment\", \"reinstall\", \"get_venv_args\", \"list_interpreters\", \"PipxError\", \"run\", \"upgrade_shared\", \"pipx_wrap\", \"package_is_url\", \"print\", \"info\", \"get_pip_args\"]}']}, 'search_files_path_by_pattern': {'number': 26, 'observation': ['{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/api/endpoints/event_file_committers.py\"}], \"pagination\": {\"total\": 1, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/sentry_apps/external_requests/test_issue_link_requester.py\"}], \"pagination\": {\"total\": 1, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/static/app/utils/replays/hooks/useReplayList.tsx\"}], \"pagination\": {\"total\": 1, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/integrations/utils/test_sync.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/test_sync.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/api_jobs/test_sync.py\"}], \"pagination\": {\"total\": 3, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/runner/commands/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/plugins/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/relay/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/ratelimits/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop/securedrop/tests/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/update-server/tests/common/test_config.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/performance-metrics/tests/performance_metrics/system_resource_tracker/test_config.py\"}], \"pagination\": {\"total\": 8, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/analytics/__tests__/reduxActionToAnalyticsEvent.test.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/redux-resources\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/redux\"}], \"pagination\": {\"total\": 3, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/top-selectors\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/step-forms\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/resources\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/__tests__\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/__testing-utils__\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/ui\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/well-selection\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/load-file\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/types.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/App.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/form-types.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/molecules\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/analytics\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/utils\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/modules\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/timelineMiddleware\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/pages\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/collision-types.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/ProtocolEditor.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/ProtocolRoutes.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/index.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/__fixtures__\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/steplist\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/pipettes\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/components\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/configureStore.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/dismiss\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/error.html\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/labware-ingred\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/file-data\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/assets\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/networking\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/feature-flags\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/file-types.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/navigation\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/tutorial\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/liquid-defs\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/constants.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/persist.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/labware-defs\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/protocol-designer/src/initialize.ts\"}], \"pagination\": {\"total\": 41, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/integration/test_styles_modal_dialog_error_details.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/tests/integration/test_styles_modal_dialog_button.py\"}], \"pagination\": {\"total\": 2, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/sentry_metrics/test_gen_metrics_multiprocess_steps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/sentry_metrics/test_rh_metrics_multiprocess_steps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/analytics/events/integration_pipeline_step.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0618_drop_event_user_id_from_userreport_table_step_2.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0736_rm_reprocessing_step2.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0616_drop_event_user_id_from_userreport_table_step_1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0663_artifactbundleindex_cleanup_step3.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0661_artifactbundleindex_cleanup_step2.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0738_rm_reprocessing_step3.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/migrations/0734_rm_reprocessing_step1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/SWELancer-Benchmark/project/nanoeval/nanoeval/solvers/computer_tasks/steps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/SWELancer-Benchmark/project/nanoeval/nanoeval/solvers/computer_tasks/steps_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/g-code-testing/g_code_parsing/g_code_functionality_defs/smoothie/microstepping_c_enable_g_code_functionality_def.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/g-code-testing/g_code_parsing/g_code_functionality_defs/smoothie/microstepping_b_enable_g_code_functionality_def.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/g-code-testing/g_code_parsing/g_code_functionality_defs/smoothie/steps_per_mm_g_code_functionality_def.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/g-code-testing/g_code_parsing/g_code_functionality_defs/smoothie/microstepping_c_disable_g_code_functionality_def.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/g-code-testing/g_code_parsing/g_code_functionality_defs/smoothie/microstepping_b_disable_g_code_functionality_def.py\"}], \"pagination\": {\"total\": 17, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [], \"pagination\": {\"total\": 0, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test_1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/sudo_testutils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/apidocs_test_case.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/safe_migrations_apps/migration_test_app/migrations/0001_create_migration_run_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/conftest.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_docker_memory_check.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_lint_requirements.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_bump_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_pin_github_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_flake8_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_check_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_sort_stronger_modules.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_minidump_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_payload_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_unreal_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_integration.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_message_filters.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_sdk.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_metrics_extraction.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_example.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/java/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_wsgi.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_constants.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_killswitches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_sdk_updates.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_unmerge.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_mypy_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_http.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_devimports.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_celery.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_culprit.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_datascrubbing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_stacktraces.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_dependencies.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_java.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_task.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/consumers/test_process.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_sentry_apps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_onboarding.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_core.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_staff.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_releases.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_signals.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_featureadoption.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_superuser.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/outbox/test_control.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_redis.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_autofix.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_test_generation.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_math.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_breakpoints.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_issue_summary.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_signed_seer_api.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/anomaly_detection/test_store_data.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_types.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_similar_issues.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_grouping_records.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_fetch_issues_given_patches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_more_parsing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/workflows/test_compare.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_dummy.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_silo_models.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_pending_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_router.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_jsonfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_bounded.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_slug.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_hybrid_cloud_foreign_key.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_picklefield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/bitfield/test_bitfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/manager/test_base_query_set.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/schema/safe_migrations/integration/test_migrations.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/test_absolute_url.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/services/test_organization.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_silo_aware_transaction_patch.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_util.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_client.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_flagpole_context.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_manager.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_sentry_app.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_alert_rule_trigger_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_repository.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_organizationmember.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_artifactbundle.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_workflow.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_monitor.py\"}], \"pagination\": {\"total\": 3679, \"cursor\": 0, \"page_size\": 100, \"has_more\": true}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/DropTipWizardHeader.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/DropTipWizard.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/DropTipWizardFlows.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/__tests__/DropTipWizardFlows.test.ts\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/__tests__/DropTipWizardHeader.test.tsx\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/__tests__/DropTipWizard.test.tsx\"}], \"pagination\": {\"total\": 7, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/app/src/organisms/DropTipWizardFlows/__tests__\"}], \"pagination\": {\"total\": 1, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/tests/test_standalone_interpreter.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/tests/test_interpreter.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/interpreter.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/src/pipx/commands/interpreter.py\"}], \"pagination\": {\"total\": 4, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test_1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/sudo_testutils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/apidocs_test_case.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/safe_migrations_apps/migration_test_app/migrations/0001_create_migration_run_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/conftest.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_docker_memory_check.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_lint_requirements.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_bump_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_pin_github_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_flake8_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_check_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_sort_stronger_modules.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_minidump_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_payload_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_unreal_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_integration.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_message_filters.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_sdk.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_metrics_extraction.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_example.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/java/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_wsgi.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_constants.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_killswitches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_sdk_updates.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_unmerge.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_mypy_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_http.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_devimports.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_celery.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_culprit.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_datascrubbing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_stacktraces.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_dependencies.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_java.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_task.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/consumers/test_process.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_sentry_apps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_onboarding.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_core.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_staff.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_releases.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_signals.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_featureadoption.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_superuser.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/outbox/test_control.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_redis.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_autofix.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_test_generation.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_math.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_breakpoints.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_issue_summary.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_signed_seer_api.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/anomaly_detection/test_store_data.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_types.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_similar_issues.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_grouping_records.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_fetch_issues_given_patches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_more_parsing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/workflows/test_compare.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_dummy.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_silo_models.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_pending_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_router.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_jsonfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_bounded.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_slug.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_hybrid_cloud_foreign_key.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_picklefield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/bitfield/test_bitfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/manager/test_base_query_set.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/schema/safe_migrations/integration/test_migrations.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/test_absolute_url.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/services/test_organization.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_silo_aware_transaction_patch.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_util.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_client.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_flagpole_context.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_manager.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_sentry_app.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_alert_rule_trigger_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_repository.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_organizationmember.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_artifactbundle.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_workflow.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_monitor.py\"}], \"pagination\": {\"total\": 3679, \"cursor\": 0, \"page_size\": 100, \"has_more\": true}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test_1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/sudo_testutils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/apidocs_test_case.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/safe_migrations_apps/migration_test_app/migrations/0001_create_migration_run_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/conftest.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_docker_memory_check.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_lint_requirements.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_bump_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_pin_github_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_flake8_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_check_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_sort_stronger_modules.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_minidump_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_payload_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_unreal_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_integration.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_message_filters.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_sdk.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_metrics_extraction.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_example.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/java/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_wsgi.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_constants.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_killswitches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_sdk_updates.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_unmerge.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_mypy_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_http.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_devimports.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_celery.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_culprit.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_datascrubbing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_stacktraces.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_dependencies.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_java.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_task.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/consumers/test_process.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_sentry_apps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_onboarding.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_core.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_staff.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_releases.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_signals.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_featureadoption.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_superuser.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/outbox/test_control.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_redis.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_autofix.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_test_generation.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_math.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_breakpoints.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_issue_summary.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_signed_seer_api.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/anomaly_detection/test_store_data.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_types.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_similar_issues.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_grouping_records.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_fetch_issues_given_patches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_more_parsing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/workflows/test_compare.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_dummy.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_silo_models.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_pending_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_router.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_jsonfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_bounded.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_slug.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_hybrid_cloud_foreign_key.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_picklefield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/bitfield/test_bitfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/manager/test_base_query_set.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/schema/safe_migrations/integration/test_migrations.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/test_absolute_url.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/services/test_organization.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_silo_aware_transaction_patch.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_util.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_client.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_flagpole_context.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_manager.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_sentry_app.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_alert_rule_trigger_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_repository.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_organizationmember.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_artifactbundle.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_workflow.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_monitor.py\"}], \"pagination\": {\"total\": 3679, \"cursor\": 0, \"page_size\": 100, \"has_more\": true}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test_1.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/utils/smal_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/sudo_testutils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/apidocs_test_case.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/fixtures/safe_migrations_apps/migration_test_app/migrations/0001_create_migration_run_test.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/conftest.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_docker_memory_check.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_lint_requirements.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_bump_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_pin_github_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/test_flake8_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_check_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_sort_stronger_modules.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/tools/mypy_helpers/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_minidump_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_payload_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/symbolicator/test_unreal_full.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_integration.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_message_filters.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_sdk.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/test_metrics_extraction.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/javascript/test_example.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/relay_integration/lang/java/test_plugin.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_wsgi.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_constants.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_killswitches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_sdk_updates.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_unmerge.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_mypy_stronglist.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_http.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_devimports.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_celery.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_culprit.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_datascrubbing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_stacktraces.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/test_dependencies.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_java.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/test_task.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/profiles/consumers/test_process.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_sentry_apps.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_onboarding.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_core.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_staff.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_releases.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_signals.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_featureadoption.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/test_superuser.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/receivers/outbox/test_control.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_redis.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/buffer/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_autofix.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_test_generation.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_math.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_breakpoints.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_issue_summary.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/test_signed_seer_api.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/anomaly_detection/test_store_data.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_types.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_similar_issues.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/similarity/test_grouping_records.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_fetch_issues_given_patches.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/fetch_issues/test_more_parsing.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/seer/workflows/test_compare.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/newsletter/test_dummy.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_silo_models.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_transactions.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_pending_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_deletion.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/test_router.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/test_utils.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_jsonfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_bounded.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_slug.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_hybrid_cloud_foreign_key.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/test_picklefield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/fields/bitfield/test_bitfield.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/models/manager/test_base_query_set.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/db/postgres/schema/safe_migrations/integration/test_migrations.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/test_absolute_url.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/organizations/services/test_organization.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_base.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_silo_aware_transaction_patch.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_util.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/silo/test_client.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_flagpole_context.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/features/test_manager.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_sentry_app.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_alert_rule_trigger_action.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_repository.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_organizationmember.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_artifactbundle.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_workflow.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/deletions/test_monitor.py\"}], \"pagination\": {\"total\": 3679, \"cursor\": 0, \"page_size\": 100, \"has_more\": true}}', '{\"data\": [{\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/runner/commands/test_run.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/consumers/test_run.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/tests/sentry/issues/test_run.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/hardware/tests/opentrons_hardware/firmware_update/test_run.py\"}, {\"path\": \"/data/veteran/project/TestPlanAgent/test_project/pipx/tests/test_run.py\"}], \"pagination\": {\"total\": 5, \"cursor\": 0, \"page_size\": 100, \"has_more\": false}}']}, 'search_class_in_project': {'number': 35, 'observation': ['{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"save\\\\nowner_id\\\\nowner\\\\nget_autoassigned_owner\\\\ninvalidate_debounce_issue_owners_evaluation_cache\\\\ninvalidate_assignee_exists_cache\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/models/groupowner.py\", \"line\": [54, 178], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"resolve_many\\\\nmany_from_object\\\\nfrom_object\\\\nfrom_orm_user\\\\nfrom_rpc_user\\\\nfrom_orm_team\\\\nfrom_rpc_team\\\\nfrom_identifier\\\\nfrom_identifier\\\\nfrom_identifier\\\\nfrom_id\\\\n__post_init__\\\\n__hash__\\\\n__eq__\\\\nresolve\\\\nidentifier\\\\nis_team\\\\nis_user\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/types/actor.py\", \"line\": [26, 262], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"title\\\\nshort_id\\\\nfind_referenced_groups\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/models/commit.py\", \"line\": [37, 76], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"run\\\\n_build_url\\\\n_validate_response\\\\n_build_headers\\\\nbody\\\\nsentry_app\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/sentry_apps/external_requests/issue_link_requester.py\", \"line\": [40, 176], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"get_field_list\\\\nget\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/sentry/src/sentry/replays/endpoints/organization_replay_events_meta.py\", \"line\": [14, 81], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"split_list\\\\n__init__\\\\nload_and_update_config\\\\nupdate_config\\\\nuser_prompt_config\\\\nuser_prompt_config_one\\\\nvalidated_input\\\\nsanitize_fingerprint\\\\nvalidate_gpg_keys\\\\nvalidate_journalist_alert_email\\\\nexists\\\\nsave\\\\nclean_config\\\\nload\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop/admin/securedrop_admin/__init__.py\", \"line\": [123, 734], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"__init__\\\\ncall_api\\\\n_update_users\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/securedrop_client/api_jobs/sync.py\", \"line\": [17, 138], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"load\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/securedrop_client/config.py\", \"line\": [32, 84], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"load\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/securedrop_client/config.py\", \"line\": [32, 84], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"load\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/securedrop-client/client/securedrop_client/config.py\", \"line\": [32, 84], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"select_storage\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/snuba/snuba/datasets/entities/storage_selectors/selector.py\", \"line\": [14, 28], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"select_storage\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/snuba/snuba/datasets/entities/storage_selectors/selector.py\", \"line\": [14, 28], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"function\", \"info\": \"def pluggable_sets_entity() -> PluggableEntity:\\\\n    return PluggableEntity(\\\\n        entity_key=EntityKey.GENERIC_METRICS_SETS,\\\\n        storages=[\\\\n            EntityStorageConnection(\\\\n                get_storage(StorageKey.GENERIC_METRICS_SETS),\\\\n                TranslationMappers(\\\\n                    subscriptables=[\\\\n                        SubscriptableMapper(\\\\n                            from_column_table=None,\\\\n                            from_column_name=\\\\\"tags_raw\\\\\",\\\\n                            to_nested_col_table=None,\\\\n                            to_nested_col_name=\\\\\"tags\\\\\",\\\\n                            value_subcolumn_name=\\\\\"raw_value\\\\\",\\\\n                        ),\\\\n                        SubscriptableMapper(\\\\n                            from_column_table=None,\\\\n                            from_column_name=\\\\\"tags\\\\\",\\\\n                            to_nested_col_table=None,\\\\n                            to_nested_col_name=\\\\\"tags\\\\\",\\\\n                            value_subcolumn_name=\\\\\"indexed_value\\\\\",\\\\n                        ),\\\\n                    ],\\\\n                    functions=[\\\\n                        FunctionNameMapper(\\\\\"uniq\\\\\", \\\\\"uniqCombined64Merge\\\\\"),\\\\n                        FunctionNameMapper(\\\\\"uniqIf\\\\\", \\\\\"uniqCombined64MergeIf\\\\\"),\\\\n                    ],\\\\n                ),\\\\n            )\\\\n        ],\\\\n        query_processors=[\\\\n            TagsTypeTransformer(),\\\\n            MappedGranularityProcessor(\\\\n                accepted_granularities=PERFORMANCE_GRANULARITIES,\\\\n                default_granularity=DEFAULT_MAPPED_GRANULARITY_ENUM,\\\\n            ),\\\\n            TimeSeriesProcessor({\\\\\"bucketed_time\\\\\": \\\\\"timestamp\\\\\"}, (\\\\\"timestamp\\\\\",)),\\\\n        ],\\\\n        columns=[\\\\n            SchemaColumn(\\\\\"org_id\\\\\", UInt(64)),\\\\n            SchemaColumn(\\\\\"project_id\\\\\", UInt(64)),\\\\n            SchemaColumn(\\\\\"metric_id\\\\\", UInt(64)),\\\\n            SchemaColumn(\\\\\"timestamp\\\\\", DateTime()),\\\\n            SchemaColumn(\\\\\"bucketed_time\\\\\", DateTime()),\\\\n            SchemaColumn(\\\\\"tags\\\\\", Nested([(\\\\\"key\\\\\", UInt(64)), (\\\\\"value\\\\\", UInt(64))])),\\\\n            SchemaColumn(\\\\\"value\\\\\", AggregateFunction(\\\\\"uniqCombined64\\\\\", [UInt(64)])),\\\\n        ],\\\\n        validators=[],\\\\n        required_time_column=\\\\\"timestamp\\\\\",\\\\n        storage_selector=DefaultQueryStorageSelector(),\\\\n    )\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/snuba/tests/datasets/entities/test_pluggable_entity.py\", \"line\": [50, 100], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"__init__\\\\nfile\\\\nfile_opened\\\\ncontents\\\\nparse_as_csv\\\\n_remove_trailing_empty_rows\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocols/parameters/csv_parameter_interface.py\", \"line\": [11, 96], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"initialize\\\\nread\\\\nclose_lid\\\\nopen_lid\\\\nis_lid_on\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocol_api/core/engine/module_core.py\", \"line\": [572, 696], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"initialize\\\\nread\\\\nclose_lid\\\\nopen_lid\\\\nis_lid_on\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocol_api/core/engine/module_core.py\", \"line\": [572, 696], \"kind\": \"def\"}}', 'cat not find the entity (class or function) in the project', 'cat not find the entity (class or function) in the project', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/calibration_storage/deck_configuration.py\", \"line\": [10, 13], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/calibration_storage/deck_configuration.py\", \"line\": [10, 13], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"__init__\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/api/src/opentrons/protocol_engine/errors/exceptions.py\", \"line\": [1104, 1114], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/shared-data/python/opentrons_shared_data/protocol/types.py\", \"line\": [275, 277], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/shared-data/python/opentrons_shared_data/protocol/types.py\", \"line\": [275, 277], \"kind\": \"def\"}}', '{\"detail_of_entity\": {\"category\": \"class\", \"info\": \"__init__\\\\nrefresh_processes\\\\nsnapshots\\\\nget_and_store_system_data_snapshots\", \"fname\": \"/data/veteran/project/TestPlanAgent/test_project/opentrons/performance-metrics/src/performance_metrics/system_resource_tracker/_system_resource_tracker.py\", \"line\": [19, 102], \"kind\": \"def\"}}', '{\"error\": \"Entity \\'Requirement\\' exists but has invalid structure\"}']}}\n"
     ]
    }
   ],
   "source": [
    "# 统计工具的使用情况\n",
    "tool_list = {}\n",
    "for react in reacts:\n",
    "    tool = react[\"action\"]\n",
    "    if tool not in tool_list:\n",
    "        tool_list[tool] = {}\n",
    "        tool_list[tool][\"number\"]= 1\n",
    "        tool_list[tool][\"observation\"] = []\n",
    "        tool_list[tool][\"observation\"].append(react[\"observation\"])\n",
    "    else:\n",
    "        tool_list[tool][\"number\"] += 1\n",
    "        tool_list[tool][\"observation\"].append(react[\"observation\"])\n",
    "print(tool_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"tool_list.json\", 'w') as f:\n",
    "    json.dump(tool_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计工具使用后得分情况\n",
    "import os \n",
    "result_dir = \"./result/ReAct\"\n",
    "\n",
    "llm_model = \"qwen-coder-32B\"\n",
    "\n",
    "reacts_and_scores = {}\n",
    "# 获取ref test plan以及 candidate test plan\n",
    "for repo in os.listdir(result_dir):\n",
    "    repo_dir = os.path.join(result_dir, repo)\n",
    "    if os.path.isdir(repo_dir):\n",
    "        Test_plan_dir = os.path.join(repo_dir, \"Test-Plan\")\n",
    "        if os.path.isdir(Test_plan_dir):\n",
    "            Test_plan_list = os.listdir(Test_plan_dir)\n",
    "            for Test_plan in Test_plan_list:\n",
    "                if llm_model in Test_plan:\n",
    "                    PR_content_file_dir = os.path.join(Test_plan_dir, Test_plan)\n",
    "                    pull_number = PR_content_file_dir.split(\"_\")[-1].split(\".\")[0]\n",
    "                    reacts_and_scores[pull_number] = {}\n",
    "                    if os.path.isfile(PR_content_file_dir):\n",
    "                        with open(PR_content_file_dir, 'r') as f:\n",
    "                            PR_content_json = json.load(f)\n",
    "                        reacts_and_scores[pull_number][\"react_info\"] = PR_content_json[\"react_info\"][:-1]\n",
    "                    \n",
    "        scores_dir = os.path.join(repo_dir, \"scores\")\n",
    "        if os.path.isdir(scores_dir):\n",
    "            scores_list_dir = os.listdir(scores_dir)\n",
    "            for score_file in scores_list_dir:\n",
    "                if llm_model in score_file:\n",
    "                    score_file_path = os.path.join(scores_dir, score_file)\n",
    "                    # print(score_file_path)\n",
    "                    pull_number = score_file_path.split(\"_\")[-1].split(\".\")[0]\n",
    "                    reacts_and_scores[pull_number][\"scores\"] = []\n",
    "                    with open(score_file_path, 'r') as f: \n",
    "                        score = json.load(f)\n",
    "                        score[\"type\"] = \"ReAct\"\n",
    "                        reacts_and_scores[pull_number][\"scores\"].append(score)\n",
    "                    # inout_score_file_path = score_file_path.replace(\"ReAct\", \"backup-without-git-diff/InOut\")\n",
    "                    inout_score_file_path = score_file_path.replace(\"ReAct\", \"InOut\")\n",
    "                    with open(inout_score_file_path, 'r') as f:\n",
    "                        score = json.load(f)\n",
    "                        score[\"type\"] = \"InOut\"\n",
    "                        reacts_and_scores[pull_number][\"scores\"].append(score)\n",
    "# print(reacts_and_scores)\n",
    "with open(f\"{llm_model}_reacts_and_scores_summary_diff.json\", 'w') as f:\n",
    "    json.dump(reacts_and_scores, f, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
